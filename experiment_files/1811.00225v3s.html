<!DOCTYPE html><html>
<head>
<title></title>
<style type="text/css">
<!--
.xflip {
    -moz-transform: scaleX(-1);
    -webkit-transform: scaleX(-1);
    -o-transform: scaleX(-1);
    transform: scaleX(-1);
    filter: fliph;
}
.yflip {
    -moz-transform: scaleY(-1);
    -webkit-transform: scaleY(-1);
    -o-transform: scaleY(-1);
    transform: scaleY(-1);
    filter: flipv;
}
.xyflip {
    -moz-transform: scaleX(-1) scaleY(-1);
    -webkit-transform: scaleX(-1) scaleY(-1);
    -o-transform: scaleX(-1) scaleY(-1);
    transform: scaleX(-1) scaleY(-1);
    filter: fliph + flipv;
}
-->
</style>
</head>
<body>
<a name=1></a>Understanding&#160;Learning&#160;Dynamics&#160;Of&#160;Language&#160;Models&#160;with&#160;SVCCA<br/>
Naomi&#160;Saphra&#160;and&#160;Adam&#160;Lopez<br/>
n.saphra@ed.ac.uk<br/>
alopez@ed.ac.uk<br/>
Institute&#160;for&#160;Language,&#160;Cognition,&#160;and&#160;Computation<br/>
University&#160;of&#160;Edinburgh<br/>
Abstract<br/>
gories&#160;in&#160;lower&#160;layers,&#160;and&#160;more&#160;contextual&#160;cate-<br/>gories&#160;in&#160;higher&#160;layers.&#160;For&#160;example,&#160;<a href="1811.00225v3s.html#9">Blevins&#160;et&#160;al.</a><br/>
Research&#160;has&#160;shown&#160;that&#160;neural&#160;models&#160;im-<br/>
<a href="1811.00225v3s.html#9">(2018)&#160;</a>found&#160;that&#160;a&#160;word’s&#160;part&#160;of&#160;speech&#160;(POS)&#160;is<br/>
plicitly&#160;encode&#160;linguistic&#160;features,&#160;but&#160;there<br/>
encoded&#160;by&#160;lower&#160;layers,&#160;and&#160;the&#160;POS&#160;of&#160;its&#160;syn-<br/>
has&#160;been&#160;no&#160;research&#160;showing&#160;how&#160;these&#160;en-<br/>
tactic&#160;parent&#160;is&#160;encoded&#160;by&#160;higher&#160;layers;&#160;while<br/>
codings&#160;arise&#160;as&#160;the&#160;models&#160;are&#160;trained.&#160;We<br/>present&#160;the&#160;first&#160;study&#160;on&#160;the&#160;learning&#160;dy-<br/>
<a href="1811.00225v3s.html#9">Belinkov&#160;et&#160;al.&#160;(2018)&#160;</a>found&#160;that&#160;POS&#160;is&#160;encoded<br/>
namics&#160;of&#160;neural&#160;language&#160;models,&#160;using&#160;a<br/>
by&#160;lower&#160;layers&#160;and&#160;semantic&#160;category&#160;is&#160;encoded<br/>
simple&#160;and&#160;flexible&#160;analysis&#160;method&#160;called<br/>
by&#160;higher&#160;layers.&#160;More&#160;generally,&#160;the&#160;most&#160;useful<br/>
Singular&#160;Vector&#160;Canonical&#160;Correlation&#160;Anal-<br/>
layer&#160;for&#160;an&#160;arbitrary&#160;NLP&#160;task&#160;seems&#160;to&#160;depend&#160;on<br/>
ysis&#160;(SVCCA),&#160;which&#160;enables&#160;us&#160;to&#160;compare<br/>
how&#160;“high-level”&#160;the&#160;task&#160;is&#160;<a href="1811.00225v3s.html#10">(Peters&#160;et&#160;al.,&#160;2018).</a><br/>
learned&#160;representations&#160;across&#160;time&#160;and&#160;across<br/>
Since&#160;we&#160;know&#160;that&#160;lower&#160;layers&#160;in&#160;a&#160;multi-layer<br/>
models,&#160;without&#160;the&#160;need&#160;to&#160;evaluate&#160;directly<br/>
model&#160;converge&#160;to&#160;their&#160;final&#160;representations&#160;more<br/>
on&#160;annotated&#160;data.&#160;We&#160;probe&#160;the&#160;evolution&#160;of<br/>
quickly&#160;than&#160;higher&#160;layers&#160;<a href="1811.00225v3s.html#10">(Raghu&#160;et&#160;al.,&#160;2017),&#160;</a>it<br/>
syntactic,&#160;semantic,&#160;and&#160;topic&#160;representations<br/>and&#160;find&#160;that&#160;part-of-speech&#160;is&#160;learned&#160;earlier<br/>
is&#160;likely&#160;that&#160;models&#160;learn&#160;local&#160;lexical&#160;categories<br/>
than&#160;topic;&#160;that&#160;recurrent&#160;layers&#160;become&#160;more<br/>
like&#160;POS&#160;earlier&#160;than&#160;they&#160;learn&#160;higher-level&#160;lin-<br/>
similar&#160;to&#160;those&#160;of&#160;a&#160;tagger&#160;during&#160;training;<br/>
guistic&#160;categories&#160;like&#160;semantic&#160;class.<br/>
and&#160;embedding&#160;layers&#160;less&#160;similar.&#160;Our&#160;results<br/>
How&#160;and&#160;when&#160;do&#160;neural&#160;representations&#160;come<br/>
and&#160;methods&#160;could&#160;inform&#160;better&#160;learning&#160;al-<br/>
to&#160;encode&#160;specific&#160;linguistic&#160;categories?&#160;Answers<br/>
gorithms&#160;for&#160;NLP&#160;models,&#160;possibly&#160;to&#160;incor-<br/>
could&#160;explain&#160;why&#160;neural&#160;models&#160;work&#160;and&#160;help&#160;us<br/>
porate&#160;linguistic&#160;information&#160;more&#160;effectively.<br/>
improve&#160;learning&#160;algorithms.&#160;We&#160;investigate&#160;how<br/>
1<br/>
Introduction<br/>
representations&#160;of&#160;linguistic&#160;structure&#160;are&#160;learned<br/>over&#160;time&#160;in&#160;neural&#160;language&#160;models&#160;(LMs),&#160;which<br/>
Large&#160;neural&#160;networks&#160;have&#160;a&#160;notorious&#160;capacity<br/>
are&#160;central&#160;to&#160;NLP:&#160;on&#160;their&#160;own,&#160;they&#160;are&#160;used<br/>
to&#160;memorize&#160;training&#160;data&#160;<a href="1811.00225v3s.html#10">(Zhang&#160;et&#160;al.,&#160;2016),</a><br/>
to&#160;produce&#160;contextual&#160;representations&#160;of&#160;words&#160;for<br/>
but&#160;their&#160;high&#160;accuracy&#160;on&#160;many&#160;NLP&#160;tasks&#160;shows<br/>
many&#160;tasks&#160;(e.g.&#160;<a href="1811.00225v3s.html#10">Peters&#160;et&#160;al.,&#160;2018);&#160;</a>while&#160;con-<br/>
that&#160;they&#160;nonetheless&#160;generalize.&#160;One&#160;apparent&#160;ex-<br/>
ditional&#160;LMs&#160;power&#160;machine&#160;translation,&#160;speech<br/>
planation&#160;for&#160;their&#160;performance&#160;is&#160;that&#160;they&#160;learn<br/>
recognition,&#160;and&#160;dialogue&#160;systems.&#160;We&#160;use&#160;a&#160;sim-<br/>
linguistic&#160;generalizations&#160;even&#160;without&#160;explicit&#160;su-<br/>
ple&#160;and&#160;flexible&#160;method,&#160;Singular&#160;Vector&#160;Canon-<br/>
arXiv:1811.00225v3 &#160;[cs.CL] &#160;3 Apr 2019<br/>
pervision&#160;for&#160;those&#160;generalizations—for&#160;example,<br/>
ical&#160;Correlation&#160;Analysis&#160;(SVCCA;&#160;<a href="1811.00225v3s.html#10">Raghu&#160;et&#160;al.,</a><br/>
that&#160;subject&#160;and&#160;verb&#160;number&#160;agree&#160;in&#160;English<br/>
<a href="1811.00225v3s.html#10">2017),&#160;</a>which&#160;allows&#160;us&#160;to&#160;compare&#160;representa-<br/>
<a href="1811.00225v3s.html#10">(Linzen&#160;et&#160;al.,&#160;2016);&#160;</a>that&#160;derivational&#160;suffixes&#160;at-<br/>
tions&#160;from&#160;our&#160;LM&#160;at&#160;each&#160;epoch&#160;of&#160;training&#160;with<br/>
tach&#160;to&#160;only&#160;specific&#160;parts&#160;of&#160;speech&#160;<a href="1811.00225v3s.html#10">(Kementched-</a><br/>
representations&#160;of&#160;other&#160;models&#160;trained&#160;to&#160;predict<br/>
<a href="1811.00225v3s.html#10">jhieva&#160;and&#160;Lopez,&#160;2018);&#160;</a>and&#160;that&#160;short&#160;segments<br/>
specific&#160;linguistic&#160;categories.<br/>
We&#160;discover&#160;that<br/>
of&#160;speech&#160;form&#160;natural&#160;clusters&#160;corresponding&#160;to<br/>
lower&#160;layers&#160;initially&#160;discover&#160;features&#160;shared&#160;by<br/>
phonemes&#160;<a href="1811.00225v3s.html#9">(Alishahi&#160;et&#160;al.,&#160;2017).&#160;</a>These&#160;studies<br/>
all&#160;predictive&#160;models,&#160;but&#160;lose&#160;these&#160;features&#160;as&#160;the<br/>
tell&#160;us&#160;that&#160;neural&#160;models&#160;learn&#160;to&#160;implicitly&#160;rep-<br/>
LM&#160;explores&#160;more&#160;specific&#160;clusters.&#160;We&#160;demon-<br/>
resent&#160;linguistic&#160;categories&#160;and&#160;their&#160;interactions.<br/>
strate&#160;that&#160;different&#160;aspects&#160;of&#160;linguistic&#160;structure<br/>
But&#160;how&#160;do&#160;they&#160;learn&#160;these&#160;representations?<br/>
are&#160;learned&#160;at&#160;different&#160;rates&#160;within&#160;a&#160;single&#160;recur-<br/>
One&#160;clue&#160;comes&#160;from&#160;the&#160;inspection&#160;of&#160;multi-<br/>
rent&#160;layer,&#160;acquiring&#160;POS&#160;tags&#160;early&#160;but&#160;continuing<br/>
layer&#160;models,&#160;which&#160;seem&#160;to&#160;encode&#160;lexical&#160;cate-<br/>
to&#160;learn&#160;global&#160;topic&#160;information&#160;later&#160;in&#160;training.<br/>
<hr/>
<a name=2></a>2<br/>
Methods<br/>
and&#160;B&#160;∈&#160;RN×dB&#160;.&#160;We&#160;project&#160;these&#160;views&#160;onto&#160;a<br/>shared&#160;subspace&#160;in&#160;two&#160;steps:<br/>
Our&#160;experiments&#160;require&#160;a&#160;LM,&#160;tagging&#160;models,<br/>and&#160;a&#160;method&#160;to&#160;inspect&#160;the&#160;models:&#160;SVCCA.<br/>
1.&#160;Use&#160;Singular&#160;Value&#160;Decomposition&#160;(SVD)&#160;to<br/>
reduce&#160;matrices&#160;A&#160;and&#160;B&#160;to&#160;lower&#160;dimen-<br/>
2.1<br/>
Language&#160;model<br/>
sional&#160;matrices&#160;A0&#160;and&#160;B0,&#160;respectively.&#160;This<br/>
We&#160;model&#160;the&#160;probability&#160;distribution&#160;over&#160;a&#160;se-<br/>
is&#160;necessary&#160;because&#160;many&#160;dimensions&#160;in&#160;the<br/>
quence&#160;of&#160;tokens&#160;x1&#160;.&#160;.&#160;.&#160;x|x|&#160;with&#160;a&#160;conventional<br/>
representations&#160;are&#160;noisy,&#160;and&#160;in&#160;fact&#160;cancel<br/>
two-layer&#160;LSTM&#160;LM.&#160;The&#160;pipeline&#160;from&#160;input&#160;xt<br/>
each&#160;other&#160;out&#160;<a href="1811.00225v3s.html#10">(Frankle&#160;and&#160;Carbin,&#160;2018).</a><br/>
at&#160;time&#160;step&#160;t&#160;to&#160;a&#160;distribution&#160;over&#160;xt+1&#160;is&#160;de-<br/>
SVD&#160;removes&#160;dimensions&#160;that&#160;were&#160;likely&#160;to<br/>
scribed&#160;in&#160;Formulae&#160;<a href="1811.00225v3s.html#2">(1)–(4).&#160;</a>At&#160;time&#160;step&#160;t,&#160;input<br/>
be&#160;less&#160;important&#160;in&#160;the&#160;original&#160;representa-<br/>
word&#160;xt&#160;is&#160;embedded&#160;as&#160;<a href="1811.00225v3s.html#2">(1)&#160;</a>het,&#160;which&#160;is&#160;input&#160;to<br/>
tions&#160;from&#160;A&#160;and&#160;B,&#160;and&#160;in&#160;keeping&#160;with<br/>
a&#160;two-layer&#160;LSTM,&#160;producing&#160;outputs&#160;<a href="1811.00225v3s.html#2">(2)&#160;</a>h1t&#160;and<br/>
<a href="1811.00225v3s.html#10">Raghu&#160;et&#160;al.&#160;(2017),&#160;</a>we&#160;retain&#160;enough&#160;dimen-<br/>
<a href="1811.00225v3s.html#2">(3)&#160;</a>h2t&#160;at&#160;these&#160;layers,&#160;along&#160;with&#160;cell&#160;states&#160;c1t&#160;and<br/>
sions&#160;to&#160;keep&#160;99%&#160;of&#160;the&#160;variance&#160;in&#160;the&#160;data.<br/>
c2t.&#160;A&#160;softmax&#160;layer&#160;converts&#160;h2t&#160;to&#160;a&#160;distribution<br/>from&#160;which&#160;<a href="1811.00225v3s.html#2">(4)&#160;</a>ˆ<br/>
xt+1&#160;is&#160;sampled.<br/>
2.&#160;Use&#160;Canonical&#160;Correlation&#160;Analysis&#160;(CCA)<br/>
to&#160;project&#160;A0&#160;and&#160;B0&#160;onto&#160;a&#160;shared&#160;sub-<br/>
het&#160;=&#160;embedding(xt)<br/>
(1)<br/>
space,&#160;maximizing&#160;the&#160;correlation&#160;of&#160;the&#160;pro-<br/>
h1<br/>
jections.&#160;Formally,&#160;CCA&#160;identifies&#160;vectors<br/>
t&#160;,&#160;c1<br/>
t<br/>
=<br/>
LSTM1(het,&#160;h1t−1,&#160;c1t−1)<br/>
(2)<br/>
h2<br/>
w,&#160;v&#160;to&#160;maximize&#160;ρ&#160;=&#160;&lt;w&gt;A0,v&gt;B0&gt;&#160;.&#160;We<br/>
t&#160;,&#160;c2<br/>
t<br/>
=<br/>
LSTM2(h1t,&#160;h2t−1,&#160;c2t−1)<br/>
(3)<br/>
kw&gt;A0kkv&gt;B0k<br/>
ˆ<br/>
x<br/>
treat&#160;these&#160;w,&#160;v&#160;as&#160;new&#160;basis&#160;vectors,&#160;comput-<br/>
t+1<br/>
∼&#160;softmax(h2t)<br/>
(4)<br/>
ing&#160;the&#160;top&#160;dC&#160;(a&#160;hyperparameter)&#160;such&#160;ba-<br/>
Each&#160;function&#160;can&#160;be&#160;thought&#160;of&#160;as&#160;a&#160;representa-<br/>
sis&#160;vectors&#160;to&#160;form&#160;projection&#160;matrices&#160;W&#160;∈<br/>
tion&#160;or&#160;embedding&#160;of&#160;its&#160;discrete&#160;input;&#160;hence&#160;he<br/>
RdC×dA0&#160;,&#160;V&#160;∈&#160;RdC×dA0&#160;.&#160;The&#160;resulting&#160;pro-<br/>
t&#160;is<br/>
a&#160;representation&#160;of&#160;x<br/>
jections&#160;W&#160;A0&#160;and&#160;V&#160;B0&#160;map&#160;onto&#160;a&#160;shared<br/>
t,&#160;and—due&#160;to&#160;the&#160;recursion<br/>
in&#160;<a href="1811.00225v3s.html#2">(2)—</a>h1<br/>
subspace&#160;where&#160;the&#160;representations&#160;of&#160;each<br/>
t&#160;is&#160;a&#160;representation&#160;of&#160;x1&#160;.&#160;.&#160;.&#160;xt.<br/>
datapoint&#160;from&#160;A0&#160;and&#160;B0&#160;are&#160;maximally&#160;cor-<br/>
2.2<br/>
Tagging&#160;models<br/>
related.<br/>
To&#160;inspect&#160;our&#160;language&#160;model&#160;for&#160;learned&#160;linguis-<br/>tic&#160;categories,&#160;we&#160;will&#160;use&#160;a&#160;collection&#160;of&#160;tagging<br/>
Intuitively,&#160;the&#160;correlation&#160;ρ&#160;will&#160;be&#160;high&#160;if&#160;both<br/>
models,&#160;designed&#160;to&#160;mimic&#160;the&#160;behavior&#160;of&#160;our&#160;lan-<br/>
representations&#160;encode&#160;the&#160;same&#160;information,&#160;and<br/>
guage&#160;model&#160;but&#160;predicting&#160;the&#160;next&#160;tag&#160;rather&#160;than<br/>
low&#160;if&#160;they&#160;encode&#160;unrelated&#160;information.&#160;Figure&#160;<a href="1811.00225v3s.html#3">1</a><br/>
the&#160;next&#160;word.&#160;Given&#160;x<br/>
illustrates&#160;how&#160;we&#160;use&#160;SVCCA&#160;to&#160;compare&#160;repre-<br/>
1&#160;.&#160;.&#160;.&#160;x|x|,&#160;we&#160;model&#160;a&#160;corre-<br/>
sponding&#160;sequence&#160;of&#160;tags&#160;y<br/>
sentation&#160;h2<br/>
1&#160;.&#160;.&#160;.&#160;y|<br/>
t&#160;of&#160;our&#160;language&#160;model&#160;with&#160;the&#160;recur-<br/>
x|&#160;using&#160;a&#160;one-<br/>
0<br/>
layer&#160;LSTM.&#160;(Our&#160;limited&#160;labeled&#160;data&#160;made&#160;this<br/>
rent&#160;representation&#160;of&#160;a&#160;tagger,&#160;h1t&#160;.&#160;In&#160;practice,&#160;we<br/>
more&#160;accurate&#160;on&#160;topic&#160;tagging&#160;than&#160;another&#160;two-<br/>
run&#160;over&#160;all&#160;time&#160;steps&#160;in&#160;a&#160;test&#160;corpus,&#160;rather&#160;than<br/>
layer&#160;LSTM,&#160;so&#160;this&#160;architecture&#160;does&#160;not&#160;directly<br/>
a&#160;single&#160;time&#160;step&#160;as&#160;illustrated.<br/>
parallel&#160;the&#160;LM.)<br/>
3<br/>
Experimental&#160;Setup<br/>
he0<br/>
t<br/>
=<br/>
embedding0(xt)<br/>
(5)<br/>
We&#160;trained&#160;our&#160;LM&#160;on&#160;a&#160;corpus&#160;of&#160;tok-<br/>
h10<br/>
0<br/>
0<br/>
0<br/>
0<br/>
t&#160;,&#160;c1<br/>
t<br/>
=<br/>
LSTM0(het&#160;,&#160;h1t−1&#160;,&#160;c1t−1&#160;)<br/>
(6)<br/>
enized,&#160;lowercased&#160;English&#160;Wikipedia&#160;(70/10/20<br/>
ˆ<br/>
y<br/>
0<br/>
train/dev/test&#160;split).<br/>
To&#160;reduce&#160;the&#160;number&#160;of<br/>
t+1<br/>
∼&#160;softmax0(h1t&#160;)<br/>
(7)<br/>
unique&#160;words&#160;in&#160;the&#160;corpus,&#160;we&#160;excluded&#160;any&#160;sen-<br/>
We&#160;will&#160;also&#160;discuss&#160;input&#160;taggers,&#160;which&#160;share<br/>
tence&#160;with&#160;a&#160;word&#160;type&#160;appearing&#160;fewer&#160;than&#160;100<br/>
this&#160;architecture&#160;but&#160;instead&#160;sample&#160;yt,&#160;the&#160;tag&#160;of<br/>
times.&#160;Words&#160;appearing&#160;fewer&#160;than&#160;100&#160;times&#160;in<br/>
the&#160;most&#160;recently&#160;observed&#160;word.<br/>
the&#160;resulting&#160;training&#160;set&#160;are&#160;replaced&#160;with&#160;an&#160;un-<br/>known&#160;token.&#160;The&#160;resulting&#160;training&#160;set&#160;has&#160;over<br/>
2.3<br/>
SVCCA<br/>
227&#160;million&#160;tokens&#160;of&#160;20K&#160;types.<br/>
SVCCA&#160;is&#160;a&#160;general&#160;method&#160;to&#160;compare&#160;the&#160;cor-<br/>
We&#160;train&#160;for&#160;50&#160;epochs&#160;to&#160;maximize&#160;cross-<br/>
relation&#160;of&#160;two&#160;vector&#160;representations.&#160;Let&#160;dA&#160;and<br/>
entropy,&#160;using&#160;a&#160;batch&#160;size&#160;of&#160;40,&#160;dropout&#160;ratio<br/>
dB&#160;be&#160;their&#160;dimensions.&#160;For&#160;N&#160;data&#160;points&#160;we&#160;have<br/>
of&#160;0.2,&#160;and&#160;sequence&#160;length&#160;of&#160;35.&#160;The&#160;optimizer<br/>
two&#160;distinct&#160;views,&#160;given&#160;by&#160;matrices&#160;A&#160;∈&#160;RN×dA<br/>
is&#160;standard&#160;SGD&#160;with&#160;clipped&#160;gradients&#160;at&#160;0.25,<br/>
<hr/>
<a name=3></a><img src="1811.00225v3-3_1.png"/><br/>
Language&#160;model<br/>
xt+1<br/>
Tag&#160;Predictor<br/>
softmax<br/>
yt+1<br/>
SVD(h2)<br/>
SVD<br/>
h2t<br/>
softmax<br/>
SVD(h10)<br/>
SVD<br/>
L<br/>
0<br/>
STM<br/>
h1t<br/>
h1t<br/>
LSTM<br/>
L<br/>
0<br/>
STM<br/>
het<br/>
het<br/>
embedding<br/>
embedding<br/>
xt<br/>
max&#160;ρ(W&#160;·&#160;SVD(h2),&#160;V&#160;·&#160;SVD(h10))<br/>
xt<br/>
W,V<br/>
Figure&#160;1:&#160;SVCCA&#160;used&#160;to&#160;compare&#160;the&#160;layer&#160;h2&#160;of&#160;a&#160;language&#160;model&#160;and&#160;layer&#160;h10&#160;of&#160;a&#160;tagger.<br/>
Tag<br/>
These<br/>
cats<br/>
live<br/>
in<br/>
that<br/>
house<br/>
.<br/>
UDP&#160;POS<br/>
DET<br/>
NOUN<br/>
VERB<br/>
ADP<br/>
DET<br/>
NOUN<br/>
SYM<br/>
PTB&#160;POS<br/>
DT<br/>
NNS<br/>
VBP<br/>
IN<br/>
DT<br/>
NN<br/>
.<br/>
SEM&#160;(coarse)<br/>
DEM<br/>
ENT<br/>
EVE<br/>
ATT<br/>
DEM<br/>
ENT<br/>
LOG<br/>
SEM&#160;(fine)<br/>
PRX<br/>
CON<br/>
ENS<br/>
REL<br/>
DST<br/>
CON<br/>
NIL<br/>
topic<br/>
pets<br/>
pets<br/>
pets<br/>
pets<br/>
pets<br/>
pets<br/>
pets<br/>
Table&#160;1:&#160;An&#160;annotated&#160;example&#160;sentence&#160;from&#160;the&#160;article&#160;pets,&#160;based&#160;on&#160;an&#160;example&#160;from&#160;<a href="1811.00225v3s.html#9">Bjerva&#160;et&#160;al.&#160;(2016).</a><br/>
POS&#160;tagging<br/>
For&#160;syntactic&#160;categories,&#160;we&#160;use<br/>
POS&#160;tags,&#160;as&#160;in&#160;<a href="1811.00225v3s.html#9">Belinkov&#160;et&#160;al.&#160;(2017).</a><br/>
As&#160;a<br/>
coarse-grained&#160;tagset,&#160;we&#160;use&#160;silver&#160;Universal&#160;De-<br/>pendency&#160;Parse&#160;(UDP)&#160;POS&#160;tags&#160;automatically<br/>added&#160;to&#160;our&#160;Wikipedia&#160;corpus&#160;with&#160;spacy<a href="1811.00225v3s.html#3">.1&#160;</a>We<br/>also&#160;use&#160;a&#160;corpus&#160;of&#160;fine-grained&#160;human&#160;anno-<br/>tated&#160;Penn&#160;Treebank&#160;POS&#160;tags&#160;from&#160;the&#160;Groningen<br/>
Figure&#160;2:&#160;Test&#160;performance&#160;of&#160;the&#160;LM.&#160;Vertical&#160;dotted<br/>
Meaning&#160;Bank&#160;(GMB;&#160;<a href="1811.00225v3s.html#9">Bos&#160;et&#160;al.,&#160;2017).</a><br/>
lines&#160;indicate&#160;when&#160;the&#160;optimizer&#160;rescales&#160;the&#160;step&#160;size.<br/>
Semantic&#160;tagging<br/>
We&#160;follow&#160;<a href="1811.00225v3s.html#9">Belinkov&#160;et&#160;al.</a><br/>
<a href="1811.00225v3s.html#9">(2018)&#160;</a>in&#160;representing&#160;word-level&#160;semantic&#160;infor-<br/>
with&#160;the&#160;learning&#160;rate&#160;quartered&#160;when&#160;validation<br/>
mation&#160;with&#160;silver&#160;SEM&#160;tags&#160;<a href="1811.00225v3s.html#9">(Bjerva&#160;et&#160;al.,&#160;2016).</a><br/>
loss&#160;increases.&#160;The&#160;result&#160;of&#160;training&#160;is&#160;shown&#160;in<br/>
SEM&#160;tags&#160;disambiguate&#160;POS&#160;tags&#160;in&#160;ways&#160;that&#160;are<br/>
Figure&#160;<a href="1811.00225v3s.html#3">2,&#160;</a>which&#160;illustrates&#160;the&#160;dips&#160;in&#160;loss&#160;when<br/>
relevant&#160;to&#160;multilingual&#160;settings.&#160;For&#160;example,&#160;the<br/>
learning&#160;rate&#160;changes.&#160;All&#160;experiments&#160;on&#160;the&#160;LM<br/>
comma&#160;is&#160;not&#160;assigned&#160;a&#160;single&#160;tag&#160;as&#160;punctua-<br/>
throughout&#160;training&#160;are&#160;conducted&#160;by&#160;running&#160;the<br/>
tion,&#160;but&#160;has&#160;distinct&#160;tags&#160;according&#160;to&#160;its&#160;function:<br/>
model&#160;at&#160;the&#160;end&#160;of&#160;each&#160;epoch&#160;in&#160;inference&#160;mode<br/>
conjunction,&#160;disjunction,&#160;or&#160;apposition.&#160;The&#160;66<br/>
over&#160;the&#160;test&#160;corpus.<br/>
fine-grained&#160;SEM&#160;tag&#160;classes&#160;fall&#160;under&#160;13&#160;coarse-<br/>grained&#160;tags,&#160;and&#160;an&#160;‘unknown’&#160;tag.<br/>
3.1<br/>
Taggers<br/>
Global&#160;topic<br/>
For&#160;topic,&#160;we&#160;classify&#160;each&#160;word<br/>
of&#160;the&#160;sequence&#160;by&#160;its&#160;source&#160;Wikipedia&#160;article;<br/>
To&#160;understand&#160;the&#160;representations&#160;learned&#160;by&#160;our<br/>
for&#160;example,&#160;every&#160;word&#160;in&#160;the&#160;wikipedia&#160;article<br/>
LM,&#160;we&#160;compare&#160;them&#160;with&#160;the&#160;internal&#160;represen-<br/>
on&#160;Trains&#160;is&#160;labeled&#160;“Trains”.&#160;This&#160;task&#160;assesses<br/>
tations&#160;of&#160;tagging&#160;models,&#160;using&#160;SVCCA.&#160;Where<br/>
whether&#160;the&#160;network&#160;encodes&#160;the&#160;global&#160;topic&#160;of<br/>
possible,&#160;we&#160;use&#160;coarse-grained&#160;and&#160;fine-grained<br/>
the&#160;sentence.<br/>
tagsets&#160;to&#160;account&#160;for&#160;effects&#160;from&#160;the&#160;size&#160;of&#160;the<br/>tagset.&#160;Table&#160;<a href="1811.00225v3s.html#3">1&#160;</a>illustrates&#160;our&#160;tagsets.<br/>
1https://spacy.io/<br/>
<hr/>
<a name=4></a><img src="1811.00225v3-4_1.png"/><br/>
<img src="1811.00225v3-4_2.png"/><br/>
Figure&#160;3:&#160;SVCCA&#160;score&#160;between&#160;representations&#160;at<br/>
Figure&#160;4:&#160;SVCCA&#160;score&#160;between&#160;the&#160;LM&#160;at&#160;each&#160;epoch<br/>
each&#160;epoch&#160;and&#160;from&#160;the&#160;final&#160;trained&#160;LM.<br/>
and&#160;a&#160;LM&#160;with&#160;different&#160;initialization.<br/>
Empirical&#160;upper&#160;bounds.<br/>
Our&#160;main&#160;experi-<br/>
UDP&#160;silver&#160;POS&#160;and&#160;topic&#160;information&#160;use&#160;the<br/>
ments&#160;will&#160;test&#160;the&#160;rate&#160;at&#160;which&#160;different&#160;linguis-<br/>
same&#160;corpus,&#160;taken&#160;from&#160;the&#160;100&#160;longest&#160;articles<br/>
tic&#160;categories&#160;are&#160;learned&#160;by&#160;different&#160;layers,&#160;but<br/>
in&#160;Wikipedia&#160;randomly&#160;partitioned&#160;in&#160;a&#160;70/10/20<br/>
to&#160;interpret&#160;the&#160;results,&#160;we&#160;need&#160;to&#160;understand&#160;the<br/>
train/dev/test&#160;split.&#160;Each&#160;token&#160;is&#160;tagged&#160;with&#160;POS<br/>
behaviour&#160;of&#160;SVCCA&#160;for&#160;these&#160;models.&#160;In&#160;the-<br/>
and&#160;with&#160;the&#160;ID&#160;of&#160;the&#160;source&#160;article.&#160;The&#160;corpus<br/>
ory,&#160;SVCCA&#160;scores&#160;can&#160;vary&#160;from&#160;0&#160;for&#160;no&#160;corre-<br/>
is&#160;taken&#160;from&#160;the&#160;LM&#160;training&#160;data,&#160;which&#160;may&#160;in-<br/>
lation&#160;to&#160;1&#160;for&#160;perfect&#160;correlation.&#160;But&#160;in&#160;practice,<br/>
crease&#160;the&#160;similarity&#160;between&#160;the&#160;tag&#160;model&#160;and<br/>
these&#160;extreme&#160;cases&#160;will&#160;not&#160;occur.&#160;To&#160;establish<br/>
LM.&#160;Because&#160;both&#160;tag&#160;predictors&#160;are&#160;trained&#160;and<br/>
an&#160;empirical&#160;upper&#160;bound&#160;on&#160;correlation,&#160;we&#160;com-<br/>
tested&#160;on&#160;the&#160;same&#160;domain&#160;as&#160;the&#160;LM,&#160;they&#160;can<br/>
pared&#160;the&#160;similarity&#160;at&#160;each&#160;epoch&#160;of&#160;training&#160;to&#160;the<br/>
be&#160;easily&#160;compared&#160;in&#160;terms&#160;of&#160;their&#160;similarity&#160;to<br/>
frozen&#160;final&#160;state&#160;of&#160;a&#160;LM&#160;with&#160;identical&#160;architec-<br/>
the&#160;LM&#160;representation.&#160;Though&#160;the&#160;SEM&#160;corpus<br/>
ture&#160;but&#160;different&#160;initialization,&#160;trained&#160;on&#160;the&#160;same<br/>
and&#160;the&#160;PTB&#160;corpus&#160;are&#160;different&#160;domains&#160;from<br/>
data&#160;(Figure&#160;<a href="1811.00225v3s.html#4">4).2&#160;</a>The&#160;correlations&#160;increase&#160;over<br/>
the&#160;Wikipedia&#160;training&#160;data,&#160;we&#160;compare&#160;their&#160;ac-<br/>
time&#160;as&#160;expected,&#160;but&#160;to&#160;a&#160;maximum&#160;near&#160;0.64;<br/>
tivations&#160;on&#160;the&#160;same&#160;191K-token&#160;100-article&#160;test<br/>
we&#160;don’t&#160;expect&#160;correlations&#160;between&#160;our&#160;LM&#160;and<br/>
corpus.<br/>
other&#160;models&#160;to&#160;exceed&#160;this&#160;value.&#160;We&#160;explore&#160;cor-<br/>
Table&#160;<a href="1811.00225v3s.html#5">2&#160;</a>describes&#160;the&#160;training&#160;and&#160;validation<br/>
responding&#160;lower&#160;bounds&#160;in&#160;our&#160;main&#160;experiments<br/>
corpus&#160;statistics&#160;for&#160;each&#160;tagging&#160;task.&#160;Note&#160;that<br/>
below.<br/>
topic&#160;and&#160;UDP&#160;POS&#160;both&#160;apply&#160;to&#160;the&#160;same&#160;en-<br/>wikipedia&#160;corpus,&#160;but&#160;PTB&#160;POS&#160;and&#160;SEM&#160;use&#160;two<br/>
Correlations&#160;between&#160;different&#160;layers.<br/>
Next<br/>
different&#160;unaligned&#160;sets&#160;from&#160;the&#160;GMB&#160;corpus.<br/>
we&#160;examine&#160;the&#160;correlation&#160;between&#160;different&#160;lay-<br/>ers&#160;of&#160;the&#160;same&#160;model&#160;over&#160;time&#160;(Figure&#160;<a href="1811.00225v3s.html#5">5).&#160;</a>We&#160;ob-<br/>serve&#160;that,&#160;while&#160;over&#160;time&#160;correlation&#160;increases,&#160;in<br/>
4<br/>
Experiments,&#160;Results,&#160;and&#160;Analysis<br/>
general&#160;closer&#160;layers&#160;are&#160;more&#160;similar,&#160;and&#160;they&#160;are<br/>less&#160;correlated&#160;than&#160;they&#160;are&#160;with&#160;the&#160;same&#160;layer&#160;of<br/>
A&#160;benefit&#160;of&#160;SVCCA&#160;is&#160;its&#160;flexibility:&#160;it&#160;can&#160;com-<br/>
a&#160;differently&#160;initialized&#160;model.&#160;This&#160;supports&#160;the<br/>
pute&#160;the&#160;correlation&#160;of&#160;a&#160;hidden&#160;representation&#160;to<br/>
idea&#160;that&#160;we&#160;should&#160;compare&#160;recurrent&#160;layers&#160;with<br/>
any&#160;other&#160;vector.<br/>
<a href="1811.00225v3s.html#10">Raghu&#160;et&#160;al.&#160;(2017)&#160;</a>used&#160;it<br/>
recurrent&#160;layers&#160;because&#160;their&#160;representations&#160;play<br/>
to&#160;understand&#160;learning&#160;dynamics&#160;by&#160;comparing&#160;a<br/>
similar&#160;roles&#160;within&#160;their&#160;respective&#160;architectures.<br/>
learned&#160;representation&#160;to&#160;snapshots&#160;of&#160;the&#160;same<br/>representation&#160;at&#160;different&#160;epochs&#160;during&#160;training.<br/>
SVCCA&#160;vs.&#160;Diagnostic&#160;classifiers<br/>
A&#160;popular<br/>
We&#160;use&#160;a&#160;similar&#160;experiment&#160;to&#160;establish&#160;the&#160;basic<br/>
method&#160;to&#160;analyze&#160;learned&#160;representations&#160;is&#160;to&#160;use<br/>
learning&#160;dynamics&#160;of&#160;our&#160;model.&#160;In&#160;our&#160;shallow<br/>
a&#160;diagnostic&#160;classifier&#160;<a href="1811.00225v3s.html#9">(Belinkov&#160;et&#160;al.,&#160;2017),&#160;</a>a<br/>
2-level&#160;model,&#160;activations&#160;at&#160;h1&#160;converge&#160;slightly<br/>
separate&#160;model&#160;that&#160;is&#160;trained&#160;to&#160;predict&#160;a&#160;linguistic<br/>
after&#160;h2&#160;(Figure&#160;<a href="1811.00225v3s.html#4">3).&#160;</a>This&#160;differs&#160;from&#160;the&#160;results<br/>
category&#160;of&#160;interest,&#160;yt,&#160;from&#160;an&#160;arbitrary&#160;hidden<br/>
of&#160;<a href="1811.00225v3s.html#10">Raghu&#160;et&#160;al.&#160;(2017),&#160;</a>who&#160;found&#160;that&#160;a&#160;5-layer<br/>
layer&#160;ht.&#160;Diagnostic&#160;classifiers&#160;are&#160;widely&#160;used<br/>
stacked&#160;LSTM&#160;LM&#160;exhibits&#160;faster&#160;convergence&#160;at<br/>
<a href="1811.00225v3s.html#9">(Belinkov&#160;et&#160;al.,&#160;2018;&#160;</a><a href="1811.00225v3s.html#10">Giulianelli&#160;et&#160;al.,&#160;2018).</a><br/>
lower&#160;layers,&#160;but&#160;this&#160;difference&#160;may&#160;be&#160;attributed<br/>
But&#160;if&#160;a&#160;diagnostic&#160;classifier&#160;is&#160;trained&#160;on&#160;enough<br/>
to&#160;our&#160;much&#160;larger&#160;training&#160;data,&#160;which&#160;gives&#160;our<br/>
2This&#160;experiment&#160;is&#160;similar&#160;to&#160;the&#160;comparisons&#160;of&#160;ran-<br/>
model&#160;sufficient&#160;training&#160;data&#160;at&#160;early&#160;epochs.<br/>
domly&#160;initialized&#160;models&#160;by&#160;<a href="1811.00225v3s.html#10">Morcos&#160;et&#160;al.&#160;(2018).</a><br/>
<hr/>
<a name=5></a><img src="1811.00225v3-5_1.png"/><br/>
<img src="1811.00225v3-5_2.png"/><br/>
number<br/>
token&#160;count<br/>
label&#160;t&#160;+&#160;1<br/>
label&#160;t<br/>
randomized<br/>
tag<br/>
corpus<br/>
of&#160;classes<br/>
train<br/>
dev<br/>
acc<br/>
ppl<br/>
acc<br/>
ppl<br/>
acc<br/>
ppl<br/>
UDP&#160;POS<br/>
wiki<br/>
17<br/>
665K<br/>
97K<br/>
50<br/>
4.3<br/>
93<br/>
1.2<br/>
21<br/>
8.9<br/>
PTB&#160;POS<br/>
GMB<br/>
36<br/>
943K<br/>
136K<br/>
51<br/>
4.7<br/>
95<br/>
1.18<br/>
14<br/>
18.0<br/>
SEM&#160;(coarse)<br/>
GMB<br/>
14<br/>
937K<br/>
132K<br/>
55<br/>
3.5<br/>
91<br/>
1.3<br/>
22<br/>
9.0<br/>
SEM&#160;(fine)<br/>
GMB<br/>
67<br/>
937K<br/>
132K<br/>
50<br/>
5.6<br/>
88<br/>
1.45<br/>
17<br/>
21.5<br/>
topic<br/>
wiki<br/>
100<br/>
665K<br/>
97K<br/>
36<br/>
19.1<br/>
37<br/>
16.3<br/>
5<br/>
81.6<br/>
Table&#160;2:&#160;Tag&#160;predictor&#160;and&#160;tagger&#160;statistics.&#160;Accuracy&#160;and&#160;perplexity&#160;on&#160;t&#160;+&#160;1&#160;are&#160;from&#160;the&#160;target&#160;tag&#160;predictor,<br/>on&#160;t&#160;are&#160;from&#160;the&#160;input&#160;tagger.&#160;Metrics&#160;obtained&#160;when&#160;training&#160;on&#160;randomly&#160;shuffled&#160;labels&#160;are&#160;provided&#160;as&#160;a&#160;low<br/>baseline.&#160;Accuracy&#160;is&#160;on&#160;the&#160;test&#160;set&#160;from&#160;the&#160;training&#160;domain&#160;(GMB&#160;or&#160;Wikipedia).<br/>
Figure&#160;5:&#160;SVCCA&#160;score&#160;between&#160;different&#160;layers&#160;of&#160;the<br/>LM&#160;at&#160;each&#160;epoch.&#160;For&#160;example,&#160;ρ(h2,&#160;h1)&#160;compares<br/>the&#160;activations&#160;h2&#160;with&#160;the&#160;activations&#160;h1.<br/>
examples,&#160;then&#160;random&#160;embeddings&#160;as&#160;input&#160;rep-<br/>
Figure&#160;6:&#160;Learning&#160;dynamics&#160;interpreted&#160;with&#160;diagnos-<br/>
resentations&#160;often&#160;outperform&#160;any&#160;pretrained&#160;in-<br/>
tic&#160;classifiers&#160;labeling&#160;input&#160;word&#160;tag&#160;yt.<br/>
termediate&#160;representation&#160;(<a href="1811.00225v3s.html#10">?Zhang&#160;and&#160;Bowman,<br/>2018).</a><br/>
This&#160;suggests&#160;that&#160;diagnostic&#160;classifiers<br/>
may&#160;work&#160;simply&#160;by&#160;memorizing&#160;the&#160;associa-<br/>
Another&#160;distinction&#160;from&#160;the&#160;typical&#160;use&#160;of&#160;diag-<br/>
tion&#160;between&#160;an&#160;embedding&#160;and&#160;the&#160;most&#160;frequent<br/>
nostic&#160;classifiers&#160;is&#160;that&#160;probes&#160;are&#160;usually&#160;used&#160;to<br/>
output&#160;category&#160;associated&#160;with&#160;that&#160;embedding;<br/>
decode&#160;tag&#160;information&#160;about&#160;the&#160;context&#160;or&#160;most<br/>
since&#160;for&#160;many&#160;words&#160;their&#160;category&#160;is&#160;(empiri-<br/>
recent&#160;input&#160;from&#160;the&#160;hidden&#160;state&#160;at&#160;the&#160;current<br/>
cally)&#160;unambiguous,&#160;this&#160;may&#160;give&#160;an&#160;inflated&#160;view<br/>
step.&#160;Because&#160;the&#160;hidden&#160;representation&#160;at&#160;time<br/>
of&#160;just&#160;how&#160;much&#160;a&#160;model&#160;“understands”&#160;about<br/>
t&#160;is&#160;meant&#160;to&#160;encode&#160;predictive&#160;information&#160;about<br/>
that&#160;category.<br/>
the&#160;target&#160;word&#160;at&#160;time&#160;t+1,&#160;we&#160;treat&#160;it&#160;as&#160;encoding<br/>
Our&#160;use&#160;of&#160;SVCCA&#160;below&#160;will&#160;differ&#160;from&#160;the<br/>
a&#160;prediction&#160;about&#160;the&#160;tag&#160;of&#160;the&#160;target&#160;word.<br/>
use&#160;of&#160;diagnostic&#160;classifiers&#160;in&#160;an&#160;important&#160;way.<br/>
To&#160;understand&#160;the&#160;empirical&#160;strengths&#160;and<br/>
Diagnostic&#160;classifiers&#160;use&#160;the&#160;intermediate&#160;repre-<br/>
weaknesses&#160;of&#160;these&#160;approaches,&#160;we&#160;compare&#160;the<br/>
sentations&#160;of&#160;the&#160;LM&#160;as&#160;inputs&#160;to&#160;a&#160;tagger.&#160;A&#160;repre-<br/>
use&#160;of&#160;SVCCA&#160;and&#160;diagnostic&#160;classifiers&#160;in&#160;under-<br/>
sentation&#160;is&#160;claimed&#160;to&#160;encode,&#160;for&#160;example,&#160;POS<br/>
standing&#160;learning&#160;dynamics.&#160;In&#160;other&#160;words,&#160;we<br/>
if&#160;the&#160;classifier&#160;accurately&#160;predicts&#160;it—in&#160;other<br/>
ask:&#160;is&#160;our&#160;first&#160;conceptual&#160;shift&#160;(to&#160;SVCCA)&#160;nec-<br/>
words,&#160;whether&#160;it&#160;can&#160;decode&#160;it&#160;from&#160;the&#160;repre-<br/>
essary?&#160;To&#160;test&#160;this,&#160;we&#160;use&#160;the&#160;same&#160;model&#160;as&#160;<a href="1811.00225v3s.html#9">Be-</a><br/>
sentation.&#160;We&#160;will&#160;instead&#160;evaluate&#160;the&#160;similarity<br/>
<a href="1811.00225v3s.html#9">linkov&#160;et&#160;al.&#160;(2017),&#160;</a>which&#160;classifies&#160;an&#160;arbitrary<br/>
between&#160;the&#160;representations&#160;in&#160;an&#160;LM&#160;and&#160;in&#160;an<br/>
representation&#160;using&#160;a&#160;ReLU&#160;followed&#160;by&#160;a&#160;soft-<br/>
independently-trained&#160;tagger.&#160;The&#160;intuition&#160;behind<br/>
max&#160;layer.&#160;To&#160;be&#160;consistent&#160;with&#160;<a href="1811.00225v3s.html#9">Belinkov&#160;et&#160;al.</a><br/>
this&#160;is&#160;that,&#160;if&#160;the&#160;representation&#160;of&#160;our&#160;LM&#160;encodes<br/>
<a href="1811.00225v3s.html#9">(2017),&#160;</a>we&#160;use&#160;yt&#160;as&#160;their&#160;target&#160;label.&#160;We&#160;repeat<br/>
a&#160;particular&#160;category,&#160;then&#160;it&#160;must&#160;be&#160;similar&#160;to&#160;the<br/>
their&#160;method&#160;in&#160;this&#160;manner&#160;(Figure&#160;<a href="1811.00225v3s.html#5">6)&#160;</a>as&#160;well&#160;as<br/>
representation&#160;of&#160;model&#160;that&#160;is&#160;specifically&#160;trained<br/>
applying&#160;our&#160;second&#160;modification,&#160;in&#160;which&#160;we&#160;in-<br/>
to&#160;predict&#160;that&#160;category.&#160;A&#160;benefit&#160;of&#160;the&#160;approach<br/>
stead&#160;target&#160;the&#160;label&#160;yt+1&#160;(Figure&#160;<a href="1811.00225v3s.html#6">7).</a><br/>
is&#160;that&#160;similarity&#160;can&#160;be&#160;evaluated&#160;on&#160;any&#160;dataset,<br/>
We&#160;found&#160;the&#160;correlations&#160;to&#160;be&#160;relatively&#160;stable<br/>
not&#160;only&#160;one&#160;that&#160;has&#160;been&#160;labeled&#160;with&#160;the&#160;linguis-<br/>
over&#160;the&#160;course&#160;of&#160;training.&#160;This&#160;is&#160;at&#160;odds&#160;with<br/>
tic&#160;categories&#160;of&#160;interest.<br/>
the&#160;results&#160;in&#160;Figures&#160;<a href="1811.00225v3s.html#3">2&#160;</a>and&#160;<a href="1811.00225v3s.html#4">3,&#160;</a>which&#160;suggest&#160;that<br/>
<hr/>
<a name=6></a><img src="1811.00225v3-6_1.png"/><br/>
<img src="1811.00225v3-6_2.png"/><br/>
<img src="1811.00225v3-6_3.png"/><br/>
<img src="1811.00225v3-6_4.png"/><br/>
Figure&#160;7:&#160;Learning&#160;dynamics&#160;interpreted&#160;with&#160;diagnos-<br/>tic&#160;classifiers&#160;labeling&#160;target&#160;word&#160;tag&#160;yt+1.<br/>
representations&#160;change&#160;substantially&#160;during&#160;train-<br/>ing&#160;in&#160;ways&#160;that&#160;materially&#160;affect&#160;the&#160;accuracy&#160;of<br/>the&#160;LM.&#160;This&#160;suggests&#160;that&#160;diagnostic&#160;classifiers<br/>are&#160;not&#160;illustrating&#160;improvements&#160;in&#160;word&#160;repre-<br/>sentations&#160;throughout&#160;training,&#160;and&#160;we&#160;conclude<br/>that&#160;they&#160;are&#160;ineffective&#160;for&#160;understanding&#160;learning<br/>dynamics.&#160;Our&#160;remaining&#160;experiments&#160;use&#160;only<br/>SVCCA.<br/>
4.1<br/>
SVCCA&#160;on&#160;Output&#160;Tag&#160;Prediction<br/>
We&#160;applied&#160;SVCCA&#160;to&#160;each&#160;layer&#160;of&#160;our&#160;LM&#160;with<br/>the&#160;corresponding&#160;layer&#160;of&#160;each&#160;tag&#160;predictor&#160;in<br/>order&#160;to&#160;find&#160;the&#160;correlation&#160;between&#160;the&#160;LM&#160;rep-<br/>resentation&#160;and&#160;the&#160;tag&#160;model&#160;representation&#160;at<br/>each&#160;level&#160;(Figure&#160;<a href="1811.00225v3s.html#6">8).&#160;</a>To&#160;establish&#160;empirical&#160;lower<br/>bounds&#160;on&#160;correlation,&#160;we&#160;also&#160;trained&#160;our&#160;taggers<br/>on&#160;the&#160;same&#160;data&#160;with&#160;randomly&#160;shuffled&#160;labels,<br/>as&#160;in&#160;<a href="1811.00225v3s.html#10">Zhang&#160;et&#160;al.&#160;(2016).&#160;</a>These&#160;latter&#160;experi-<br/>ments,&#160;denoted&#160;by&#160;the&#160;dotted&#160;lines&#160;of&#160;Figure&#160;<a href="1811.00225v3s.html#6">8,<br/></a>show&#160;how&#160;much&#160;of&#160;the&#160;similarity&#160;between&#160;mod-<br/>els&#160;is&#160;caused&#160;by&#160;their&#160;ability&#160;to&#160;memorize&#160;arbi-<br/>trary&#160;associations.&#160;Note&#160;that&#160;the&#160;resulting&#160;scores<br/>are&#160;nonzero,&#160;likely&#160;because&#160;the&#160;linguistic&#160;structure<br/>of&#160;the&#160;input&#160;shapes&#160;representations&#160;even&#160;when&#160;the<br/>output&#160;is&#160;random,&#160;due&#160;to&#160;the&#160;memorization&#160;phase<br/>of&#160;training&#160;<a href="1811.00225v3s.html#10">(Shwartz-Ziv&#160;and&#160;Tishby,&#160;2017).</a><br/>
The&#160;strongest&#160;similarity&#160;at&#160;recurrent&#160;layers&#160;be-<br/>
longs&#160;to&#160;the&#160;most&#160;local&#160;property,&#160;the&#160;UDP&#160;POS<br/>tag.&#160;Both&#160;coarse-&#160;and&#160;fine-grained&#160;semantic&#160;tags,<br/>which&#160;rely&#160;on&#160;longer&#160;range&#160;dependencies,&#160;fall&#160;be-<br/>
Figure&#160;8:&#160;SVCCA&#160;correlation&#160;scores&#160;between&#160;the&#160;LM<br/>
low&#160;UDP&#160;POS&#160;consistently.&#160;Topic,&#160;which&#160;is&#160;global<br/>
predicting&#160;xt+1&#160;and&#160;the&#160;tag&#160;model&#160;predicting&#160;yt+1.&#160;At<br/>
to&#160;an&#160;entire&#160;document,&#160;is&#160;the&#160;least&#160;captured&#160;and&#160;the<br/>
the&#160;end&#160;of&#160;each&#160;epoch,&#160;we&#160;compare&#160;the&#160;current&#160;LM&#160;with<br/>
slowest&#160;to&#160;stabilize.&#160;Indeed,&#160;correlation&#160;with&#160;true<br/>
the&#160;final&#160;tag&#160;model.&#160;Dotted&#160;lines&#160;use&#160;shuffled&#160;tags.&#160;Gray<br/>
topic&#160;falls&#160;consistently&#160;below&#160;the&#160;score&#160;for&#160;a&#160;model<br/>
vertical&#160;lines&#160;mark&#160;when&#160;the&#160;step&#160;size&#160;is&#160;rescaled.<br/>
<hr/>
<a name=7></a>trained&#160;on&#160;randomized&#160;topic&#160;tags,&#160;implying&#160;that<br/>
put.&#160;The&#160;network&#160;thus&#160;initially&#160;learns&#160;to&#160;effectively<br/>
early&#160;in&#160;training&#160;the&#160;model&#160;has&#160;removed&#160;the&#160;con-<br/>
represent&#160;the&#160;input,&#160;then&#160;compresses&#160;this&#160;represen-<br/>
text&#160;necessary&#160;to&#160;identify&#160;topic&#160;(below&#160;even&#160;the&#160;in-<br/>
tation,&#160;keeping&#160;only&#160;the&#160;elements&#160;relevant&#160;to&#160;the<br/>
adequate&#160;contextual&#160;information&#160;memorized&#160;by&#160;a<br/>
<a href="1811.00225v3s.html#7">output.3&#160;</a>If&#160;the&#160;LM&#160;begins&#160;by&#160;maximizing&#160;mutual<br/>
model&#160;with&#160;random&#160;labels),&#160;which&#160;depends&#160;on&#160;the<br/>
information&#160;with&#160;input,&#160;because&#160;the&#160;input&#160;is&#160;identi-<br/>
general&#160;vocabulary&#160;in&#160;a&#160;sentence&#160;rather&#160;than&#160;a&#160;local<br/>
cal&#160;for&#160;the&#160;LM&#160;and&#160;tag&#160;models&#160;it&#160;may&#160;lead&#160;to&#160;these<br/>
sequence.&#160;Over&#160;time&#160;correlation&#160;rises,&#160;possibly&#160;be-<br/>
similar&#160;initial&#160;representations,&#160;followed&#160;by&#160;a&#160;de-<br/>
cause&#160;the&#160;model&#160;permits&#160;more&#160;long-distance&#160;con-<br/>
cline&#160;in&#160;similarity&#160;as&#160;the&#160;compression&#160;narrows&#160;to<br/>
text&#160;to&#160;be&#160;encoded.&#160;<a href="1811.00225v3s.html#10">Khandelwal&#160;et&#160;al.&#160;(2018)&#160;</a>found<br/>
properties&#160;specific&#160;to&#160;each&#160;task.<br/>
that&#160;LSTMs&#160;remember&#160;content&#160;words&#160;like&#160;nouns<br/>for&#160;more&#160;time&#160;steps&#160;than&#160;they&#160;remember&#160;function<br/>
4.2<br/>
SVCCA&#160;on&#160;Input&#160;Tagging<br/>
words&#160;like&#160;prepositions&#160;and&#160;articles.&#160;We&#160;hypothe-<br/>
Our&#160;second&#160;conceptual&#160;shift&#160;is&#160;to&#160;focus&#160;on&#160;out-<br/>
size&#160;that&#160;the&#160;LM’s&#160;slower&#160;stabilization&#160;on&#160;topic&#160;is<br/>
put&#160;tag&#160;prediction—asking&#160;what&#160;a&#160;representation<br/>
related&#160;to&#160;this&#160;phenomenon,&#160;since&#160;it&#160;must&#160;depend<br/>
encodes&#160;about&#160;the&#160;next&#160;output&#160;word,&#160;rather&#160;than<br/>
on&#160;content&#160;words,&#160;and&#160;its&#160;ability&#160;to&#160;remember&#160;them<br/>
what&#160;it&#160;has&#160;encoded&#160;about&#160;words&#160;it&#160;has&#160;already&#160;ob-<br/>
increases&#160;throughout&#160;training.<br/>
served&#160;in&#160;the&#160;input.&#160;What&#160;effect&#160;does&#160;this&#160;have?<br/>
The&#160;encoder&#160;layer&#160;exhibits&#160;very&#160;different&#160;pat-<br/>
Since&#160;we&#160;already&#160;studied&#160;output&#160;tags&#160;in&#160;the&#160;pre-<br/>
terns.&#160;Because&#160;the&#160;representation&#160;produced&#160;by&#160;the<br/>
vious&#160;set&#160;of&#160;experiments,&#160;here&#160;we&#160;consider&#160;input<br/>
encoder&#160;layer&#160;is&#160;local&#160;to&#160;the&#160;word,&#160;the&#160;nuances<br/>
tags,&#160;in&#160;the&#160;style&#160;of&#160;most&#160;diagnostic&#160;classifier&#160;anal-<br/>
that&#160;determine&#160;how&#160;a&#160;word&#160;is&#160;tagged&#160;in&#160;context<br/>
ysis&#160;(Figure&#160;<a href="1811.00225v3s.html#8">9).&#160;</a>The&#160;learning&#160;dynamics&#160;are&#160;similar<br/>
cannot&#160;be&#160;learned.<br/>
The&#160;encoder&#160;layers&#160;are&#160;all<br/>
to&#160;those&#160;for&#160;tag&#160;prediction,&#160;but&#160;the&#160;UDP&#160;POS&#160;tag-<br/>
highly&#160;similar&#160;to&#160;each&#160;other,&#160;which&#160;suggests&#160;that<br/>
ger&#160;decreases&#160;dramatically&#160;in&#160;all&#160;correlations&#160;while<br/>
the&#160;unigram&#160;representations&#160;produced&#160;by&#160;the&#160;en-<br/>
the&#160;GMB-trained&#160;<a href="1811.00225v3s.html#7">taggers4&#160;</a>often&#160;increase&#160;slightly.<br/>
coder&#160;are&#160;less&#160;dependent&#160;on&#160;the&#160;particular&#160;end&#160;task<br/>
While&#160;the&#160;shapes&#160;of&#160;the&#160;lines&#160;are&#160;similar,&#160;UDP<br/>
of&#160;the&#160;neural&#160;network.&#160;Similarity&#160;between&#160;the&#160;en-<br/>
POS&#160;no&#160;longer&#160;consistently&#160;dominates&#160;the&#160;other<br/>
coders&#160;declines&#160;over&#160;time&#160;as&#160;they&#160;become&#160;more<br/>
tasks&#160;in&#160;recurrent&#160;layer&#160;correlation.&#160;Instead,&#160;we<br/>
specialized&#160;towards&#160;the&#160;language&#160;modeling&#160;task.<br/>
find&#160;the&#160;more&#160;granular&#160;PTB&#160;POS&#160;tags&#160;lead&#160;to&#160;the<br/>
This&#160;decline&#160;points&#160;to&#160;some&#160;simple&#160;patterns&#160;which<br/>
most&#160;similar&#160;representations.<br/>
are&#160;learned&#160;for&#160;all&#160;language&#160;tasks,&#160;but&#160;which&#160;are<br/>
5<br/>
Discussion&#160;and&#160;Conclusions<br/>
gradually&#160;replaced&#160;by&#160;representations&#160;more&#160;use-<br/>ful&#160;for&#160;language&#160;modeling.&#160;This&#160;process&#160;may&#160;even<br/>
We&#160;find&#160;clear&#160;patterns&#160;in&#160;the&#160;encoding&#160;of&#160;linguistic<br/>
be&#160;considered&#160;a&#160;naturally&#160;occurring&#160;analog&#160;to&#160;the<br/>
structure&#160;with&#160;SVCCA,&#160;in&#160;contrast&#160;to&#160;the&#160;weaker<br/>
common&#160;practice&#160;of&#160;initializing&#160;the&#160;encoder&#160;layer<br/>
results&#160;from&#160;a&#160;less&#160;responsive&#160;diagnostic&#160;classifier.<br/>
as&#160;word&#160;embeddings&#160;pretrained&#160;an&#160;unrelated&#160;task<br/>
Because&#160;SVCCA&#160;proves&#160;so&#160;much&#160;more&#160;sensitive<br/>
such&#160;as&#160;skipgram&#160;or&#160;CBOW&#160;<a href="1811.00225v3s.html#10">(Mikolov&#160;et&#160;al.,&#160;2013).</a><br/>
than&#160;the&#160;diagnostic&#160;classifiers&#160;currently&#160;in&#160;use,&#160;we<br/>
It&#160;seems&#160;that&#160;the&#160;‘easy’&#160;word&#160;properties,&#160;which<br/>
believe&#160;that&#160;future&#160;work&#160;on&#160;measuring&#160;the&#160;encod-<br/>
immediately&#160;improve&#160;performance,&#160;are&#160;similar&#160;re-<br/>
ing&#160;of&#160;linguistic&#160;structure&#160;should&#160;use&#160;the&#160;similarity<br/>
gardless&#160;of&#160;the&#160;particular&#160;language&#160;task.<br/>
of&#160;individual&#160;modules&#160;from&#160;independently&#160;trained<br/>
At&#160;h1,&#160;the&#160;correlation&#160;shows&#160;a&#160;clear&#160;initial&#160;de-<br/>
tag&#160;predictors&#160;rather&#160;than&#160;the&#160;performance&#160;of&#160;tag<br/>
cline&#160;in&#160;similarity&#160;for&#160;all&#160;tasks.&#160;This&#160;seems&#160;to&#160;point<br/>
predictors&#160;trained&#160;on&#160;a&#160;particular&#160;representation.<br/>
to&#160;an&#160;initial&#160;representation&#160;that&#160;relies&#160;on&#160;simple<br/>
This&#160;system&#160;should&#160;also&#160;be&#160;of&#160;interest&#160;because<br/>
shared&#160;properties,&#160;which&#160;in&#160;the&#160;first&#160;stage&#160;of&#160;train-<br/>
it&#160;is&#160;efficient.&#160;To&#160;train&#160;a&#160;diagnostic&#160;classifier,&#160;we<br/>
ing&#160;is&#160;gradually&#160;dissolved&#160;before&#160;the&#160;layer&#160;begins<br/>
must&#160;run&#160;a&#160;forward&#160;pass&#160;of&#160;the&#160;LM&#160;for&#160;each&#160;for-<br/>
to&#160;converge&#160;on&#160;a&#160;structure&#160;shared&#160;with&#160;each&#160;tag<br/>
ward&#160;pass&#160;of&#160;the&#160;auxiliary&#160;model,&#160;while&#160;SVCCA<br/>
predictor.&#160;It&#160;may&#160;also&#160;be&#160;linked&#160;to&#160;the&#160;information<br/>
only&#160;requires&#160;the&#160;LM&#160;to&#160;run&#160;on&#160;the&#160;test&#160;set.&#160;A&#160;fur-<br/>
bottleneck&#160;learning&#160;phases&#160;explored&#160;by&#160;<a href="1811.00225v3s.html#10">Shwartz-</a><br/>
ther&#160;efficiency&#160;gain&#160;is&#160;particular&#160;to&#160;studying&#160;learn-<br/>
<a href="1811.00225v3s.html#10">Ziv&#160;and&#160;Tishby&#160;(2017).&#160;</a>They&#160;suggest&#160;that&#160;neu-<br/>
3This&#160;memorization–compression&#160;learning&#160;pattern&#160;paral-<br/>
ral&#160;networks&#160;learn&#160;by&#160;first&#160;maximizing&#160;the&#160;mutual<br/>
lels&#160;the&#160;memorization–generalization&#160;of&#160;the&#160;first&#160;half&#160;of&#160;the<br/>
information&#160;between&#160;the&#160;input&#160;and&#160;internal&#160;rep-<br/>
U-shaped&#160;curve&#160;exhibited&#160;by&#160;human&#160;children&#160;learning&#160;irreg-<br/>ular&#160;word&#160;forms.&#160;?&#160;observe&#160;similar&#160;patterns&#160;when&#160;artificially<br/>
resentation,&#160;then&#160;minimizing&#160;the&#160;mutual&#160;informa-<br/>
modeling&#160;inflection.<br/>
tion&#160;between&#160;the&#160;internal&#160;representation&#160;and&#160;out-<br/>
4PTB&#160;POS,&#160;SEM&#160;(fine),&#160;and&#160;SEM&#160;(coarse)<br/>
<hr/>
<a name=8></a><img src="1811.00225v3-8_1.png"/><br/>
<img src="1811.00225v3-8_2.png"/><br/>
<img src="1811.00225v3-8_3.png"/><br/>
ing&#160;dynamics:&#160;we&#160;train&#160;only&#160;one&#160;tagger&#160;and&#160;com-<br/>pare&#160;it&#160;to&#160;different&#160;versions&#160;of&#160;the&#160;LM&#160;over&#160;train-<br/>ing,&#160;but&#160;for&#160;standard&#160;probing,&#160;we&#160;must&#160;train&#160;a<br/>new&#160;version&#160;of&#160;each&#160;layer’s&#160;tagger&#160;at&#160;each&#160;epoch.<br/>Our&#160;SVCCA&#160;experiments&#160;in&#160;Figure&#160;<a href="1811.00225v3s.html#6">8&#160;</a>ran&#160;in&#160;hours,<br/>while&#160;the&#160;diagnostic&#160;classifier&#160;experiments&#160;in&#160;Fig-<br/>ure&#160;<a href="1811.00225v3s.html#6">7&#160;</a>ran&#160;for&#160;days.<br/>
Our&#160;method&#160;holds&#160;another,&#160;more&#160;subtle&#160;advan-<br/>
tage.&#160;Our&#160;analysis&#160;provides&#160;an&#160;alternative&#160;view&#160;of<br/>what&#160;it&#160;means&#160;for&#160;a&#160;model&#160;to&#160;encode&#160;some&#160;linguis-<br/>tic&#160;trait.&#160;The&#160;literature&#160;on&#160;analyzing&#160;neural&#160;net-<br/>works&#160;includes&#160;a&#160;broad&#160;spectrum&#160;of&#160;interpretations<br/>about&#160;what&#160;it&#160;means&#160;to&#160;encode&#160;a&#160;property.&#160;At&#160;one<br/>end&#160;of&#160;the&#160;spectrum&#160;lies&#160;the&#160;purely&#160;informational<br/>view&#160;(e.g.,&#160;mutual&#160;information;&#160;?).&#160;Mutual&#160;infor-<br/>mation&#160;is&#160;a&#160;very&#160;flexible&#160;view,&#160;but&#160;it&#160;requires&#160;us&#160;to<br/>compute&#160;theoretical&#160;information&#160;content,&#160;which&#160;in<br/>practice&#160;can&#160;only&#160;be&#160;estimated.&#160;Furthermore,&#160;in-<br/>formation&#160;can&#160;be&#160;represented&#160;without&#160;being&#160;used,<br/>as&#160;shown&#160;by&#160;?,&#160;who&#160;found&#160;that&#160;NMT&#160;systems&#160;of-<br/>ten&#160;predicted&#160;tense&#160;according&#160;to&#160;a&#160;diagnostic&#160;clas-<br/>sifier&#160;but&#160;did&#160;not&#160;produce&#160;the&#160;correct&#160;tense&#160;as&#160;out-<br/>put.&#160;The&#160;other&#160;end&#160;of&#160;the&#160;spectrum&#160;is&#160;focused&#160;on<br/>the&#160;structure&#160;of&#160;the&#160;representation&#160;space&#160;(e.g.,&#160;the<br/>features&#160;and&#160;the&#160;property&#160;in&#160;question&#160;are&#160;linearly<br/>similar;&#160;<a href="1811.00225v3s.html#9">Alishahi&#160;et&#160;al.,&#160;2017).&#160;</a>Analyzing&#160;struc-<br/>tural&#160;similarity&#160;should&#160;remedy&#160;the&#160;shortcomings&#160;of<br/>the&#160;informational&#160;view,&#160;but&#160;most&#160;intermediate&#160;rep-<br/>resentations&#160;are&#160;not&#160;targeted&#160;to&#160;extract&#160;the&#160;prop-<br/>erty&#160;in&#160;question&#160;through&#160;a&#160;linear&#160;transformation,<br/>and&#160;failing&#160;to&#160;be&#160;interpretable&#160;through&#160;such&#160;sim-<br/>ple&#160;extraction&#160;should&#160;not&#160;be&#160;equated&#160;to&#160;a&#160;failure&#160;to<br/>encode&#160;that&#160;property.<br/>
Most&#160;of&#160;the&#160;literature&#160;on&#160;analyzing&#160;representa-<br/>
tions,&#160;by&#160;probing&#160;with&#160;a&#160;more&#160;complex&#160;architec-<br/>ture,&#160;seeks&#160;the&#160;flexibility&#160;of&#160;mutual&#160;information<br/>with&#160;the&#160;concreteness&#160;and&#160;tractability&#160;of&#160;the&#160;struc-<br/>tural&#160;view&#160;–&#160;but&#160;instead&#160;obscures&#160;the&#160;strict&#160;infor-<br/>mation&#160;view&#160;without&#160;offering&#160;interpretable&#160;infor-<br/>mation&#160;about&#160;the&#160;structure,&#160;because&#160;the&#160;architec-<br/>ture&#160;of&#160;a&#160;diagnostic&#160;classifier&#160;affects&#160;its&#160;perfor-<br/>mance.&#160;It&#160;should&#160;not&#160;be&#160;surprising&#160;that&#160;represen-<br/>tational&#160;quality&#160;as&#160;measured&#160;by&#160;such&#160;systems&#160;is&#160;a<br/>poor&#160;indicator&#160;of&#160;translation&#160;quality&#160;(?).&#160;SVCCA,<br/>in&#160;contrast,&#160;is&#160;a&#160;structural&#160;view&#160;that&#160;does&#160;not&#160;di-<br/>rectly&#160;compare&#160;an&#160;activation&#160;that&#160;targets&#160;word&#160;pre-<br/>diction&#160;with&#160;a&#160;particular&#160;tag,&#160;but&#160;instead&#160;compares<br/>that&#160;activation&#160;with&#160;one&#160;targeting&#160;the&#160;prediction&#160;of<br/>
Figure&#160;9:&#160;SVCCA&#160;correlation&#160;scores&#160;between&#160;LM&#160;ac-<br/>
the&#160;tag.<br/>
tivations&#160;when&#160;predicting&#160;xt+1&#160;and&#160;tagger&#160;activations<br/>when&#160;labeling&#160;yt.&#160;Dotted&#160;lines&#160;use&#160;shuffled&#160;tags.&#160;Gray<br/>
Let&#160;us&#160;consider&#160;a&#160;specific&#160;common&#160;probing<br/>
vertical&#160;lines&#160;mark&#160;when&#160;the&#160;step&#160;size&#160;is&#160;rescaled.<br/>
method.&#160;What&#160;do&#160;we&#160;learn&#160;about&#160;the&#160;LM&#160;when&#160;a<br/>
<hr/>
<a name=9></a>feedforward&#160;network&#160;cannot&#160;extract&#160;tag&#160;informa-<br/>
language&#160;modeling&#160;representations.<br/>
tion&#160;directly&#160;from&#160;the&#160;embedding&#160;layer,&#160;but&#160;can<br/>
The&#160;techniques&#160;in&#160;this&#160;paper&#160;could&#160;be&#160;applied&#160;to<br/>
from&#160;a&#160;recurrent&#160;layer?&#160;It&#160;may&#160;be&#160;tempting&#160;to&#160;con-<br/>
better&#160;understand&#160;the&#160;high&#160;performance&#160;of&#160;a&#160;sys-<br/>
clude&#160;that&#160;tag&#160;information&#160;relies&#160;heavily&#160;on&#160;con-<br/>
tem&#160;like&#160;ELMo&#160;<a href="1811.00225v3s.html#10">(Peters&#160;et&#160;al.,&#160;2018).&#160;</a>Different&#160;lay-<br/>
text,&#160;but&#160;consider&#160;some&#160;alternative&#160;explanations.<br/>
ers&#160;in&#160;such&#160;a&#160;system&#160;are&#160;useful&#160;for&#160;different&#160;tasks,<br/>
If&#160;the&#160;embedding&#160;encodes&#160;the&#160;tag&#160;to&#160;be&#160;interpreted<br/>
and&#160;this&#160;effect&#160;could&#160;be&#160;understood&#160;in&#160;terms&#160;of&#160;the<br/>
by&#160;a&#160;recurrent&#160;layer,&#160;a&#160;feedforward&#160;network&#160;may<br/>
gradual&#160;divergence&#160;between&#160;the&#160;layers&#160;and&#160;their&#160;re-<br/>
not&#160;be&#160;capable&#160;of&#160;representing&#160;the&#160;function&#160;to&#160;ex-<br/>
spective&#160;convergence&#160;to&#160;representations&#160;geared&#160;to-<br/>
tract&#160;that&#160;tag&#160;because&#160;it&#160;does&#160;not&#160;have&#160;access&#160;to&#160;a<br/>
ward&#160;a&#160;single&#160;task.<br/>
context&#160;vector&#160;for&#160;aiding&#160;interpretation&#160;of&#160;the&#160;hid-<br/>den&#160;layer.&#160;Perhaps&#160;its&#160;activation&#160;functions&#160;cover&#160;a<br/>
Acknowledgements<br/>
different&#160;range&#160;of&#160;outputs.&#160;By&#160;directly&#160;comparing<br/>
We&#160;thank&#160;Denis&#160;Emelin,&#160;Sameer&#160;Bansal,&#160;Toms<br/>
LSTM&#160;layers&#160;to&#160;LSTM&#160;layers&#160;and&#160;embedding&#160;lay-<br/>
Bergmanis,&#160;Maria&#160;Corkery,&#160;Sharon&#160;Goldwater,<br/>
ers&#160;to&#160;embedding&#160;layers,&#160;we&#160;respect&#160;the&#160;shape&#160;of<br/>
Sorcha&#160;Gilroy,&#160;Aibek&#160;Makazhanov,&#160;Yevgen&#160;Ma-<br/>
their&#160;outputs&#160;and&#160;the&#160;role&#160;of&#160;each&#160;module&#160;within<br/>
tusevych,&#160;Kate&#160;McCurdy,&#160;Janie&#160;Sinclair,&#160;Ida&#160;Szu-<br/>
the&#160;network&#160;in&#160;our&#160;analysis.<br/>
bert,&#160;Nikolay&#160;Bogoychev,&#160;Clara&#160;Vania,&#160;and&#160;the<br/>
The&#160;results&#160;of&#160;our&#160;analysis&#160;imply&#160;that&#160;early&#160;in<br/>
anonymous&#160;reviewers&#160;for&#160;helpful&#160;discussion&#160;and<br/>
training,&#160;representing&#160;part&#160;of&#160;speech&#160;is&#160;the&#160;natu-<br/>
comments&#160;on&#160;drafts.&#160;We&#160;thank&#160;Matthew&#160;Summers<br/>
ral&#160;way&#160;to&#160;get&#160;initial&#160;high&#160;performance.&#160;However,<br/>
for&#160;assistance&#160;with&#160;visualisations.<br/>
as&#160;training&#160;progresses,&#160;it&#160;increasingly&#160;benefits&#160;the<br/>model&#160;to&#160;represent&#160;categories&#160;with&#160;longer-range<br/>dependencies,&#160;such&#160;as&#160;topic.<br/>
References<br/>
Afra&#160;Alishahi,&#160;Marie&#160;Barking,&#160;and&#160;Grzegorz&#160;Chrupała.<br/>
6<br/>
Future&#160;Work<br/>
2017.&#160;Encoding&#160;of&#160;phonology&#160;in&#160;a&#160;recurrent&#160;neu-<br/>ral&#160;model&#160;of&#160;grounded&#160;speech.&#160;In&#160;Proceedings&#160;of<br/>
One&#160;direction&#160;for&#160;future&#160;work&#160;is&#160;exploring&#160;how<br/>
the&#160;21st&#160;Conference&#160;on&#160;Computational&#160;Natural&#160;Lan-<br/>
generalization&#160;interacts&#160;with&#160;the&#160;correlations&#160;be-<br/>
guage&#160;Learning&#160;(CoNLL&#160;2017),&#160;pages&#160;368–378.<br/>
tween&#160;LMs&#160;and&#160;tag&#160;predictors.&#160;It&#160;may&#160;be&#160;that&#160;a<br/>
Yonatan&#160;Belinkov,&#160;Nadir&#160;Durrani,&#160;Fahim&#160;Dalvi,&#160;Has-<br/>
faithful&#160;encoding&#160;of&#160;a&#160;property&#160;like&#160;POS&#160;tag&#160;in-<br/>
san&#160;Sajjad,&#160;and&#160;James&#160;Glass.&#160;2017.&#160;<a href="http://aclweb.org/anthology/P17-1080">What&#160;do&#160;Neural</a><br/>
dicates&#160;that&#160;the&#160;LM&#160;is&#160;relying&#160;more&#160;on&#160;linguistic<br/>
<a href="http://aclweb.org/anthology/P17-1080">Machine&#160;Translation&#160;Models&#160;Learn&#160;about&#160;Morphol-<br/>ogy?&#160;</a>In&#160;Proceedings&#160;of&#160;the&#160;55th&#160;Annual&#160;Meeting&#160;of<br/>
structure&#160;than&#160;on&#160;memorizing&#160;specific&#160;phrases,&#160;and<br/>
the&#160;Association&#160;for&#160;Computational&#160;Linguistics&#160;(Vol-<br/>
therefore&#160;is&#160;associated&#160;with&#160;a&#160;more&#160;general&#160;model.<br/>
ume&#160;1:&#160;Long&#160;Papers),&#160;pages&#160;861–872,&#160;Vancouver,<br/>
If&#160;these&#160;measurements&#160;of&#160;structure&#160;encoding&#160;are<br/>
Canada.&#160;Association&#160;for&#160;Computational&#160;Linguistics.<br/>
associated&#160;with&#160;more&#160;general&#160;models,&#160;we&#160;might&#160;in-<br/>
Yonatan&#160;Belinkov,&#160;Lluís&#160;Màrquez,&#160;Hassan&#160;Sajjad,<br/>
troduce&#160;regularizers&#160;or&#160;other&#160;modifications&#160;that&#160;ex-<br/>
Nadir&#160;Durrani,&#160;Fahim&#160;Dalvi,&#160;and&#160;James&#160;R.&#160;Glass.<br/>
plicitly&#160;encourage&#160;correlation&#160;with&#160;a&#160;tagging&#160;task.<br/>
2018.&#160;<a href="http://arxiv.org/abs/1801.07772">Evaluating&#160;Layers&#160;of&#160;Representation&#160;in&#160;Neu-</a><br/>
<a href="1811.00225v3s.html#9">Combes&#160;et&#160;al.&#160;(2018)&#160;</a>identified&#160;the&#160;phenomenon<br/>
<a href="http://arxiv.org/abs/1801.07772">ral&#160;Machine&#160;Translation&#160;on&#160;Part-of-Speech&#160;and&#160;Se-<br/>mantic&#160;Tagging&#160;Tasks.&#160;</a>CoRR,&#160;abs/1801.07772.<br/>
of&#160;gradient&#160;starvation,&#160;meaning&#160;that&#160;while&#160;fre-<br/>quent&#160;and&#160;unambiguous&#160;features&#160;are&#160;learned<br/>
Johannes&#160;Bjerva,&#160;Barbara&#160;Plank,&#160;and&#160;Johan&#160;Bos.&#160;2016.<br/>
quickly&#160;in&#160;training,&#160;they&#160;slow&#160;down&#160;the&#160;learning<br/>
Semantic&#160;Tagging&#160;with&#160;Deep&#160;Residual&#160;Networks.&#160;In<br/>COLING.<br/>
of&#160;rarer&#160;features.&#160;For&#160;example,&#160;artificially&#160;bright-<br/>ening&#160;images&#160;according&#160;to&#160;their&#160;class&#160;leads&#160;to&#160;a<br/>
Terra&#160;Blevins,&#160;Omer&#160;Levy,&#160;and&#160;Luke&#160;Zettlemoyer.<br/>
delay&#160;in&#160;learning&#160;to&#160;represent&#160;the&#160;more&#160;complex<br/>
2018.&#160;<a href="http://arxiv.org/abs/1805.04218">Deep&#160;RNNs&#160;Encode&#160;Soft&#160;Hierarchical&#160;Syn-<br/>tax.&#160;</a>arXiv:1805.04218&#160;[cs].&#160;ArXiv:&#160;1805.04218.<br/>
natural&#160;class&#160;features.&#160;Although&#160;it&#160;is&#160;tempting&#160;to<br/>claim&#160;that&#160;semantic&#160;structure&#160;is&#160;learned&#160;using&#160;syn-<br/>
Johan&#160;Bos,&#160;Valerio&#160;Basile,&#160;Kilian&#160;Evang,&#160;Noortje&#160;J<br/>
tactic&#160;structure&#160;as&#160;natural&#160;scaffolding,&#160;it&#160;is&#160;possible<br/>
Venhuizen,&#160;and&#160;Johannes&#160;Bjerva.&#160;2017.&#160;The&#160;gronin-<br/>gen&#160;meaning&#160;bank.&#160;In&#160;Handbook&#160;of&#160;linguistic&#160;anno-<br/>
that&#160;the&#160;simple&#160;predictive&#160;power&#160;of&#160;POS&#160;is&#160;acting<br/>
tation,&#160;pages&#160;463–496.&#160;Springer.<br/>
as&#160;an&#160;attractor&#160;and&#160;starving&#160;semantic&#160;features&#160;that<br/>are&#160;rarer&#160;and&#160;more&#160;ambiguous.&#160;A&#160;possible&#160;direc-<br/>
Remi&#160;Tachet&#160;des&#160;Combes,&#160;Mohammad&#160;Pezeshki,<br/>
Samira&#160;Shabanian,&#160;Aaron&#160;Courville,&#160;and&#160;Yoshua<br/>
tion&#160;for&#160;future&#160;work&#160;would&#160;be&#160;to&#160;explore&#160;which&#160;of<br/>
Bengio.&#160;2018.&#160;<a href="http://arxiv.org/abs/1809.06848">On&#160;the&#160;Learning&#160;Dynamics&#160;of&#160;Deep</a><br/>
these&#160;explanations&#160;is&#160;true,&#160;possibly&#160;by&#160;decorrelat-<br/>
<a href="http://arxiv.org/abs/1809.06848">Neural&#160;Networks.</a><br/>
arXiv:1809.06848&#160;[cs,&#160;stat].<br/>
ing&#160;particular&#160;aspects&#160;of&#160;linguistic&#160;structure&#160;from<br/>
ArXiv:&#160;1809.06848.<br/>
<hr/>
<a name=10></a>Jonathan&#160;Frankle&#160;and&#160;Michael&#160;Carbin.&#160;2018.<br/>
<a href="http://arxiv.org/abs/1803.03635">The</a><br/>
A<br/>
Performance&#160;Out&#160;Of&#160;Domain<br/>
<a href="http://arxiv.org/abs/1803.03635">Lottery&#160;Ticket&#160;Hypothesis:&#160;Training&#160;Pruned&#160;Neu-<br/>ral&#160;Networks.</a><br/>
arXiv:1803.03635&#160;[cs].<br/>
ArXiv:<br/>
Because&#160;SEM&#160;tags&#160;and&#160;PTB&#160;POS&#160;tags&#160;were<br/>
1803.03635.<br/>
both&#160;trained&#160;on&#160;the&#160;GMB&#160;corpus,&#160;we&#160;present&#160;the<br/>
Mario&#160;Giulianelli,&#160;Jack&#160;Harding,&#160;Florian&#160;Mohnert,<br/>
SVCCA&#160;similarities&#160;on&#160;an&#160;in-domain&#160;GMB&#160;test<br/>
Dieuwke&#160;Hupkes,&#160;and&#160;Willem&#160;Zuidema.&#160;2018.&#160;<a href="http://arxiv.org/abs/1808.08079">Un-</a><br/>
corpus&#160;as&#160;well&#160;as&#160;the&#160;Wikipedia&#160;test&#160;corpus&#160;used<br/>
<a href="http://arxiv.org/abs/1808.08079">der&#160;the&#160;Hood:&#160;Using&#160;Diagnostic&#160;Classifiers&#160;to&#160;In-</a><br/>
elsewhere&#160;in&#160;the&#160;paper.&#160;The&#160;results&#160;are&#160;in&#160;Fig-<br/>
<a href="http://arxiv.org/abs/1808.08079">vestigate&#160;and&#160;Improve&#160;how&#160;Language&#160;Models&#160;Track</a><br/>
ures&#160;<a href="1811.00225v3s.html#11">10-11.&#160;</a>In&#160;general&#160;correlations&#160;are&#160;higher&#160;us-<br/>
<a href="http://arxiv.org/abs/1808.08079">Agreement&#160;Information.</a><br/>
arXiv:1808.08079&#160;[cs].<br/>
ing&#160;the&#160;original&#160;tagging&#160;domain,&#160;but&#160;not&#160;enough&#160;to<br/>
ArXiv:&#160;1808.08079.<br/>
contradict&#160;our&#160;earlier&#160;analysis.&#160;The&#160;shapes&#160;of&#160;the<br/>
Yova&#160;Kementchedjhieva&#160;and&#160;Adam&#160;Lopez.&#160;2018.&#160;Indi-<br/>
curves&#160;remain&#160;similar.<br/>
catements&#160;that&#160;character&#160;language&#160;models&#160;learn&#160;En-<br/>glish&#160;morpho-syntactic&#160;units&#160;and&#160;regularities.<br/>
In<br/>
Proc.&#160;of&#160;Workshop&#160;on&#160;Analyzing&#160;and&#160;interpreting<br/>neural&#160;networks&#160;for&#160;NLP.<br/>
Urvashi&#160;Khandelwal,&#160;He&#160;He,&#160;Peng&#160;Qi,&#160;and&#160;Dan<br/>
Jurafsky.&#160;2018.<br/>
<a href="http://arxiv.org/abs/1805.04623">Sharp&#160;Nearby,</a><br/>
<a href="http://arxiv.org/abs/1805.04623">Fuzzy&#160;Far</a><br/>
<a href="http://arxiv.org/abs/1805.04623">Away:&#160;How&#160;Neural&#160;Language&#160;Models&#160;Use&#160;Context.<br/></a>arXiv:1805.04623&#160;[cs].&#160;ArXiv:&#160;1805.04623.<br/>
Tal&#160;Linzen,&#160;Emmanuel&#160;Dupoux,&#160;and&#160;Yoav&#160;Goldberg.<br/>
2016.<br/>
<a href="http://arxiv.org/abs/1611.01368">Assessing&#160;the&#160;Ability&#160;of&#160;LSTMs&#160;to&#160;Learn</a><br/>
<a href="http://arxiv.org/abs/1611.01368">Syntax-Sensitive&#160;Dependencies.&#160;</a>arXiv:1611.01368<br/>[cs].&#160;ArXiv:&#160;1611.01368.<br/>
Tomas&#160;Mikolov,&#160;Ilya&#160;Sutskever,&#160;Kai&#160;Chen,&#160;Greg&#160;S&#160;Cor-<br/>
rado,&#160;and&#160;Jeff&#160;Dean.&#160;2013.&#160;<a href="http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">Distributed&#160;Representa-<br/>tions&#160;of&#160;Words&#160;and&#160;Phrases&#160;and&#160;their&#160;Composition-<br/>ality.&#160;</a>In&#160;Advances&#160;in&#160;Neural&#160;Information&#160;Processing<br/>Systems&#160;26,&#160;pages&#160;3111–3119.&#160;Curran&#160;Associates,<br/>Inc.<br/>
Ari&#160;S.&#160;Morcos,&#160;Maithra&#160;Raghu,&#160;and&#160;Samy&#160;Ben-<br/>
gio.&#160;2018.<br/>
<a href="http://arxiv.org/abs/1806.05759">Insights&#160;on&#160;representational&#160;similar-</a><br/>
<a href="http://arxiv.org/abs/1806.05759">ity&#160;in&#160;neural&#160;networks&#160;with&#160;canonical&#160;correlation.<br/></a>arXiv:1806.05759&#160;[cs,&#160;stat].&#160;ArXiv:&#160;1806.05759.<br/>
Matthew&#160;E&#160;Peters,&#160;Mark&#160;Neumann,&#160;Mohit&#160;Iyyer,&#160;Matt<br/>
Gardner,&#160;Christopher&#160;Clark,&#160;Kenton&#160;Lee,&#160;and&#160;Luke<br/>Zettlemoyer.&#160;2018.&#160;Deep&#160;contextualized&#160;word&#160;rep-<br/>resentations.&#160;arXiv&#160;preprint&#160;arXiv:1802.05365.<br/>
Maithra&#160;Raghu,&#160;Justin&#160;Gilmer,&#160;Jason&#160;Yosinski,&#160;and<br/>
Jascha&#160;Sohl-Dickstein.&#160;2017.<br/>
<a href="http://arxiv.org/abs/1706.05806">SVCCA:&#160;Singu-</a><br/>
<a href="http://arxiv.org/abs/1706.05806">lar&#160;Vector&#160;Canonical&#160;Correlation&#160;Analysis&#160;for<br/>Deep&#160;Learning&#160;Dynamics&#160;and&#160;Interpretability.<br/></a>arXiv:1706.05806&#160;[cs,&#160;stat].&#160;ArXiv:&#160;1706.05806.<br/>
Ravid&#160;Shwartz-Ziv&#160;and&#160;Naftali&#160;Tishby.&#160;2017.&#160;<a href="http://arxiv.org/abs/1703.00810">Open-</a><br/>
<a href="http://arxiv.org/abs/1703.00810">ing&#160;the&#160;Black&#160;Box&#160;of&#160;Deep&#160;Neural&#160;Networks&#160;via<br/>Information.</a><br/>
arXiv:1703.00810&#160;[cs].<br/>
ArXiv:<br/>
1703.00810.<br/>
Chiyuan&#160;Zhang,&#160;Samy&#160;Bengio,&#160;Moritz&#160;Hardt,&#160;Ben-<br/>
jamin&#160;Recht,&#160;and&#160;Oriol&#160;Vinyals.&#160;2016.&#160;Understand-<br/>ing&#160;deep&#160;learning&#160;requires&#160;rethinking&#160;generalization.<br/>arXiv&#160;preprint&#160;arXiv:1611.03530.<br/>
Kelly&#160;W.&#160;Zhang&#160;and&#160;Samuel&#160;R.&#160;Bowman.&#160;2018.&#160;<a href="http://arxiv.org/abs/1809.10040">Lan-</a><br/>
<a href="http://arxiv.org/abs/1809.10040">guage&#160;Modeling&#160;Teaches&#160;You&#160;More&#160;Syntax&#160;than<br/>Translation&#160;Does:&#160;Lessons&#160;Learned&#160;Through&#160;Auxil-<br/>iary&#160;Task&#160;Analysis.&#160;</a>arXiv:1809.10040&#160;[cs].&#160;ArXiv:<br/>1809.10040.<br/>
<hr/>
<a name=11></a><img src="1811.00225v3-11_1.png"/><br/>
<img src="1811.00225v3-11_2.png"/><br/>
<img src="1811.00225v3-11_3.png"/><br/>
<img src="1811.00225v3-11_4.png"/><br/>
<img src="1811.00225v3-11_5.png"/><br/>
<img src="1811.00225v3-11_6.png"/><br/>
Figure&#160;10:&#160;SVCCA&#160;correlation&#160;scores&#160;between&#160;LM&#160;and<br/>
Figure&#160;11:&#160;SVCCA&#160;correlation&#160;scores&#160;between&#160;LM&#160;and<br/>
yt+1&#160;tag&#160;predictor.&#160;Dotted&#160;lines&#160;use&#160;models&#160;trained&#160;on<br/>
yt&#160;tagger.&#160;Dotted&#160;lines&#160;use&#160;models&#160;trained&#160;on&#160;randomly<br/>
randomly&#160;shuffled&#160;the&#160;data.&#160;Dashed&#160;lines&#160;use&#160;GMB&#160;do-<br/>
shuffled&#160;the&#160;data.&#160;Dashed&#160;lines&#160;use&#160;GMB&#160;domain&#160;test<br/>
main&#160;test&#160;data.<br/>
data.<br/>
<hr/>
</body>
</html>
