<!DOCTYPE html><html>
<head>
<title></title>
<style type="text/css">
<!--
.xflip {
    -moz-transform: scaleX(-1);
    -webkit-transform: scaleX(-1);
    -o-transform: scaleX(-1);
    transform: scaleX(-1);
    filter: fliph;
}
.yflip {
    -moz-transform: scaleY(-1);
    -webkit-transform: scaleY(-1);
    -o-transform: scaleY(-1);
    transform: scaleY(-1);
    filter: flipv;
}
.xyflip {
    -moz-transform: scaleX(-1) scaleY(-1);
    -webkit-transform: scaleX(-1) scaleY(-1);
    -o-transform: scaleX(-1) scaleY(-1);
    transform: scaleX(-1) scaleY(-1);
    filter: fliph + flipv;
}
-->
</style>
</head>
<body>
<a name=1></a>Social&#160;Learning&#160;with&#160;Questions<br/>
Grant&#160;Schoenebeck,&#160;Univeristy&#160;of&#160;Michigan,&#160;schoeneb@umich.edu<br/>
Shih-Tang&#160;Su,&#160;Univeristy&#160;of&#160;Michigan,&#160;shihtang@umich.edu<br/>
Vijay&#160;Subramanian,&#160;Univeristy&#160;of&#160;Michigan,&#160;vgsubram@umich.edu<br/>
November&#160;14,&#160;2018<br/>
Abstract<br/>
This&#160;work&#160;studies&#160;sequential&#160;social&#160;learning&#160;(also&#160;known&#160;as&#160;Bayesian&#160;observational&#160;learning),<br/>
and&#160;how&#160;private&#160;communication&#160;can&#160;enable&#160;agents&#160;to&#160;avoid&#160;herding&#160;to&#160;the&#160;wrong&#160;action/state.<br/>Starting&#160;from&#160;the&#160;seminal&#160;<a href="1811.00226v3s.html#1">BHW1&#160;</a>model&#160;where&#160;asymptotic&#160;learning&#160;does&#160;not&#160;occur,&#160;we&#160;allow<br/>agents&#160;to&#160;ask&#160;private&#160;and&#160;finite&#160;questions&#160;to&#160;a&#160;bounded&#160;subset&#160;of&#160;their&#160;predecessors.&#160;While<br/>retaining&#160;the&#160;publicly&#160;observed&#160;history&#160;of&#160;the&#160;agents&#160;and&#160;their&#160;Bayes&#160;rationality&#160;from&#160;the&#160;BHW<br/>model,&#160;we&#160;further&#160;assume&#160;that&#160;both&#160;the&#160;ability&#160;to&#160;ask&#160;questions&#160;and&#160;the&#160;questions&#160;themselves<br/>are&#160;common&#160;knowledge.&#160;Then&#160;interpreting&#160;asking&#160;questions&#160;as&#160;partitioning&#160;information&#160;sets,&#160;we<br/>study&#160;whether&#160;asymptotic&#160;learning&#160;can&#160;be&#160;achieved&#160;with&#160;finite&#160;capacity&#160;questions.&#160;Restricting<br/>our&#160;attention&#160;to&#160;the&#160;network&#160;where&#160;every&#160;agent&#160;is&#160;only&#160;allowed&#160;to&#160;query&#160;her&#160;immediate&#160;prede-<br/>cessor,&#160;an&#160;explicit&#160;construction&#160;shows&#160;that&#160;a&#160;1-bit&#160;question&#160;from&#160;each&#160;agent&#160;is&#160;enough&#160;to&#160;enable<br/>asymptotic&#160;learning.<br/>
arXiv:1811.00226v3 &#160;[cs.GT] &#160;12 Nov 2018<br/>
1Bikhchandani,&#160;Hirshleifer,&#160;and&#160;Welch,&#160;1992&#160;<a href="1811.00226v3s.html#12">[1]</a><br/>
<hr/>
<a name=2></a>1<br/>
Introduction<br/>
In&#160;social&#160;networks,&#160;agents&#160;use&#160;information&#160;from&#160;(a)&#160;private&#160;signals&#160;(knowledge)&#160;they&#160;have,&#160;(b)<br/>learning&#160;past&#160;agents&#160;actions&#160;(observations),&#160;and&#160;(c)&#160;comments&#160;from&#160;contactable&#160;experienced&#160;agents<br/>(experts)&#160;to&#160;guide&#160;their&#160;own&#160;decisions.&#160;The&#160;study&#160;of&#160;learning&#160;using&#160;private&#160;signals&#160;and&#160;past&#160;agents’<br/>actions,&#160;i.e.,&#160;private&#160;or&#160;public&#160;history,&#160;in&#160;homogeneous&#160;and&#160;Bayes-rational&#160;agents&#160;was&#160;initiated&#160;by<br/>the&#160;seminal&#160;work&#160;in&#160;<a href="1811.00226v3s.html#12">[1,&#160;2,&#160;3].&#160;</a>Key&#160;results&#160;in&#160;<a href="1811.00226v3s.html#12">[1,&#160;2,&#160;3]&#160;</a>state&#160;that&#160;in&#160;the&#160;model&#160;where&#160;countably&#160;infinite<br/>Bayes-rational&#160;agents&#160;make&#160;decisions&#160;sequentially&#160;to&#160;match&#160;binary&#160;unknown&#160;states&#160;of&#160;the&#160;world,<br/>named&#160;social&#160;learning&#160;or&#160;Bayesian&#160;observational&#160;learning&#160;in&#160;the&#160;literature&#160;<a href="1811.00226v3s.html#12">[4,&#160;5,&#160;6,&#160;7,&#160;8,&#160;9,&#160;10,&#160;11,&#160;12],<br/></a>an&#160;outcome&#160;called&#160;Information&#160;Cascade&#160;occurs&#160;almost&#160;surely&#160;with&#160;fully&#160;observable&#160;history&#160;and<br/>bounded&#160;likelihood&#160;ratio&#160;of&#160;signals.&#160;An&#160;information&#160;cascade&#160;occurs&#160;when&#160;it&#160;is&#160;optimal&#160;for&#160;agents<br/>to&#160;ignore&#160;their&#160;own&#160;(private)&#160;signals&#160;for&#160;decision&#160;making&#160;after&#160;observing&#160;the&#160;history.<br/>
Though<br/>
individually&#160;optimal,&#160;this&#160;may&#160;lead&#160;to&#160;a&#160;socially&#160;sub-optimal&#160;outcome&#160;where&#160;after&#160;an&#160;information<br/>cascade,&#160;all&#160;agents&#160;ignore&#160;their&#160;private&#160;signal&#160;and&#160;choose&#160;the&#160;wrong&#160;action,&#160;referred&#160;to&#160;as&#160;a&#160;wrong<br/>cascade.&#160;In&#160;models&#160;of&#160;social&#160;learning,&#160;there&#160;is&#160;another&#160;possible&#160;outcome&#160;known&#160;as&#160;(asymptotic)<br/>le<a href="1811.00226v3s.html#2">arning2.&#160;</a>This&#160;occurs&#160;when&#160;the&#160;information&#160;in&#160;the&#160;private&#160;signals&#160;is&#160;aggregated&#160;efficiently&#160;so&#160;that<br/>agents&#160;eventually&#160;learn&#160;the&#160;underlying&#160;true&#160;state&#160;the&#160;world&#160;and&#160;make&#160;socially&#160;optimal&#160;decisions.<br/>
Literature&#160;studying&#160;social&#160;learning,&#160;i.e.,&#160;making&#160;socially&#160;optimal&#160;decisions,&#160;is&#160;mainly&#160;focussed&#160;on<br/>
using&#160;channels&#160;(a)&#160;and&#160;(b)&#160;above&#160;for&#160;Bayes-rational&#160;agents;&#160;works&#160;using&#160;channel&#160;(c)&#160;mostly&#160;study<br/>learning&#160;by&#160;modeling&#160;it&#160;as&#160;a&#160;communication&#160;channel&#160;in&#160;distributed&#160;(sequential)&#160;hypothesis&#160;testing<br/>problems,&#160;but&#160;with&#160;non-Bayes-rational&#160;agents.&#160;Inspired&#160;by&#160;behaviors&#160;in&#160;social&#160;networks,&#160;where&#160;peo-<br/>ple&#160;usually&#160;query&#160;their&#160;friends&#160;who&#160;have&#160;prior&#160;experience&#160;before&#160;making&#160;their&#160;own&#160;decisions,&#160;using<br/>information&#160;via&#160;(c)&#160;by&#160;communicating&#160;with&#160;contactable&#160;past&#160;agents&#160;may&#160;reveal&#160;another&#160;channel&#160;to<br/>achieve&#160;asymptotic&#160;learning&#160;for&#160;Bayes-rational&#160;agents.&#160;Another&#160;reason&#160;to&#160;explore&#160;this&#160;channel&#160;is<br/>the&#160;following&#160;statement&#160;by&#160;Gul&#160;and&#160;Lundholm&#160;in&#160;<a href="1811.00226v3s.html#12">[10]:&#160;</a>“Informational&#160;cascades&#160;can&#160;be&#160;eliminated&#160;by<br/>enriching&#160;the&#160;setting&#160;in&#160;a&#160;way&#160;that&#160;allows&#160;prior&#160;agents’&#160;information&#160;to&#160;be&#160;transmitted.”&#160;This&#160;general<br/>principle,&#160;however,&#160;does&#160;not&#160;reveal&#160;whether&#160;learning&#160;can&#160;be&#160;achieved&#160;with&#160;finite-bit&#160;<a href="1811.00226v3s.html#2">questions3.</a><br/>
Problem&#160;Statement:&#160;Motivated&#160;by&#160;behaviors&#160;in&#160;real&#160;social&#160;networks&#160;and&#160;the&#160;quoted&#160;statement<br/>in&#160;<a href="1811.00226v3s.html#12">[10],&#160;</a>we&#160;want&#160;to&#160;study&#160;if&#160;querying&#160;past&#160;agents&#160;with&#160;bounded&#160;number&#160;of&#160;finite&#160;capacity&#160;questions<br/>sequentially,&#160;but&#160;without&#160;relaxing&#160;assumptions&#160;of&#160;(a)&#160;and&#160;(b)&#160;used&#160;in&#160;BHW&#160;model&#160;<a href="1811.00226v3s.html#12">[1],&#160;</a>can&#160;achieve<br/>asymptotic&#160;learning&#160;or&#160;not.&#160;More&#160;precisely,&#160;we&#160;assume&#160;the&#160;essential&#160;features&#160;of&#160;the&#160;problem&#160;of<br/>sequential&#160;social&#160;learning&#160;with&#160;a&#160;common&#160;database&#160;recording&#160;actions&#160;of&#160;agents&#160;<a href="1811.00226v3s.html#12">[1,&#160;2,&#160;3]</a>,&#160;but&#160;allow<br/>each&#160;Bayes-rational&#160;agent&#160;to&#160;ask&#160;a&#160;single,&#160;private&#160;and&#160;finite-capacity&#160;(for&#160;response)&#160;question&#160;of&#160;each<br/>among&#160;a&#160;subset&#160;of&#160;past&#160;agents&#160;(friends&#160;or&#160;assumed&#160;experts).&#160;Note&#160;that&#160;the&#160;Maximum&#160;Aposteriori<br/>Probability&#160;(MAP)&#160;rule&#160;is&#160;still&#160;individually&#160;optimally&#160;and&#160;will&#160;be&#160;used&#160;by&#160;each&#160;agent&#160;for&#160;her&#160;decision.<br/>We&#160;emphasize&#160;here&#160;that&#160;the&#160;BHW&#160;model&#160;<a href="1811.00226v3s.html#12">[1]&#160;</a>has&#160;private&#160;signals&#160;with&#160;a&#160;bounded&#160;likelihood&#160;ratio,<br/>and&#160;with&#160;Bayes-rational&#160;agents&#160;only&#160;the&#160;ideas&#160;in&#160;Theme&#160;2&#160;are&#160;known&#160;to&#160;yield&#160;the&#160;learning&#160;outcome.<br/>In&#160;this&#160;paper,&#160;allowing&#160;for&#160;private&#160;questions,&#160;we&#160;want&#160;to&#160;answer&#160;the&#160;following&#160;three&#160;questions:&#160;1)<br/>What&#160;is&#160;the&#160;minimum&#160;set&#160;of&#160;agents&#160;that&#160;need&#160;to&#160;be&#160;queried&#160;as&#160;a&#160;function&#160;of&#160;the&#160;agent’s&#160;index&#160;and<br/>information&#160;set?&#160;;&#160;2)&#160;What&#160;is&#160;the&#160;minimum&#160;size&#160;of&#160;questions&#160;needed&#160;to&#160;achieve&#160;learning?,&#160;and&#160;3)<br/>Can&#160;we&#160;construct&#160;a&#160;set&#160;of&#160;questions&#160;that&#160;will&#160;achieve&#160;either&#160;minimum?<br/>
Before&#160;stating&#160;our&#160;main&#160;contributions,&#160;we&#160;highlight&#160;the&#160;main&#160;differences&#160;between&#160;this&#160;work&#160;and<br/>
the&#160;existing&#160;literature.&#160;In&#160;the&#160;literature,&#160;there&#160;are&#160;three&#160;well-developed&#160;themes&#160;to&#160;achieve&#160;social<br/>learning:&#160;one,&#160;the&#160;presence&#160;of&#160;many&#160;agents&#160;with&#160;rich&#160;private&#160;signals&#160;(with&#160;unbounded&#160;likelihood<br/>ratios);&#160;two,&#160;the&#160;obfuscation&#160;of&#160;the&#160;history&#160;of&#160;agents’&#160;actions&#160;when&#160;viewed&#160;so&#160;that&#160;at&#160;least&#160;a&#160;minimal<br/>
2See&#160;Definition&#160;<a href="1811.00226v3s.html#4">1&#160;</a>in&#160;Section&#160;<a href="1811.00226v3s.html#4">2.<br/></a>3Appendix&#160;<a href="1811.00226v3s.html#23">B.3.1&#160;</a>shows&#160;a&#160;learning&#160;example&#160;where&#160;the&#160;total&#160;bits&#160;agent&#160;n&#160;spends&#160;on&#160;questions&#160;is&#160;not&#160;bounded.<br/>
1<br/>
<hr/>
<a name=3></a>number&#160;of&#160;agents&#160;have&#160;their&#160;private&#160;signal&#160;revealed&#160;by&#160;their&#160;actions;&#160;and&#160;three,&#160;the&#160;presence&#160;of&#160;many<br/>(or&#160;all)&#160;non-Bayesian&#160;algorithmic&#160;agents.&#160;We&#160;briefly&#160;describ<a href="1811.00226v3s.html#3">e4&#160;</a>these&#160;three&#160;themes&#160;in&#160;the&#160;following:<br/>Theme&#160;1:&#160;Compared&#160;to&#160;the&#160;seminal&#160;BHW&#160;model&#160;<a href="1811.00226v3s.html#12">[1],&#160;</a>models&#160;in&#160;this&#160;theme&#160;use&#160;information<br/>from&#160;(b)&#160;and&#160;generalize&#160;the&#160;information&#160;content&#160;in&#160;(a).&#160;Unlike&#160;BHW&#160;and&#160;our&#160;model&#160;considering<br/>private&#160;signals&#160;with&#160;bounded&#160;likelihood&#160;ratios,&#160;the&#160;seminal&#160;work&#160;by&#160;Smith&#160;and&#160;Sørensen&#160;<a href="1811.00226v3s.html#12">[4]&#160;</a>allowed<br/>generalized&#160;models&#160;for&#160;richer&#160;signals&#160;characterized&#160;by&#160;the&#160;(unbounded)&#160;likelihood&#160;ratio&#160;of&#160;the&#160;two<br/>states&#160;deduced&#160;from&#160;the&#160;private&#160;signals;&#160;and&#160;learning&#160;is&#160;achievable&#160;under&#160;richer&#160;signals.<br/>Theme&#160;2:&#160;Unlike&#160;BHW&#160;and&#160;our&#160;model&#160;disclose&#160;full&#160;history&#160;to&#160;every&#160;agent,&#160;works&#160;in&#160;this&#160;theme<br/>use&#160;partial&#160;history&#160;in&#160;(b).&#160;By&#160;revealing&#160;a&#160;random&#160;or&#160;a&#160;judiciously&#160;designed&#160;deterministic&#160;subset&#160;of<br/>past&#160;agents’&#160;actions&#160;in&#160;networks,&#160;<a href="1811.00226v3s.html#12">[8]&#160;</a>and&#160;<a href="1811.00226v3s.html#12">[13]&#160;</a>respectively&#160;showed&#160;the&#160;asymptotic&#160;learning&#160;can&#160;be<br/>achieved&#160;through&#160;revealing&#160;either&#160;a&#160;random&#160;subset&#160;of&#160;history&#160;or&#160;at&#160;most&#160;d&#160;past&#160;agents&#160;in&#160;a&#160;special<br/>class&#160;of&#160;networks.&#160;However,&#160;presenting&#160;reduced&#160;or&#160;distorted&#160;views&#160;of&#160;the&#160;history&#160;of&#160;agents’&#160;actions<br/>is&#160;philosophically&#160;troubling&#160;as&#160;it&#160;implicitly&#160;assumes&#160;that&#160;the&#160;distortions&#160;made&#160;are&#160;always&#160;benign&#160;or<br/>for&#160;efficiency,&#160;and&#160;also&#160;posits&#160;an&#160;implicit&#160;trust&#160;in&#160;the&#160;system&#160;designer&#160;on&#160;the&#160;part&#160;of&#160;the&#160;agents.<br/>Theme&#160;3:&#160;Here,&#160;by&#160;allowing&#160;non-Bayesian&#160;agents&#160;or&#160;changing&#160;payoff&#160;structures,&#160;there&#160;is&#160;a&#160;class&#160;of<br/>literature&#160;on&#160;distributed&#160;binary&#160;hypothesis&#160;testing&#160;problems&#160;that&#160;follows&#160;Cover&#160;<a href="1811.00226v3s.html#12">[14]&#160;</a>and&#160;Hellman<br/>and&#160;Cover&#160;<a href="1811.00226v3s.html#12">[15]&#160;</a>and&#160;falls&#160;under&#160;(c).&#160;In&#160;this&#160;model,&#160;agents&#160;can&#160;only&#160;observe&#160;the&#160;actions&#160;from&#160;their<br/>immediate&#160;predecessor,&#160;and&#160;their&#160;actions&#160;now&#160;try&#160;to&#160;transmit&#160;information&#160;and&#160;to&#160;learn&#160;collabora-<br/>tively&#160;the&#160;true&#160;state&#160;of&#160;the&#160;world.&#160;It&#160;is&#160;shown&#160;in&#160;<a href="1811.00226v3s.html#12">[15]&#160;</a>that&#160;the&#160;learning,&#160;often&#160;called&#160;optimal&#160;decision<br/>rules&#160;in&#160;this&#160;literature,&#160;cannot&#160;be&#160;achieved&#160;under&#160;bounded&#160;likelihood&#160;ratio&#160;of&#160;signals.&#160;However,&#160;if<br/>observing&#160;K&#160;≥&#160;2&#160;immediate&#160;predecessor&#160;is&#160;allowed,&#160;authors&#160;in&#160;<a href="1811.00226v3s.html#12">[16]&#160;</a>showed&#160;that&#160;asymptotic&#160;learning<br/>can&#160;be&#160;achieved&#160;using&#160;a&#160;specific&#160;set&#160;of&#160;four-state&#160;Markov&#160;chains.&#160;From&#160;the&#160;perspective&#160;of&#160;informa-<br/>tion&#160;design,&#160;this&#160;approach&#160;of&#160;designing&#160;Markov&#160;chains&#160;for&#160;learning&#160;is&#160;similar&#160;in&#160;spirit&#160;to&#160;partitioning<br/>of&#160;information&#160;sets,&#160;but&#160;for&#160;non-Bayesian&#160;agents.<br/>
Main&#160;Contributions:&#160;Our&#160;analysis&#160;of&#160;the&#160;modified&#160;BHW&#160;model&#160;<a href="1811.00226v3s.html#12">[1]&#160;</a>described&#160;above&#160;yields&#160;two<br/>main&#160;contributions:<br/>1)&#160;To&#160;the&#160;best&#160;of&#160;our&#160;knowledge,&#160;we&#160;are&#160;the&#160;first&#160;to&#160;highlight&#160;the&#160;ability&#160;to&#160;change&#160;information<br/>structures&#160;among&#160;agents&#160;to&#160;achieve&#160;learning&#160;in&#160;social&#160;learning&#160;problems.&#160;The&#160;approach&#160;used&#160;in&#160;this<br/>work,&#160;namely&#160;partitioning&#160;information&#160;sets,&#160;is&#160;closely&#160;related&#160;to&#160;the&#160;Bayesian&#160;persuasion&#160;<a href="1811.00226v3s.html#12">[17,&#160;</a><a href="1811.00226v3s.html#13">18].<br/></a>Designs&#160;achieving&#160;asymptotic&#160;learning&#160;in&#160;our&#160;work&#160;can&#160;be&#160;viewed&#160;as&#160;a&#160;“relayed&#160;Bayesian&#160;persuasion”<br/>by&#160;persuading&#160;agents&#160;in&#160;“possibly&#160;wrong&#160;cascades”&#160;to&#160;avoid&#160;the&#160;information&#160;cascades&#160;eventually.<br/>2)&#160;With&#160;an&#160;explicit&#160;construction&#160;of&#160;1-bit&#160;question&#160;corresponding&#160;to&#160;the&#160;agent’s&#160;possible&#160;information<br/>set&#160;and&#160;index&#160;value&#160;in&#160;the&#160;network&#160;and&#160;where&#160;agents&#160;are&#160;only&#160;allowed&#160;to&#160;query&#160;their&#160;immediate<br/>predecessors,&#160;we&#160;show&#160;that&#160;learning&#160;is&#160;achievable&#160;and&#160;answer&#160;the&#160;three&#160;questions&#160;addressed&#160;above<br/>in&#160;a&#160;single&#160;construction.<br/>
Note&#160;that&#160;in&#160;our&#160;approach,&#160;the&#160;system&#160;designer&#160;commits&#160;to&#160;a&#160;specific&#160;information&#160;structure&#160;(full<br/>
public&#160;history&#160;of&#160;previous&#160;agents’&#160;actions&#160;plus&#160;private&#160;communications)&#160;without&#160;any&#160;reductions&#160;or<br/>distortions,&#160;and&#160;also&#160;provides&#160;the&#160;agents&#160;with&#160;a&#160;question&#160;guidebook,&#160;whose&#160;performance&#160;each&#160;agent<br/>can&#160;verify&#160;independently.&#160;The&#160;minimal&#160;nature&#160;of&#160;our&#160;learning&#160;achieving&#160;question&#160;guidebook&#160;also<br/>reveals&#160;the&#160;fragility&#160;of&#160;information&#160;cascades&#160;(Sec.16&#160;in&#160;<a href="1811.00226v3s.html#13">[19]),&#160;</a>as&#160;a&#160;small&#160;amount&#160;of&#160;strategically<br/>delivered&#160;information&#160;leads&#160;to&#160;learning.&#160;The&#160;information&#160;revelation&#160;in&#160;our&#160;question&#160;guidebook&#160;is<br/>strategic&#160;in&#160;contrast&#160;to&#160;reviews&#160;that&#160;are&#160;<a href="1811.00226v3s.html#13">[20]&#160;</a>generated&#160;via&#160;an&#160;exogenous&#160;process&#160;(and&#160;revealed&#160;only<br/>for&#160;some&#160;specific&#160;actions),&#160;and&#160;furthermore,&#160;lead&#160;to&#160;learning&#160;<a href="1811.00226v3s.html#12">[7]&#160;</a>only&#160;if&#160;the&#160;signals&#160;are&#160;rich.&#160;A&#160;subtle<br/>but&#160;rather&#160;interesting&#160;point&#160;of&#160;our&#160;approach&#160;is&#160;the&#160;“relayed&#160;persuasion”&#160;aspect&#160;wherein&#160;we&#160;only<br/>aim&#160;to&#160;persuade&#160;particular&#160;agents&#160;chosen&#160;by&#160;our&#160;design&#160;instead&#160;of&#160;agents&#160;chosen&#160;by&#160;nature&#160;as&#160;is<br/>commonly&#160;seen&#160;in&#160;Bayesian&#160;persuasion&#160;<a href="1811.00226v3s.html#13">[21,&#160;22].</a><br/>
4See&#160;Related&#160;Work&#160;in&#160;Appendix&#160;<a href="1811.00226v3s.html#25">C&#160;</a>for&#160;a&#160;detailed&#160;discussion.<br/>
2<br/>
<hr/>
<a name=4></a>2<br/>
Problem&#160;Formulation<br/>
BHW&#160;Model&#160;and&#160;Information&#160;Cascade&#160;Starting&#160;from&#160;the&#160;seminal&#160;BHW&#160;mo<a href="1811.00226v3s.html#12">del[1],&#160;</a>we&#160;consider<br/>a&#160;model&#160;with&#160;binary&#160;states&#160;of&#160;the&#160;world&#160;Θ&#160;=&#160;{A,&#160;B}&#160;that&#160;are&#160;equally&#160;likely&#160;to&#160;occur&#160;and&#160;a&#160;countable<br/>number&#160;of&#160;Bayes-rational&#160;agents,&#160;each&#160;taking&#160;a&#160;single&#160;action&#160;sequentially&#160;as&#160;indexed&#160;by&#160;n&#160;∈&#160;{1,&#160;2,&#160;...}.<br/>At&#160;each&#160;time&#160;slot&#160;n,&#160;agent&#160;n&#160;shows&#160;up&#160;and&#160;chooses&#160;an&#160;action&#160;Xn&#160;=&#160;{&#160;¯<br/>
A,&#160;¯<br/>
B}&#160;with&#160;the&#160;goal&#160;of&#160;matching<br/>
the&#160;true&#160;state&#160;of&#160;the&#160;world.&#160;Formally,&#160;for&#160;every&#160;agent&#160;n,&#160;the&#160;utility&#160;function&#160;un(Θ,&#160;Xn)&#160;is&#160;defined<br/>as&#160;un(A,&#160;¯<br/>
A)&#160;=&#160;un(B,&#160;¯<br/>
B)&#160;=&#160;1&#160;and&#160;un(A,&#160;¯<br/>
B)&#160;=&#160;un(B,&#160;¯<br/>
A)&#160;=&#160;0.<br/>
Before&#160;agent&#160;n&#160;takes&#160;her&#160;action,&#160;she&#160;receives&#160;an&#160;informative&#160;but&#160;not&#160;revealing&#160;private&#160;signal<br/>
sn.&#160;Her&#160;private&#160;signal&#160;is&#160;received&#160;through&#160;a&#160;binary&#160;symmetric&#160;channel&#160;(BSC)&#160;with&#160;a&#160;time-invariant<br/>crossover&#160;probabilit<a href="1811.00226v3s.html#4">y5&#160;</a>1−p,&#160;where&#160;p&#160;∈&#160;(0.5,&#160;1),&#160;sn&#160;∈&#160;{A,&#160;B}&#160;for&#160;all&#160;n.&#160;An&#160;agent&#160;can&#160;also&#160;observe<br/>the&#160;full&#160;history&#160;of&#160;actions&#160;taken&#160;by&#160;her&#160;predecessors&#160;(agents&#160;with&#160;index&#160;lower&#160;than&#160;her,&#160;if&#160;any),<br/>Hn&#160;∈&#160;{&#160;¯<br/>
A,&#160;¯<br/>
B}n−1.&#160;The&#160;agent&#160;then&#160;computes&#160;the&#160;posterior&#160;belief&#160;of&#160;the&#160;true&#160;states&#160;of&#160;the&#160;world<br/>
(alternatively,&#160;the&#160;likelihood&#160;ratio&#160;of&#160;one&#160;state&#160;versus&#160;the&#160;other),&#160;and&#160;takes&#160;the&#160;action&#160;corresponding<br/>to&#160;the&#160;most&#160;likely&#160;state.&#160;As&#160;in&#160;<a href="1811.00226v3s.html#13">[23,&#160;24],&#160;</a>if&#160;indifferent&#160;between&#160;the&#160;two&#160;actions,&#160;we&#160;assume&#160;that&#160;the<br/>agent&#160;follows&#160;her&#160;private&#160;signal,&#160;instead&#160;of&#160;randomizing,&#160;following&#160;the&#160;majority,&#160;etc.<br/>
Definition&#160;1.&#160;In&#160;a&#160;model&#160;of&#160;Bayesian&#160;observational&#160;learning,&#160;asymptotic&#160;learning&#160;(in&#160;probabil-<br/>ity)&#160;is&#160;achieved&#160;if&#160;limn→∞&#160;P&#160;({Xn&#160;=&#160;¯<br/>
A|Θ&#160;=&#160;A})&#160;=&#160;limn→∞&#160;P&#160;({Xn&#160;=&#160;¯<br/>
B|Θ&#160;=&#160;B})&#160;=&#160;1.&#160;If&#160;asymptotic<br/>
learning&#160;is&#160;not&#160;achievable,&#160;we&#160;say&#160;that&#160;an&#160;information&#160;cascade&#160;has&#160;occurred.<br/>
Under&#160;the&#160;above&#160;setting,&#160;we&#160;know&#160;that&#160;the&#160;BHW&#160;mo<a href="1811.00226v3s.html#12">del[1]&#160;</a>has&#160;an&#160;information&#160;cascade&#160;because<br/>
all&#160;agents&#160;will&#160;ignore&#160;their&#160;private&#160;signals&#160;and&#160;imitate&#160;their&#160;immediate&#160;predecessor’s&#160;action&#160;when<br/>the&#160;difference&#160;between&#160;the&#160;number&#160;of&#160;actions&#160;observed&#160;is&#160;greater&#160;than&#160;or&#160;equal&#160;to&#160;tw<a href="1811.00226v3s.html#4">o6.</a><br/>
Deterministic&#160;Network&#160;Topology&#160;with&#160;Finite&#160;Channel&#160;Capacity&#160;Agents’&#160;communication<br/>is&#160;modeled&#160;by&#160;a&#160;deterministic&#160;network&#160;G(N,&#160;E)&#160;with&#160;directed&#160;edges.&#160;On&#160;each&#160;such&#160;edge,&#160;agents<br/>are&#160;allowed&#160;to&#160;transmit&#160;information&#160;up&#160;to&#160;pre-determined&#160;K&#160;bits&#160;through&#160;a&#160;perfectly&#160;reliable&#160;com-<br/>munication&#160;channel.&#160;Since&#160;agent&#160;m&#160;takes&#160;action&#160;prior&#160;to&#160;n&#160;for&#160;all&#160;m&#160;&lt;&#160;n,&#160;only&#160;directed&#160;edges<br/>(m,&#160;n),&#160;m&#160;&lt;&#160;n&#160;are&#160;allowed&#160;in&#160;the&#160;network.&#160;Using&#160;these&#160;additional&#160;directed&#160;edges,&#160;agent&#160;n&#160;can&#160;ask<br/>questions&#160;individually&#160;and&#160;privately&#160;to&#160;predecessors&#160;in&#160;the&#160;set&#160;Bn&#160;=&#160;{m|(m,&#160;n)&#160;∈&#160;E}&#160;⊆&#160;[n&#160;−&#160;1]&#160;in<br/>line&#160;with&#160;the&#160;network&#160;topology,&#160;before&#160;making&#160;her&#160;decision.&#160;Agent&#160;n&#160;asks&#160;the&#160;set&#160;of&#160;questions&#160;after<br/>receiving&#160;her&#160;private&#160;signal.&#160;Critically,&#160;the&#160;<a href="1811.00226v3s.html#4">deterministic7&#160;</a>network&#160;topology&#160;is&#160;common&#160;knowledge.<br/>
Questions&#160;and&#160;Information&#160;Sets&#160;Since&#160;the&#160;network&#160;topology&#160;is&#160;pre-determined,&#160;the&#160;set&#160;of&#160;agents<br/>that&#160;a&#160;particular&#160;agent&#160;can&#160;query&#160;for&#160;information&#160;is&#160;exogenous.&#160;Given&#160;the&#160;topology,&#160;we&#160;allow&#160;the<br/>information&#160;designer&#160;to&#160;supply&#160;the&#160;agents&#160;with&#160;questions&#160;that&#160;they&#160;can&#160;ask&#160;the&#160;set&#160;of&#160;contactable<br/>predecessors&#160;Bn,&#160;n&#160;∈&#160;N&#160;(in&#160;order&#160;to&#160;distinguish&#160;which&#160;information&#160;set&#160;they&#160;are&#160;at).&#160;Assume&#160;m&#160;∈&#160;Bn,<br/>questions&#160;being&#160;asked&#160;by&#160;agent&#160;n&#160;to&#160;agent&#160;m&#160;are&#160;allowed&#160;to&#160;be&#160;dependent&#160;not&#160;only&#160;on&#160;the&#160;private<br/>signal&#160;and&#160;history&#160;observed&#160;by&#160;agent&#160;n,&#160;but&#160;also&#160;on&#160;the&#160;answers&#160;of&#160;questions&#160;asked&#160;to&#160;other&#160;agents<br/>in&#160;Bn&#160;prior&#160;to&#160;asking&#160;agent&#160;m.&#160;In&#160;short,&#160;the&#160;order&#160;that&#160;agents&#160;in&#160;Bn&#160;are&#160;queried&#160;in&#160;matters&#160;in&#160;the<br/>general&#160;framework.&#160;However,&#160;in&#160;this&#160;paper,&#160;we&#160;restrict&#160;our&#160;attention&#160;to&#160;only&#160;allow&#160;agents&#160;to&#160;ask<br/>questions&#160;sim<a href="1811.00226v3s.html#4">ultaneously8&#160;</a>to&#160;predecessors&#160;in&#160;Bn&#160;to&#160;avoid&#160;complex&#160;analyses&#160;owing&#160;to&#160;the&#160;recursive<br/>analysis&#160;required&#160;to&#160;understand&#160;the&#160;engendered&#160;higher&#160;order&#160;beliefs.&#160;With&#160;this&#160;degeneration,&#160;such<br/>a&#160;collection&#160;of&#160;a&#160;set&#160;of&#160;questions&#160;is&#160;called&#160;a&#160;question&#160;guidebook&#160;(QGB).&#160;With&#160;this&#160;background&#160;in<br/>mind,&#160;we&#160;formally&#160;define&#160;a&#160;QGB.<br/>
5The&#160;time-invariance&#160;assumption&#160;is&#160;mainly&#160;for&#160;the&#160;ease&#160;of&#160;algebraic&#160;complexity.&#160;The&#160;assumption&#160;we&#160;need&#160;for&#160;the<br/>
model&#160;is&#160;the&#160;crossover&#160;probability&#160;of&#160;agents&#160;is&#160;common&#160;knowledge.<br/>
6See&#160;Section&#160;16.2&#160;in&#160;<a href="1811.00226v3s.html#13">[19].<br/></a>7Discussions&#160;about&#160;the&#160;difference&#160;between&#160;deterministic&#160;and&#160;randomized&#160;network&#160;on&#160;this&#160;problem&#160;are&#160;in&#160;Ap-<br/>
pendix&#160;<a href="1811.00226v3s.html#21">B.2.</a><br/>
8The&#160;general&#160;framework&#160;is&#160;discussed&#160;in&#160;Appendix&#160;<a href="1811.00226v3s.html#23">B.3.</a><br/>
3<br/>
<hr/>
<a name=5></a>Definition&#160;2.&#160;A&#160;question&#160;guidebook&#160;Q&#160;is&#160;a&#160;function&#160;Q(n,&#160;Hn,&#160;sn,&#160;m)&#160;that&#160;gives&#160;agent&#160;n&#160;a&#160;set&#160;of<br/>predetermined&#160;questions&#160;conditioned&#160;on&#160;agent&#160;n’s&#160;private&#160;signal,&#160;the&#160;observed&#160;history,&#160;and&#160;the&#160;pre-<br/>decessor&#160;agent&#160;m&#160;who&#160;agent&#160;n&#160;queries.<br/>
We&#160;assume&#160;that&#160;agents&#160;being&#160;queried&#160;are&#160;truthful&#160;in&#160;their&#160;responses,&#160;which&#160;is&#160;natural&#160;as&#160;they<br/>
cannot&#160;gain&#160;from&#160;lying&#160;since&#160;their&#160;(payoff&#160;relevant)&#160;action&#160;has&#160;already&#160;been&#160;taken.<br/>
A&#160;QGB&#160;should&#160;have&#160;two&#160;important&#160;properties:&#160;feasibility&#160;and&#160;incentive&#160;compatibility.&#160;Intu-<br/>
itively,&#160;a&#160;QGB&#160;is&#160;feasible&#160;if&#160;agent&#160;n&#160;only&#160;asks&#160;questions&#160;that&#160;she&#160;knows&#160;queried&#160;agent&#160;m&#160;&lt;&#160;n&#160;can<br/>answer.&#160;This&#160;avoids&#160;the&#160;ambiguity&#160;of&#160;what&#160;would&#160;happen&#160;if&#160;agent&#160;m&#160;does&#160;not&#160;have&#160;the&#160;information<br/>to&#160;answer&#160;the&#160;question&#160;asked&#160;of&#160;it.&#160;Formally,&#160;we&#160;call&#160;an&#160;observed&#160;history&#160;Hn&#160;feasible&#160;for&#160;a&#160;guidebook<br/>Q&#160;if&#160;there&#160;is&#160;a&#160;nonzero&#160;probability&#160;of&#160;obtaining&#160;this&#160;history&#160;given&#160;all&#160;of&#160;agents&#160;follow&#160;the&#160;guidebook<br/>Q,&#160;that&#160;is&#160;P(Hm|Q&#160;is&#160;followed)&#160;&gt;&#160;0,&#160;∀m&#160;&lt;&#160;n;&#160;to&#160;avoid&#160;cumbersome&#160;notation&#160;we&#160;will&#160;simplify&#160;this<br/>to&#160;P(Hm|Q).&#160;Similarly,&#160;we&#160;call&#160;a&#160;question&#160;asked&#160;of&#160;agent&#160;m&#160;by&#160;agent&#160;n&#160;&gt;&#160;m&#160;feasible&#160;if&#160;for&#160;every&#160;sn<br/>and&#160;feasible&#160;history&#160;Hn,&#160;the&#160;question&#160;can&#160;be&#160;answered&#160;by&#160;agent&#160;k&#160;using&#160;only&#160;the&#160;information&#160;that<br/>it&#160;possesses.<br/>
Definition&#160;3.&#160;A&#160;question&#160;guidebook&#160;Q&#160;is&#160;feasible&#160;if&#160;for&#160;every&#160;agent&#160;n,&#160;under&#160;every&#160;feasible&#160;observed<br/>history&#160;H&#160;<a href="1811.00226v3s.html#5">9</a><br/>
<a href="1811.00226v3s.html#5">n</a><br/>
and&#160;sn,&#160;all&#160;questions&#160;provided&#160;by&#160;Q&#160;are&#160;feasible.<br/>
A&#160;QGB&#160;is&#160;incentive&#160;compatible&#160;if&#160;agent&#160;n&#160;always&#160;asks&#160;a&#160;question&#160;from&#160;the&#160;set&#160;of&#160;questions&#160;that<br/>
maximizes&#160;her&#160;expected&#160;payoff.<br/>
Definition&#160;4.&#160;A&#160;question&#160;guidebook&#160;Q&#160;is&#160;incentive&#160;compatible&#160;if&#160;for&#160;every&#160;agent&#160;n&#160;&gt;&#160;1,&#160;under<br/>every&#160;feasible&#160;observed&#160;history&#160;Hn&#160;and&#160;sn,&#160;the&#160;set&#160;of&#160;questions&#160;provided&#160;to&#160;her&#160;maximizes&#160;her<br/>expected&#160;utility&#160;among&#160;all&#160;feasible&#160;questions&#160;she&#160;can&#160;ask&#160;to&#160;agents&#160;in&#160;Bn.<br/>
Given&#160;a&#160;feasible&#160;and&#160;incentive&#160;compatible&#160;QGB,&#160;each&#160;question&#160;serves&#160;to&#160;partition&#160;sequences&#160;of<br/>
private&#160;signals&#160;to&#160;information&#160;sets:&#160;the&#160;possible&#160;states&#160;of&#160;randomness&#160;(underlying&#160;σ-algebra)&#160;into<br/>subsets&#160;(sub-σ-algebras&#160;to&#160;be&#160;more&#160;precise).&#160;Note&#160;that&#160;the&#160;answer&#160;to&#160;such&#160;a&#160;question&#160;specifies&#160;the<br/>set&#160;where&#160;the&#160;current&#160;realization&#160;belongs&#160;to.&#160;Viewing&#160;questions&#160;from&#160;the&#160;perspective&#160;of&#160;partitions<br/>helps&#160;in&#160;justifying&#160;the&#160;following&#160;assumption.<br/>
Assumption&#160;1.&#160;We&#160;assume&#160;that&#160;there&#160;is&#160;no&#160;cost&#160;in&#160;asking&#160;questions.&#160;Thus,&#160;if&#160;no&#160;feasible&#160;question<br/>will&#160;change&#160;the&#160;expected&#160;payoff&#160;of&#160;an&#160;agent,&#160;there&#160;is&#160;no&#160;restriction&#160;for&#160;an&#160;information&#160;designer<br/>to&#160;design&#160;any&#160;question&#160;guidebook&#160;demands&#160;that&#160;this&#160;agent&#160;asks&#160;any&#160;provided&#160;questions&#160;within&#160;the<br/>prescribed&#160;capacity&#160;limit.<br/>
Assumption&#160;<a href="1811.00226v3s.html#5">1&#160;</a>stands&#160;when&#160;a&#160;limited&#160;number&#160;of&#160;questions&#160;are&#160;asked&#160;at&#160;no&#160;cost;&#160;and&#160;every&#160;agent<br/>
is&#160;willing&#160;to&#160;help&#160;her&#160;successors,&#160;in&#160;essence&#160;bringing&#160;in&#160;some&#160;level&#160;of&#160;cooperation.&#160;The&#160;reason&#160;for<br/>this&#160;assumption&#160;is&#160;because&#160;even&#160;though&#160;no&#160;questions&#160;can&#160;benefit&#160;the&#160;current&#160;agent,&#160;her&#160;information<br/>could&#160;be&#160;beneficial&#160;to&#160;future&#160;agents.&#160;This&#160;is&#160;inspired&#160;by&#160;behavior&#160;in&#160;social&#160;networks,&#160;where&#160;is<br/>common&#160;to&#160;see&#160;people&#160;are&#160;willing&#160;to&#160;help&#160;their&#160;friend/neighbor&#160;nodes.&#160;Henceforth,&#160;we&#160;will&#160;assume<br/>such&#160;behavior.&#160;Additionally,&#160;we&#160;will&#160;also&#160;assume&#160;that&#160;the&#160;QGB&#160;is&#160;common&#160;kno<a href="1811.00226v3s.html#5">wledge10.</a><br/>
3<br/>
Telephone-game&#160;Network,&#160;Strategy,&#160;and&#160;Question&#160;Guidebooks<br/>
To&#160;exhibit&#160;how&#160;designing&#160;QGBs&#160;can&#160;achieve&#160;learning,&#160;in&#160;the&#160;following&#160;sections,&#160;we&#160;consider&#160;a<br/>special&#160;network,&#160;called&#160;telephone-game&#160;network.&#160;In&#160;this&#160;network,&#160;we&#160;only&#160;endow&#160;each&#160;pair&#160;of<br/>consecutive&#160;agents&#160;with&#160;a&#160;communication&#160;channel&#160;of&#160;finite&#160;capacity.&#160;In&#160;other&#160;words,&#160;the&#160;topology<br/>of&#160;this&#160;communication&#160;network&#160;is&#160;a&#160;directed&#160;line&#160;graph.&#160;Therefore,&#160;besides&#160;observing&#160;the&#160;actions<br/>
9Since&#160;the&#160;history&#160;is&#160;fully&#160;observable&#160;in&#160;our&#160;model,&#160;Hi&#160;⊂&#160;Hj&#160;for&#160;all&#160;i&#160;&lt;&#160;j,&#160;it&#160;is&#160;sufficient&#160;to&#160;check&#160;P(Hn−1|Q)&#160;&gt;&#160;0<br/>
for&#160;the&#160;feasibility&#160;of&#160;history&#160;Hn.&#160;However,&#160;the&#160;above&#160;definition&#160;still&#160;works&#160;when&#160;the&#160;history&#160;is&#160;only&#160;partial&#160;observable.<br/>
10A&#160;subtle&#160;weaker&#160;assumption&#160;is&#160;discussed&#160;in&#160;Appendix&#160;<a href="1811.00226v3s.html#24">B.4</a><br/>
4<br/>
<hr/>
<a name=6></a>in&#160;history,&#160;the&#160;only&#160;source&#160;for&#160;an&#160;agent&#160;to&#160;get&#160;additional&#160;information&#160;is&#160;asking&#160;finite-bit&#160;questions<br/>to&#160;her&#160;immediate&#160;predecessor&#160;(if&#160;any).&#160;Since&#160;the&#160;capacity&#160;of&#160;every&#160;channel&#160;between&#160;each&#160;agent<br/>and&#160;her&#160;immediate&#160;predecessors&#160;is&#160;finite,&#160;agents&#160;may&#160;not&#160;be&#160;able&#160;to&#160;get&#160;the&#160;information&#160;of&#160;all<br/>private&#160;signals&#160;observed&#160;by&#160;all&#160;her&#160;predecessors.&#160;This&#160;is&#160;a&#160;very&#160;basic&#160;mo<a href="1811.00226v3s.html#6">del11&#160;</a>to&#160;start&#160;studying&#160;if<br/>the&#160;asymptotic&#160;learning&#160;is&#160;achievable&#160;by&#160;finite-bit&#160;questions.In&#160;this&#160;Section,&#160;we&#160;will&#160;first&#160;propose&#160;a<br/>high-level&#160;strategy&#160;that&#160;may&#160;achieve&#160;asymptotic&#160;learning,&#160;then&#160;study&#160;the&#160;following&#160;two&#160;important<br/>questions:&#160;first,&#160;how&#160;to&#160;design&#160;QGBs&#160;to&#160;get&#160;and&#160;accumulate&#160;the&#160;information&#160;we&#160;want,&#160;we&#160;will&#160;use<br/>the&#160;term&#160;Information&#160;set&#160;partition&#160;in&#160;the&#160;following&#160;paragraphs;&#160;second,&#160;what&#160;are&#160;the&#160;necessary&#160;and<br/>sufficient&#160;conditions&#160;to&#160;implement&#160;the&#160;strategy&#160;we&#160;proposed&#160;to&#160;achieve&#160;learning?<br/>
3.1<br/>
Threshold-based&#160;Strategy<br/>
Capacity&#160;constraints&#160;may&#160;make&#160;agents&#160;incapable&#160;of&#160;getting&#160;the&#160;information&#160;of&#160;all&#160;their&#160;predecessors’<br/>private&#160;signals.&#160;However,&#160;there&#160;are&#160;some&#160;“clues”&#160;that&#160;agents&#160;can&#160;learn&#160;from&#160;a&#160;fixed&#160;length&#160;sequence<br/>of&#160;private&#160;signals&#160;owing&#160;to&#160;the&#160;different&#160;signal&#160;distributions&#160;among&#160;states&#160;of&#160;the&#160;world,&#160;e.g.,&#160;when&#160;the<br/>true&#160;state&#160;is&#160;A,&#160;private-signal&#160;sequences&#160;containing&#160;three&#160;consecutive&#160;As&#160;will&#160;occur&#160;more&#160;frequently<br/>than&#160;when&#160;the&#160;true&#160;state&#160;is&#160;B.&#160;With&#160;this&#160;intuition&#160;in&#160;mind,&#160;we&#160;propose&#160;the&#160;following&#160;strategy.<br/>
Suppose&#160;we&#160;are&#160;in&#160;an&#160;¯<br/>
A&#160;cascade,&#160;i.e.,&#160;every&#160;following&#160;agent&#160;ignores&#160;her&#160;private&#160;signal&#160;and&#160;takes<br/>
action&#160;¯<br/>
A&#160;if&#160;no&#160;information&#160;from&#160;questions&#160;is&#160;provided.&#160;As&#160;we&#160;all&#160;know,&#160;if&#160;the&#160;true&#160;state&#160;is&#160;B,&#160;agents<br/>
are&#160;less&#160;likely&#160;to&#160;get&#160;multiple&#160;private&#160;signal&#160;As&#160;in&#160;a&#160;row.&#160;Hence,&#160;we&#160;propose&#160;the&#160;following&#160;strategy:<br/>Step&#160;1:&#160;Given&#160;a&#160;predetermined&#160;threshold&#160;K,&#160;agents&#160;in&#160;an&#160;A&#160;cascade&#160;ask&#160;questions&#160;to&#160;know&#160;if&#160;the<br/>event&#160;“K&#160;consecutive&#160;private&#160;A&#160;signal&#160;are&#160;received&#160;by&#160;agents”&#160;occurs&#160;or&#160;not.<br/>Step&#160;2:&#160;Using&#160;the&#160;information&#160;of&#160;whether&#160;the&#160;event&#160;occurs&#160;or&#160;not,&#160;an&#160;agent&#160;updates&#160;her&#160;likelihood<br/>ratio&#160;of&#160;state&#160;B&#160;versus&#160;A.&#160;Starting&#160;from&#160;agent&#160;m&#160;with&#160;a&#160;fixed&#160;likelihood&#160;ratio&#160;of&#160;B&#160;versus&#160;A,&#160;there<br/>will&#160;be&#160;the&#160;first&#160;agent&#160;n&#160;&gt;&#160;m&#160;with&#160;a&#160;positive&#160;probability&#160;that&#160;her&#160;updated&#160;likelihood&#160;ratio&#160;B&#160;versus<br/>A&#160;will&#160;cross&#160;1.<br/>Step3:&#160;If&#160;agent&#160;n&#160;has&#160;likelihood&#160;ratio&#160;B&#160;versus&#160;A&#160;≥&#160;1,&#160;her&#160;best&#160;strategy&#160;is&#160;to&#160;stop&#160;the&#160;cascade.&#160;If<br/>she&#160;doesn’t&#160;stop&#160;the&#160;cascade,&#160;then&#160;we&#160;use&#160;this&#160;agent&#160;n&#160;as&#160;a&#160;new&#160;starting&#160;agent&#160;(agent&#160;m&#160;in&#160;previous<br/>step)&#160;and&#160;start&#160;a&#160;new&#160;round&#160;checking&#160;if&#160;the&#160;event&#160;occurs&#160;in&#160;the&#160;following&#160;agents.<br/>
Let’s&#160;defer&#160;the&#160;details&#160;of&#160;the&#160;implementation&#160;of&#160;this&#160;strategy&#160;to&#160;the&#160;end&#160;of&#160;this&#160;Section&#160;and<br/>
to&#160;Section&#160;<a href="1811.00226v3s.html#7">4.&#160;</a>Suppose&#160;there&#160;is&#160;a&#160;way&#160;to&#160;implement&#160;the&#160;threshold-based&#160;strategy&#160;presented&#160;above<br/>without&#160;any&#160;incentive&#160;compatibility&#160;issues,&#160;then&#160;an&#160;important&#160;feature&#160;we&#160;can&#160;observe&#160;here&#160;is&#160;that<br/>not&#160;every&#160;agent&#160;in&#160;a&#160;cascade&#160;gets&#160;the&#160;chance&#160;to&#160;stop&#160;the&#160;cascade,&#160;i.e.,&#160;some&#160;of&#160;them&#160;just&#160;ask<br/>questions&#160;and&#160;forward&#160;the&#160;information&#160;of&#160;whether&#160;the&#160;event&#160;occurs&#160;or&#160;not&#160;to&#160;their&#160;successor.&#160;Note<br/>that&#160;Assumption&#160;<a href="1811.00226v3s.html#5">1&#160;</a>grants&#160;the&#160;flexibility&#160;of&#160;designing&#160;a&#160;QGB&#160;with&#160;these&#160;questions.<br/>
Prior&#160;to&#160;designing&#160;QGBs&#160;to&#160;implement&#160;the&#160;threshold-based&#160;strategy,&#160;we&#160;know&#160;that&#160;for&#160;agents<br/>
who&#160;have&#160;a&#160;chance&#160;to&#160;stop&#160;the&#160;cascade&#160;conditional&#160;on&#160;the&#160;observed&#160;history,&#160;the&#160;questions&#160;designed<br/>for&#160;them&#160;are&#160;restricted&#160;to&#160;the&#160;set&#160;of&#160;questions&#160;that&#160;maximize&#160;their&#160;expected&#160;utility.&#160;However,&#160;for<br/>agents&#160;indifferent&#160;to&#160;any&#160;questions,&#160;we&#160;can&#160;design&#160;any&#160;question&#160;for&#160;them.&#160;Thus,&#160;in&#160;order&#160;to&#160;design<br/>questions&#160;systematically,&#160;we&#160;categorize&#160;agents&#160;into&#160;two&#160;types&#160;conditional&#160;on&#160;the&#160;QGB&#160;in&#160;practice<br/>and&#160;the&#160;observed&#160;history.<br/>
Definition&#160;5.&#160;Given&#160;an&#160;observed&#160;history&#160;in&#160;a&#160;feasible&#160;and&#160;incentive&#160;compatible&#160;QGB,&#160;an&#160;agent&#160;is<br/>active&#160;if&#160;she&#160;has&#160;a&#160;positive&#160;probability&#160;to&#160;stop&#160;the&#160;cascade,&#160;otherwise&#160;she&#160;is&#160;called&#160;silent.<br/>
To&#160;further&#160;clarify&#160;the&#160;above&#160;definition,&#160;conditional&#160;on&#160;the&#160;history,&#160;agents&#160;who&#160;may&#160;benefit&#160;from<br/>
the&#160;answer&#160;of&#160;questions&#160;are&#160;active&#160;agents,&#160;otherwise&#160;they&#160;are&#160;silent.<br/>
11The&#160;telephone-game&#160;network&#160;has&#160;the&#160;same&#160;topology&#160;as&#160;a&#160;tandem&#160;network,&#160;but&#160;the&#160;literature&#160;on&#160;learning&#160;in&#160;tandem<br/>
networks&#160;uses&#160;one-way&#160;communication&#160;made&#160;before&#160;the&#160;next&#160;agent&#160;sees&#160;her&#160;private&#160;signal.&#160;In&#160;contrast,&#160;our&#160;questions<br/>are&#160;conditional&#160;on&#160;the&#160;received&#160;private&#160;signals.&#160;To&#160;avoid&#160;any&#160;confusion,&#160;we&#160;avoid&#160;the&#160;tandem&#160;network&#160;terminology.<br/>
5<br/>
<hr/>
<a name=7></a>3.2<br/>
Questions&#160;and&#160;Information&#160;Set&#160;Partition<br/>
Here,&#160;we&#160;detail&#160;how&#160;questions&#160;help&#160;gather&#160;information,&#160;and&#160;how&#160;the&#160;capacity&#160;constraints&#160;limit&#160;the<br/>(lossless)&#160;information&#160;aggregation.&#160;To&#160;begin,&#160;let&#160;Tn&#160;be&#160;the&#160;set&#160;of&#160;sequences&#160;of&#160;private&#160;signals&#160;from<br/>agent&#160;1&#160;to&#160;n−1,&#160;Tn&#160;3&#160;(si)n−1.&#160;The&#160;information&#160;space&#160;of&#160;agent&#160;n,&#160;corresponding&#160;to&#160;a&#160;observed<br/>
i=1<br/>
history&#160;Hn&#160;and&#160;the&#160;question&#160;guidebook&#160;Q,&#160;is&#160;the&#160;set&#160;of&#160;all&#160;feasible&#160;sequences&#160;T&#160;∗<br/>
n&#160;(Q,&#160;Hn)&#160;⊆&#160;Tn.<br/>
The&#160;questions&#160;assigned&#160;to&#160;agent&#160;n&#160;help&#160;her&#160;to&#160;update&#160;her&#160;posterior&#160;belief&#160;of&#160;the&#160;true&#160;state&#160;by<br/>partitioning&#160;T&#160;∗<br/>
n&#160;into&#160;information&#160;sets&#160;In(Q,&#160;Hn)&#160;and&#160;telling&#160;agent&#160;n&#160;at&#160;which&#160;set&#160;she&#160;is&#160;in.<br/>
For<br/>
simplicity&#160;of&#160;notation,&#160;we&#160;denote&#160;the&#160;collection&#160;of&#160;information&#160;sets&#160;In(Q,&#160;Hn)&#160;by&#160;In(Q,&#160;Hn).<br/>
By&#160;viewing&#160;question&#160;as&#160;an&#160;information&#160;set&#160;partition&#160;tool,&#160;studying&#160;the&#160;transition&#160;from&#160;In(Q,&#160;Hn)<br/>
to&#160;In+1(Q,&#160;Hn+1)&#160;can&#160;help&#160;us&#160;understand&#160;how&#160;information&#160;aggregates.&#160;A&#160;well-known&#160;approach&#160;to<br/>analyze&#160;this&#160;class&#160;of&#160;problems&#160;systematically&#160;is&#160;by&#160;mapping&#160;these&#160;information-set&#160;transitions&#160;to<br/>Markov&#160;chains&#160;with&#160;transition&#160;<a href="1811.00226v3s.html#7">matrices12.&#160;</a>To&#160;formulate&#160;the&#160;mapping,&#160;we&#160;associate&#160;a&#160;QGB&#160;with&#160;a<br/>sequence&#160;of&#160;sets&#160;of&#160;Markov&#160;chains&#160;sharing&#160;the&#160;same&#160;state&#160;space.&#160;Denote&#160;(G,&#160;(Mn))&#160;to&#160;be&#160;a&#160;sequence<br/>of&#160;sets&#160;of&#160;Markov&#160;chains,&#160;where&#160;G&#160;is&#160;the&#160;state&#160;set&#160;and&#160;Mn&#160;is&#160;the&#160;set&#160;of&#160;Markov&#160;chains&#160;at&#160;time&#160;n.<br/>To&#160;represent&#160;all&#160;distinguishable&#160;information&#160;sets,&#160;an&#160;inequality&#160;|G|&#160;≥&#160;sup<br/>
|I<br/>
n,Hn∈H,sn<br/>
n(Q,&#160;Hn)|&#160;is<br/>
required&#160;for&#160;the&#160;corresponding&#160;(G,&#160;(Mn)).&#160;Since&#160;state&#160;space&#160;G&#160;is&#160;shared&#160;by&#160;all&#160;Mn,&#160;hereafter,&#160;we<br/>simplify&#160;words&#160;“agent&#160;knows&#160;her&#160;information&#160;set&#160;corresponding&#160;to&#160;state&#160;Gi”&#160;to&#160;“agent&#160;goes&#160;to&#160;Gi.”<br/>
3.3<br/>
Conditions&#160;for&#160;Asymptotic&#160;Learning<br/>
In&#160;the&#160;threshold-based&#160;strategy&#160;proposed&#160;above,&#160;with&#160;the&#160;threshold&#160;is&#160;fixed&#160;and&#160;supposing&#160;that<br/>we&#160;are&#160;in&#160;a&#160;cascade,&#160;the&#160;number&#160;of&#160;silent&#160;agents&#160;between&#160;two&#160;active&#160;agents&#160;(if&#160;an<a href="1811.00226v3s.html#7">y)13&#160;</a>is&#160;only<br/>determined&#160;by&#160;the&#160;(prior)&#160;likelihood&#160;ratio&#160;of&#160;the&#160;first&#160;silent&#160;agent&#160;who&#160;arrives&#160;right&#160;after&#160;an&#160;active<br/>agent.&#160;Denote&#160;the&#160;number&#160;of&#160;silent&#160;agents&#160;between&#160;the&#160;k-th&#160;and&#160;k&#160;+&#160;1-th&#160;active&#160;agents&#160;by&#160;mk.&#160;One<br/>necessary&#160;condition&#160;to&#160;achieve&#160;asymptotic&#160;learning&#160;is&#160;having&#160;mk&#160;go&#160;to&#160;infinity&#160;with&#160;k.&#160;If&#160;this&#160;does<br/>not&#160;happen,&#160;then&#160;we&#160;always&#160;have&#160;a&#160;positive&#160;probability&#160;(lower-bounded&#160;by&#160;a&#160;constant)&#160;to&#160;stop&#160;a<br/>cascade,&#160;which&#160;will&#160;stop&#160;every&#160;correct&#160;cascade&#160;too.&#160;However,&#160;if&#160;mk&#160;goes&#160;to&#160;infinity&#160;too&#160;fast,&#160;then<br/>we&#160;cannot&#160;guarantee&#160;that&#160;a&#160;wrong&#160;cascade&#160;will&#160;eventually&#160;be&#160;stopped.&#160;Ergo,&#160;to&#160;achieve&#160;asymptotic<br/>learning,&#160;the&#160;key&#160;is&#160;to&#160;choose&#160;questions&#160;that&#160;carefully&#160;control&#160;the&#160;growth&#160;rate&#160;of&#160;mk.&#160;In&#160;the&#160;next<br/>Section,&#160;we&#160;will&#160;detail&#160;an&#160;implementation&#160;only&#160;using&#160;a&#160;1-bit&#160;question&#160;for&#160;each&#160;agent.&#160;The&#160;precise<br/>necessary&#160;and&#160;sufficient&#160;conditions&#160;to&#160;achieve&#160;learning&#160;for&#160;threshold-based&#160;QGBs&#160;will&#160;be&#160;presented<br/>in&#160;Lemma&#160;2.<br/>
4<br/>
Implementation&#160;of&#160;Threshold-based&#160;Strategy&#160;–&#160;Asymptotic<br/>Learning&#160;achieved&#160;in&#160;One-bit&#160;Questions<br/>
In&#160;this&#160;section,&#160;we&#160;present&#160;our&#160;main&#160;result:&#160;asymptotic&#160;learning&#160;is&#160;achievable&#160;via&#160;an&#160;explicit&#160;con-<br/>struction&#160;of&#160;a&#160;question&#160;guidebook&#160;that&#160;uses&#160;a&#160;threshold-based&#160;strategy&#160;in&#160;the&#160;telephone-game&#160;net-<br/>work&#160;where&#160;agents&#160;ask&#160;exactly&#160;a&#160;single&#160;one-bit&#160;question.<br/>
Theorem&#160;1.&#160;In&#160;the&#160;telephone-game&#160;network,&#160;there&#160;exists&#160;a&#160;question&#160;guidebook&#160;using&#160;1-bit&#160;capacity<br/>questions&#160;that&#160;achieves&#160;asymptotic&#160;learning.<br/>
Before&#160;presenting&#160;the&#160;proof,&#160;we&#160;first&#160;construct&#160;the&#160;QGB,&#160;and&#160;argue&#160;the&#160;feasibility&#160;and&#160;incentive<br/>
compatibility&#160;of&#160;the&#160;designed&#160;QGB.&#160;Then,&#160;we&#160;provide&#160;the&#160;necessary&#160;and&#160;sufficient&#160;conditions&#160;when<br/>this&#160;class&#160;of&#160;QGBs&#160;achieves&#160;asymptotic&#160;learning.&#160;Finally,&#160;we&#160;prove&#160;the&#160;theorem&#160;by&#160;showing&#160;the<br/>conditions&#160;are&#160;satisfied&#160;in&#160;the&#160;constructed&#160;QGB.<br/>
12To&#160;allay&#160;readers’&#160;concerns&#160;on&#160;what&#160;typical&#160;questions&#160;should&#160;look&#160;like&#160;and&#160;why&#160;we&#160;use&#160;Markov&#160;chains&#160;to&#160;model<br/>
the&#160;QGBs,&#160;an&#160;example&#160;demonstrating&#160;the&#160;delicateness&#160;of&#160;the&#160;design&#160;problem&#160;is&#160;in&#160;Appendix&#160;<a href="1811.00226v3s.html#20">B.1.</a><br/>
13We&#160;show&#160;that&#160;active&#160;agents&#160;cannot&#160;come&#160;consecutively&#160;in&#160;the&#160;proof&#160;of&#160;Claim&#160;<a href="1811.00226v3s.html#15">1&#160;</a>in&#160;Appendix&#160;<a href="1811.00226v3s.html#15">A.1</a><br/>
6<br/>
<hr/>
<a name=8></a>Construction&#160;of&#160;the&#160;Question&#160;Guidebook&#160;Here&#160;we&#160;implement&#160;a&#160;QGB&#160;using&#160;the&#160;threshold-<br/>based&#160;strategy&#160;introduced&#160;in&#160;Section&#160;<a href="1811.00226v3s.html#6">3.1.&#160;</a>Under&#160;the&#160;constraint&#160;of&#160;1-bit&#160;capacity&#160;on&#160;questions,&#160;we<br/>choose&#160;K&#160;=&#160;2.&#160;In&#160;other&#160;words,&#160;in&#160;the&#160;QGB&#160;we&#160;are&#160;going&#160;to&#160;construct,&#160;we&#160;know&#160;that&#160;once&#160;two<br/>consecutive&#160;silent&#160;agents&#160;get&#160;a&#160;private&#160;signal&#160;of&#160;the&#160;same&#160;type&#160;as&#160;the&#160;current&#160;cascade,&#160;there&#160;is&#160;no<br/>chance&#160;to&#160;stop&#160;the&#160;cascade&#160;at&#160;the&#160;immediate&#160;next&#160;active&#160;agent.<br/>
Without&#160;loss&#160;of&#160;generality&#160;we&#160;assume&#160;that&#160;the&#160;true&#160;state&#160;of&#160;the&#160;world&#160;is&#160;B&#160;so&#160;that&#160;an&#160;¯<br/>
A&#160;cascade<br/>
is&#160;a&#160;wrong&#160;cascade&#160;and&#160;a&#160;¯<br/>
B&#160;cascade&#160;is&#160;a&#160;correct&#160;one.&#160;Moreover,&#160;to&#160;avoid&#160;trivial&#160;questions&#160;in&#160;the<br/>
QGB,&#160;the&#160;question&#160;guidebook&#160;becomes&#160;operational&#160;only&#160;when&#160;a&#160;cascade&#160;is&#160;initiated.&#160;Thus,&#160;an&#160;agent<br/>not&#160;in&#160;a&#160;cascade&#160;uses&#160;her&#160;private&#160;signal&#160;and&#160;does&#160;not&#160;need&#160;the&#160;guidebook.<br/>
As&#160;described&#160;in&#160;Section&#160;<a href="1811.00226v3s.html#6">3.1,&#160;</a>we&#160;design&#160;different&#160;questions&#160;for&#160;active&#160;and&#160;silent&#160;agents&#160;in&#160;a&#160;cascade.<br/>
Since&#160;only&#160;1-bit&#160;questions&#160;are&#160;allowed,&#160;Section&#160;<a href="1811.00226v3s.html#7">3.2&#160;</a>and&#160;accompanying&#160;details&#160;in&#160;Appendix&#160;<a href="1811.00226v3s.html#24">B.5<br/></a>suggest&#160;that&#160;the&#160;QGB&#160;will&#160;consist&#160;of&#160;the&#160;partition&#160;of&#160;the&#160;(evolving)&#160;history&#160;into&#160;five&#160;sets.&#160;Next<br/>we&#160;illustrate&#160;the&#160;QGB&#160;by&#160;providing&#160;the&#160;corresponding&#160;Markov&#160;chains&#160;first&#160;and&#160;then&#160;detailing&#160;the<br/>questions&#160;actually&#160;being&#160;asked&#160;in&#160;each&#160;possible&#160;state.&#160;The&#160;Markov&#160;chains&#160;are&#160;depicted&#160;in&#160;Figure<br/><a href="1811.00226v3s.html#8">1&#160;</a>assuming&#160;that&#160;a&#160;¯<br/>
A&#160;cascade&#160;is&#160;underwa<a href="1811.00226v3s.html#8">y14,&#160;</a>and&#160;they&#160;prescribe&#160;how&#160;the&#160;information&#160;space&#160;gets<br/>
partitioned&#160;based&#160;on&#160;the&#160;type&#160;of&#160;the&#160;agent&#160;(active&#160;or&#160;silent),&#160;the&#160;private&#160;signal&#160;of&#160;the&#160;agent&#160;and&#160;the<br/>response&#160;from&#160;the&#160;immediate&#160;predecessor&#160;to&#160;the&#160;question&#160;(if&#160;it&#160;is&#160;asked).<br/>
Silent<br/>
Active<br/>
A,B<br/>
𝐺<br/>
Agents<br/>
Agents<br/>
𝐺<br/>
0<br/>
0<br/>
A,B<br/>
B<br/>
A<br/>
A,B<br/>
B<br/>
𝐺<br/>
A<br/>
1<br/>
𝐺2<br/>
𝐺1<br/>
𝐺2<br/>
B<br/>
A<br/>
A,B<br/>
A,B<br/>
B<br/>
𝐺<br/>
A<br/>
4<br/>
𝐺3<br/>
A<br/>
𝐺4<br/>
𝐺3<br/>
B<br/>
Figure&#160;1:&#160;Markov&#160;chains&#160;of&#160;proposed&#160;threshold-based&#160;question&#160;guidebook<br/>
The&#160;corresponding&#160;Markov&#160;chains&#160;in&#160;the&#160;designed&#160;QGB,&#160;as&#160;depicted&#160;in&#160;the&#160;left&#160;of&#160;Figure&#160;<a href="1811.00226v3s.html#8">1,</a><br/>
endows&#160;every&#160;silent&#160;agent&#160;with&#160;the&#160;same&#160;transition&#160;matrix.&#160;This&#160;transition&#160;matrix&#160;is&#160;given&#160;by&#160;two<br/>different&#160;determined&#160;questions&#160;conditional&#160;on&#160;the&#160;silent&#160;agent’s&#160;private&#160;<a href="1811.00226v3s.html#8">signal15;&#160;</a>and&#160;the&#160;questions<br/>and&#160;corresponding&#160;information&#160;sets&#160;are&#160;as&#160;follows.<br/>
Receives&#160;private&#160;signal&#160;B<br/>
Receives&#160;private&#160;signal&#160;A<br/>
Question&#160;asked<br/>
Are&#160;you&#160;in&#160;{G1,&#160;G2}?<br/>
Are&#160;you&#160;at&#160;G1?<br/>
Action&#160;under&#160;positive&#160;answer<br/>
Go&#160;to&#160;G1<br/>
Go&#160;to&#160;G2<br/>
Action&#160;under&#160;negative&#160;answer<br/>
Go&#160;to&#160;G4<br/>
Go&#160;to&#160;G3<br/>
Since&#160;every&#160;active&#160;agent&#160;only&#160;cares&#160;if&#160;her&#160;immediate&#160;predecessor&#160;is&#160;in&#160;G1&#160;when&#160;she&#160;receives&#160;a<br/>
private&#160;signal&#160;B&#160;so&#160;she&#160;can&#160;stop&#160;the&#160;cascade&#160;(play&#160;¯<br/>
B),&#160;questions&#160;are&#160;only&#160;needed&#160;in&#160;that&#160;case.<br/>
Receives&#160;private&#160;signal&#160;B<br/>
Receives&#160;private&#160;signal&#160;A<br/>
Question&#160;asked<br/>
Are&#160;you&#160;at&#160;G1?<br/>
No&#160;questions&#160;asked<br/>
Action&#160;under&#160;positive&#160;answer<br/>
Go&#160;to&#160;G0&#160;and&#160;stop&#160;cascade<br/>
Go&#160;to&#160;G1<br/>
Action&#160;under&#160;negative&#160;answer<br/>
Go&#160;to&#160;G1<br/>
14In&#160;a&#160;¯<br/>
B&#160;cascade,&#160;the&#160;same&#160;guidebook&#160;applies&#160;but&#160;with&#160;the&#160;As&#160;and&#160;Bs&#160;swapped.<br/>
15As&#160;described&#160;earlier,&#160;a&#160;silent&#160;agent’s&#160;partition&#160;can&#160;never&#160;be&#160;G0.<br/>
7<br/>
<hr/>
<a name=9></a>Before&#160;showing&#160;that&#160;the&#160;QGB&#160;is&#160;feasible&#160;and&#160;incentive&#160;compatible,&#160;we&#160;want&#160;to&#160;point&#160;out&#160;that<br/>
while&#160;there&#160;exist&#160;a&#160;large&#160;set&#160;of&#160;QGBs&#160;that&#160;can&#160;achieve&#160;asymptotic&#160;learning&#160;even&#160;with&#160;the&#160;1-bit<br/>constraint,&#160;the&#160;proposed&#160;design&#160;simplifies&#160;the&#160;analysis&#160;and&#160;proofs,&#160;and&#160;avoids&#160;solving&#160;complex<br/>recursive&#160;system&#160;of&#160;equations&#160;with&#160;four&#160;variables.<br/>Feasibility&#160;and&#160;incentive&#160;compatibility&#160;of&#160;the&#160;question&#160;guidebook&#160;With&#160;the&#160;proposed&#160;QGB<br/>in&#160;hand,&#160;the&#160;first&#160;step&#160;is&#160;to&#160;verify&#160;the&#160;feasibility&#160;and&#160;incentive&#160;compatibility.&#160;Feasibility&#160;of&#160;this&#160;QGB<br/>is&#160;straightforward&#160;because&#160;every&#160;agent,&#160;no&#160;matter&#160;whether&#160;she&#160;is&#160;active&#160;or&#160;silent,&#160;knows&#160;her&#160;current<br/>state.&#160;Therefore,&#160;she&#160;can&#160;definitely&#160;answer&#160;the&#160;yes-no&#160;question&#160;about&#160;her&#160;current&#160;state&#160;to&#160;pass&#160;the<br/>feasibility&#160;check.<br/>
Showing&#160;incentive&#160;compatibility&#160;is&#160;equivalent&#160;to&#160;showing&#160;that&#160;G1&#160;is&#160;the&#160;only&#160;state&#160;that&#160;can&#160;have<br/>
likelihood&#160;ratio&#160;of&#160;B&#160;over&#160;A&#160;crossing&#160;1&#160;for&#160;any&#160;active&#160;agent.&#160;Here,&#160;we&#160;will&#160;establish&#160;a&#160;result&#160;that<br/>applies&#160;to&#160;more&#160;generally&#160;than&#160;the&#160;designed&#160;QGB.&#160;We&#160;will&#160;prove&#160;that&#160;every&#160;threshold-based&#160;QGB<br/>has&#160;positive&#160;probability&#160;to&#160;stop&#160;the&#160;cascade&#160;only&#160;when&#160;the&#160;immediate&#160;predecessor&#160;of&#160;a&#160;active&#160;agent<br/>is&#160;at&#160;G1&#160;(threshold&#160;event&#160;not&#160;holding&#160;for&#160;current&#160;majority,&#160;i.e.,&#160;¯<br/>
A).<br/>
Definition&#160;6.&#160;Given&#160;a&#160;question&#160;guidebook&#160;such&#160;that&#160;every&#160;silent&#160;agent&#160;uses&#160;the&#160;same&#160;transition<br/>matrix,&#160;a&#160;question&#160;guidebook&#160;is&#160;threshold-based&#160;if&#160;for&#160;every&#160;silent&#160;agent&#160;whose&#160;neighbor&#160;is&#160;in&#160;a<br/>transient&#160;state&#160;(e.g.,&#160;G1,&#160;G2&#160;in&#160;this&#160;question&#160;guidebook)&#160;of&#160;the&#160;Markov&#160;chain,&#160;she&#160;goes&#160;to&#160;state&#160;Gi+1<br/>upon&#160;receiving&#160;a&#160;private&#160;signal&#160;in&#160;an&#160;observed&#160;majority&#160;or&#160;goes&#160;to&#160;Gmax{1,i−1}&#160;upon&#160;receiving&#160;a<br/>private&#160;signal&#160;in&#160;an&#160;observed&#160;minority.&#160;Furthermore,&#160;active&#160;agents&#160;continue&#160;the&#160;cascade&#160;bring&#160;all<br/>feasible&#160;sequence&#160;of&#160;private&#160;signal&#160;to&#160;G1.<br/>
Lemma&#160;1.&#160;In&#160;threshold-based&#160;question&#160;guidebooks,&#160;active&#160;agents&#160;can&#160;only&#160;stop&#160;the&#160;cascade&#160;at&#160;G1.<br/>
To&#160;show&#160;Lemma&#160;<a href="1811.00226v3s.html#9">1,&#160;</a>we&#160;first&#160;need&#160;to&#160;guarantee&#160;there&#160;exists&#160;at&#160;least&#160;one&#160;silent&#160;agent&#160;between&#160;any<br/>
pair&#160;of&#160;active&#160;agents,&#160;i.e.,&#160;active&#160;agents&#160;cannot&#160;arrive&#160;consecutively.&#160;The&#160;idea&#160;of&#160;the&#160;proof&#160;is&#160;that<br/>once&#160;an&#160;active&#160;agent&#160;fails&#160;to&#160;stop&#160;a&#160;cascade,&#160;it&#160;either&#160;gets&#160;an&#160;observed-majority&#160;private&#160;signal&#160;or&#160;the<br/>cascade&#160;will&#160;continue&#160;whatever&#160;private&#160;signal&#160;she&#160;gets.&#160;Then&#160;simple&#160;algebra&#160;rules&#160;out&#160;the&#160;possibility<br/>of&#160;consecutive&#160;active&#160;agents:&#160;see&#160;Claim&#160;<a href="1811.00226v3s.html#15">1&#160;</a>in&#160;Appendix&#160;<a href="1811.00226v3s.html#15">A.1.&#160;</a>Now,&#160;given&#160;the&#160;current&#160;active&#160;agent<br/>ak,&#160;if&#160;the&#160;next&#160;active&#160;agent&#160;indexed&#160;ak+1&#160;can&#160;stop&#160;cascade&#160;at&#160;state&#160;Gi&#160;for&#160;some&#160;i&#160;&gt;&#160;1,&#160;then&#160;agent<br/>ak+1&#160;−&#160;i&#160;+&#160;1&#160;also&#160;has&#160;the&#160;ability&#160;to&#160;stop&#160;the&#160;cascade&#160;at&#160;G1,&#160;which&#160;contradicts&#160;the&#160;fact&#160;that&#160;ak+1&#160;is<br/>the&#160;next&#160;active&#160;agent.&#160;The&#160;detailed&#160;proof&#160;is&#160;in&#160;Appendix&#160;<a href="1811.00226v3s.html#15">A.1.</a><br/>
Since&#160;the&#160;QGB&#160;we&#160;constructed&#160;is&#160;a&#160;threshold-based&#160;QGB&#160;and&#160;active&#160;agents&#160;stop&#160;a&#160;cascade&#160;only<br/>
in&#160;G1,&#160;Lemma&#160;<a href="1811.00226v3s.html#9">1&#160;</a>guarantees&#160;incentive&#160;compatibility.<br/>Necessary&#160;and&#160;sufficient&#160;conditions&#160;for&#160;asymptotic&#160;learning&#160;in&#160;threshold-based&#160;question<br/>guidebooks&#160;In&#160;order&#160;to&#160;show&#160;that&#160;the&#160;proposed&#160;QGB&#160;can&#160;achieve&#160;asymptotic&#160;learning,&#160;we&#160;provide<br/>a&#160;necessary&#160;and&#160;sufficient&#160;condition&#160;to&#160;achieve&#160;asymptotic&#160;learning&#160;for&#160;every&#160;threshold-based&#160;QGB.<br/>
Definition&#160;7.&#160;Let&#160;h+(m)&#160;be&#160;the&#160;probability&#160;that&#160;the&#160;wrong&#160;cascade&#160;will&#160;be&#160;stopped&#160;when&#160;mk&#160;=&#160;m,<br/>where&#160;mk&#160;is&#160;the&#160;number&#160;of&#160;silent&#160;agent&#160;between&#160;the&#160;(k&#160;−&#160;1)th&#160;and&#160;kth&#160;active&#160;agents.&#160;Similarly,<br/>h−(m)&#160;represents&#160;the&#160;probability&#160;that&#160;the&#160;right&#160;cascade&#160;will&#160;be&#160;stopped&#160;when&#160;mk&#160;=&#160;m.<br/>
Lemma&#160;2.&#160;Given&#160;a&#160;threshold-based&#160;question&#160;guidebook&#160;Q&#160;that&#160;is&#160;operational&#160;in&#160;a&#160;cascade.&#160;The<br/>following&#160;three&#160;conditions&#160;are&#160;necessary&#160;and&#160;sufficient&#160;for&#160;the&#160;question&#160;guidebook&#160;to&#160;achieve&#160;to<br/>achieve&#160;the&#160;asymptotic&#160;learning:<br/>
1&#160;limk→∞&#160;mk&#160;=&#160;∞;<br/>
2&#160;The&#160;growth&#160;rate&#160;of&#160;mk&#160;satisfies&#160;Π∞&#160;(1&#160;−&#160;h−(mk))&#160;&gt;&#160;Π∞&#160;(1&#160;−&#160;h+(mk))&#160;=&#160;0;<br/>
k=1<br/>
k=1<br/>
3&#160;The&#160;transition&#160;matrix&#160;M&#160;∗&#160;=&#160;MsMa&#160;is&#160;irreducible,&#160;where&#160;Ms&#160;is&#160;the&#160;transition&#160;matrix&#160;for&#160;silent<br/>
agents&#160;and&#160;Ma&#160;is&#160;the&#160;transition&#160;matrix&#160;for&#160;active&#160;agents&#160;who&#160;receive&#160;observed&#160;majority&#160;signals.<br/>
8<br/>
<hr/>
<a name=10></a>The&#160;first&#160;condition&#160;makes&#160;the&#160;frequency&#160;of&#160;active&#160;agents&#160;to&#160;go&#160;to&#160;0&#160;as&#160;time&#160;goes&#160;to&#160;infinity,<br/>
otherwise&#160;asymptotic&#160;learning&#160;cannot&#160;be&#160;achieve<a href="1811.00226v3s.html#10">d16.&#160;</a>Furthermore,&#160;we&#160;want&#160;every&#160;wrong&#160;cascade<br/>to&#160;be&#160;stopped&#160;with&#160;probability&#160;1,&#160;but&#160;also&#160;need&#160;the&#160;right&#160;cascade&#160;to&#160;have&#160;a&#160;positive&#160;probability&#160;to<br/>last&#160;forever.&#160;This&#160;constrains&#160;the&#160;maximum&#160;and&#160;minimum&#160;growth&#160;rate&#160;of&#160;mk,&#160;which&#160;is&#160;discussed&#160;in<br/>the&#160;second&#160;condition.&#160;The&#160;last&#160;condition&#160;guarantees&#160;that&#160;in&#160;a&#160;cascade,&#160;with&#160;an&#160;arbitrary&#160;number<br/>of&#160;silent&#160;agents&#160;followed&#160;by&#160;an&#160;active&#160;agent,&#160;all&#160;states&#160;can&#160;be&#160;visited.&#160;Without&#160;this&#160;condition,&#160;the<br/>QGB&#160;cannot&#160;correct&#160;all&#160;kinds&#160;of&#160;the&#160;wrong&#160;cascades&#160;and&#160;no&#160;learning&#160;is&#160;achievable.<br/>
4.1<br/>
Asymptotic&#160;Learning&#160;is&#160;achieved&#160;(Sketch&#160;of&#160;proof&#160;of&#160;Theorem&#160;1)<br/>
Since&#160;the&#160;last&#160;condition&#160;in&#160;Lemma&#160;<a href="1811.00226v3s.html#9">2&#160;</a>is&#160;trivially&#160;satisfied&#160;in&#160;the&#160;designed&#160;QGB,&#160;most&#160;of&#160;proof&#160;is&#160;on<br/>verifying&#160;the&#160;first&#160;two&#160;conditions&#160;in&#160;Lemma&#160;<a href="1811.00226v3s.html#9">2.&#160;</a>For&#160;this&#160;we&#160;have&#160;to&#160;analyze&#160;the&#160;growth&#160;rate&#160;of&#160;mk<br/>thoroughly.&#160;This&#160;following&#160;paragraphs&#160;will&#160;first&#160;characterize&#160;the&#160;form&#160;of&#160;mk,&#160;then&#160;study&#160;upper&#160;and<br/>lower&#160;bounds&#160;of&#160;its&#160;growth&#160;rate.&#160;With&#160;those&#160;bounds&#160;in&#160;hand,&#160;calculations&#160;can&#160;be&#160;done&#160;to&#160;show<br/>the&#160;wrong&#160;cascade&#160;will&#160;be&#160;stopped&#160;almost&#160;surely&#160;and&#160;the&#160;right&#160;state&#160;will&#160;last&#160;forever&#160;with&#160;positive<br/>probability&#160;(which&#160;can&#160;be&#160;lower-bounded&#160;by&#160;some&#160;constant).<br/>Form&#160;of&#160;number&#160;of&#160;silent&#160;agents&#160;To&#160;study&#160;the&#160;growth&#160;rate&#160;of&#160;mk,&#160;we&#160;need&#160;to&#160;know&#160;exactly&#160;how<br/>many&#160;of&#160;agents&#160;between&#160;each&#160;pair&#160;of&#160;consecutive&#160;active&#160;agents.<br/>
Prior&#160;to&#160;this,&#160;we&#160;need&#160;to&#160;specify&#160;the&#160;functions&#160;h+(m)&#160;and&#160;h−(m)&#160;first.&#160;With&#160;threshold&#160;K&#160;=&#160;2,<br/>
two&#160;consecutive&#160;majority&#160;signals&#160;in&#160;a&#160;cascade&#160;will&#160;continue&#160;the&#160;cascade&#160;at&#160;the&#160;next&#160;active&#160;agent.<br/>Simple&#160;combinatorics&#160;yields&#160;h+(m)&#160;and&#160;h−(m)&#160;as&#160;follows:<br/>
m/2<br/>
m/2<br/>
<br/>
<br/>
<br/>
<br/>
X<br/>
m&#160;−&#160;i&#160;−&#160;1<br/>
X<br/>
m&#160;−&#160;i&#160;−&#160;1<br/>
h+(m)&#160;=<br/>
pm+1−i(1&#160;−&#160;p)i;<br/>
h−(m)&#160;=<br/>
pi(1&#160;−&#160;p)m+1−i.&#160;(1)<br/>
i<br/>
i<br/>
i=0<br/>
i=0<br/>
Furthermore,&#160;with&#160;Lemma&#160;<a href="1811.00226v3s.html#9">1,&#160;</a>we&#160;know&#160;that&#160;the&#160;likelihood&#160;ratio&#160;of&#160;B&#160;versus&#160;A&#160;at&#160;state&#160;G1&#160;is&#160;the<br/>only&#160;parameter&#160;that&#160;the&#160;next&#160;active&#160;agent&#160;needs&#160;to&#160;compute.&#160;Suppose&#160;we&#160;know&#160;the&#160;likelihood<br/>ratio&#160;of&#160;the&#160;first&#160;silent&#160;agent&#160;right&#160;after&#160;ak,&#160;the&#160;next&#160;active&#160;agent&#160;ak+1&#160;is&#160;the&#160;first&#160;agent&#160;who&#160;could<br/>have&#160;likelihood&#160;ratio&#160;at&#160;G1&#160;crossing&#160;1.&#160;Since&#160;h+(m)(h−(m))&#160;is&#160;the&#160;probability&#160;that&#160;an&#160;agent&#160;and<br/>her&#160;mth&#160;successor&#160;are&#160;both&#160;at&#160;G1&#160;conditional&#160;on&#160;the&#160;right(wrong)&#160;cascade&#160;not&#160;yet&#160;stopped.&#160;The<br/>ratio&#160;of&#160;h+(m)&#160;over&#160;h−(m)&#160;is&#160;the&#160;likelihood&#160;ratio&#160;of&#160;B&#160;versus&#160;A&#160;conditioned&#160;on&#160;the&#160;event&#160;that&#160;the<br/>cascade&#160;continues&#160;after&#160;m&#160;silent&#160;agents.&#160;Hence,&#160;by&#160;definition&#160;of&#160;a&#160;silent&#160;agent,&#160;if&#160;the&#160;agent&#160;with<br/>
H<br/>
index&#160;ak−1&#160;+&#160;m&#160;is&#160;silent,&#160;she&#160;must&#160;have&#160;likelihood&#160;ratio&#160;at&#160;G<br/>
ak−1+1&#160;h+(m)<br/>
1,&#160;`<br/>
&lt;&#160;1.&#160;Given&#160;the&#160;fact<br/>
G1<br/>
h−(m)<br/>
that&#160;h+(m)&#160;is&#160;an&#160;strictly&#160;increasing&#160;function&#160;of&#160;m&#160;for&#160;all&#160;p&#160;&gt;&#160;0.5,&#160;the&#160;number&#160;of&#160;silent&#160;agents&#160;mk<br/>
h−(m)<br/>
between&#160;active&#160;agents&#160;ak&#160;to&#160;ak+1&#160;can&#160;be&#160;mathematically&#160;defined&#160;as:<br/>
H<br/>
h+(m)<br/>
mk&#160;≡&#160;min{m|`&#160;ak+1<br/>
≥&#160;1}.<br/>
(2)<br/>
G1<br/>
h−(m)<br/>
Then,&#160;since&#160;every&#160;active&#160;agent&#160;failing&#160;to&#160;stop&#160;the&#160;cascade&#160;has&#160;only&#160;one&#160;information&#160;set&#160;cor-<br/>
responding&#160;to&#160;G1,&#160;there&#160;is&#160;a&#160;simple&#160;recursive&#160;form&#160;of&#160;likelihood&#160;ratio&#160;at&#160;state&#160;G1&#160;between&#160;first<br/>silent&#160;agents&#160;after&#160;kth&#160;and&#160;(k&#160;+&#160;1)th&#160;active&#160;agents&#160;by&#160;using&#160;the&#160;ratio&#160;of&#160;probability&#160;that&#160;the&#160;cascade<br/>
H<br/>
continuous.&#160;The&#160;recursive&#160;form&#160;of&#160;`&#160;ak+1+1&#160;a&#160;strictly&#160;<a href="1811.00226v3s.html#10">decreasing17&#160;</a>function&#160;of&#160;k,&#160;is&#160;given&#160;by:<br/>
G1<br/>
H<br/>
H<br/>
1&#160;−&#160;h+(mk)<br/>
`&#160;ak+1+1&#160;=&#160;`&#160;ak+1<br/>
(3)<br/>
G1<br/>
G1<br/>
1&#160;−&#160;h−(mk)<br/>
With&#160;functions&#160;h+(m),&#160;h−(m),&#160;and&#160;<a href="1811.00226v3s.html#10">(3),&#160;</a>mk&#160;is&#160;non-decreasing&#160;and&#160;can&#160;be&#160;computed&#160;iteratively.<br/>
16If&#160;we&#160;have&#160;a&#160;non-zero&#160;proportion&#160;of&#160;agents&#160;that&#160;take&#160;actions&#160;according&#160;to&#160;their&#160;private&#160;signals,&#160;the&#160;probability&#160;of<br/>
the&#160;right&#160;action&#160;is&#160;upper&#160;bounded&#160;away&#160;from&#160;1.<br/>
17See&#160;Appendix&#160;<a href="1811.00226v3s.html#18">A.7.1&#160;</a>for&#160;the&#160;proof.<br/>
9<br/>
<hr/>
<a name=11></a>Upper&#160;bound&#160;of&#160;growth&#160;rate&#160;of&#160;mk&#160;If&#160;asymptotic&#160;learning&#160;can&#160;be&#160;achieved&#160;under&#160;this&#160;QGB,<br/>every&#160;wrong&#160;cascade&#160;must&#160;be&#160;stopped,&#160;i.e.,&#160;Π∞&#160;(1&#160;−&#160;h+(mk))&#160;=&#160;0.&#160;Thus,&#160;if&#160;we&#160;can&#160;find&#160;a&#160;sequence<br/>
k=1<br/>
wk&#160;≥&#160;mk,&#160;∀k,&#160;and&#160;Π∞&#160;(1−h+(wk))&#160;=&#160;0,&#160;then&#160;h+(mk)&#160;≥&#160;h+(wk)&#160;guarantees&#160;Π∞&#160;(1−h+(mk))&#160;=&#160;0.<br/>
k=1<br/>
k=1<br/>
Finding&#160;the&#160;upper&#160;bound&#160;of&#160;the&#160;growth&#160;rate&#160;of&#160;mk&#160;is&#160;equivalent&#160;to&#160;finding&#160;the&#160;lower&#160;bound&#160;of<br/>sequence&#160;ns&#160;such&#160;that&#160;mk−1&#160;=&#160;s&#160;−&#160;1&#160;and&#160;mk+i−1&#160;=&#160;s&#160;for&#160;all&#160;i&#160;≤&#160;ns.&#160;Now,&#160;suppose&#160;mk&#160;=&#160;s,<br/>mk−1&#160;=&#160;s&#160;−&#160;1,&#160;we&#160;can&#160;calculate&#160;ns&#160;(See&#160;detailed&#160;calculations&#160;in&#160;<a href="1811.00226v3s.html#16">A.3)&#160;</a>to&#160;get<br/>
<br/>
h+(s)<br/>
<br/>
&#160;h+(s)h−(s&#160;−&#160;1)&#160;<br/>
ln(c<br/>
<br/>
Hat−1+1<br/>
<br/>
1(p))<br/>
{mt&#160;=&#160;s|`<br/>
≥&#160;1}&#160;≥&#160;n<br/>
≥<br/>
,<br/>
(4)<br/>
G<br/>
<br/>
1<br/>
s&#160;&gt;&#160;ln<br/>
<br/>
h−(s)<br/>
<br/>
h−(s)h+(s&#160;−&#160;1)<br/>
ps&#160;+&#160;p2s<br/>
where&#160;c1(p)&#160;is&#160;only&#160;a&#160;function&#160;of&#160;p.<br/>Wrong&#160;cascade&#160;will&#160;be&#160;stopped&#160;almost&#160;surely&#160;Taking&#160;the&#160;inequality&#160;<a href="1811.00226v3s.html#11">(4)&#160;</a>into&#160;the&#160;condition&#160;2<br/>in&#160;Lemma&#160;<a href="1811.00226v3s.html#9">2,&#160;</a>the&#160;probability&#160;that&#160;a&#160;wrong&#160;cascade&#160;will&#160;be&#160;stopped&#160;<a href="1811.00226v3s.html#11">is18</a><br/>
P(A&#160;wrong&#160;cascade&#160;can&#160;be&#160;stopped)&#160;=&#160;1&#160;−&#160;Π∞&#160;(1&#160;−&#160;h+(mk))&#160;≥&#160;1&#160;−&#160;Π∞&#160;(1&#160;−&#160;pmk&#160;)<br/>
k=1<br/>
k=1<br/>
<br/>
<br/>
≥<br/>
min{j|mj+1=J}<br/>
1&#160;−&#160;Π<br/>
(1&#160;−&#160;pmk&#160;)&#160;exp<br/>
−&#160;p&#160;ln(c<br/>
1<br/>
=&#160;1<br/>
(5)<br/>
k=1<br/>
1(p))&#160;P∞<br/>
n=J&#160;1+pn<br/>
Lower&#160;bound&#160;of&#160;growth&#160;rate&#160;of&#160;mk&#160;and&#160;the&#160;probability&#160;of&#160;stopping&#160;a&#160;right&#160;cascade<br/>Similarly,&#160;to&#160;show&#160;that&#160;P(a&#160;right&#160;cascade&#160;will&#160;be&#160;stopped)&#160;&lt;&#160;1,&#160;we&#160;can&#160;show&#160;that&#160;a&#160;lower&#160;bound&#160;of<br/>Π∞&#160;(1&#160;−&#160;h−(mk))&#160;is&#160;positive.&#160;Thus,&#160;we&#160;now&#160;need&#160;a&#160;lower&#160;bound&#160;of&#160;the&#160;growth&#160;rate&#160;of&#160;mk.&#160;Using<br/>
k=1<br/>
a&#160;similar&#160;technique&#160;as&#160;for&#160;<a href="1811.00226v3s.html#11">(4),&#160;</a>we&#160;derive&#160;an&#160;opposite&#160;inequality&#160;for&#160;¯<br/>
ns&#160;in&#160;Appendix&#160;<a href="1811.00226v3s.html#17">A.5,&#160;</a>and&#160;then<br/>
the&#160;probability&#160;that&#160;a&#160;right&#160;cascade&#160;will&#160;be&#160;stopped&#160;is<br/>
∞<br/>
&#160;X<br/>
1<br/>
<br/>
P(A&#160;right&#160;cascade&#160;will&#160;be&#160;stopped)&#160;≤&#160;1&#160;−&#160;B(p)&#160;exp<br/>
,<br/>
(6)<br/>
c4(p)c1(p)n&#160;−&#160;1<br/>
n=&#160;¯<br/>
J<br/>
min{j|mj+1=&#160;¯<br/>
J&#160;}<br/>
where&#160;B(p)&#160;=&#160;c<br/>
1<br/>
2(p)ec3(p)Π<br/>
(1&#160;−&#160;h−(k)).&#160;Since&#160;P∞<br/>
converges&#160;by&#160;the&#160;ratio<br/>
k=1<br/>
n=&#160;¯<br/>
J&#160;c4(p)c1(p)n−1<br/>
test,&#160;the&#160;RHS&#160;of&#160;<a href="1811.00226v3s.html#11">(6)&#160;</a>is&#160;less&#160;than&#160;1,&#160;so&#160;that&#160;a&#160;right&#160;cascade&#160;can&#160;last&#160;forever&#160;with&#160;a&#160;positive&#160;probability.<br/>
Now,&#160;every&#160;wrong&#160;cascade&#160;will&#160;be&#160;stopped&#160;but&#160;there&#160;is&#160;a&#160;positive&#160;probability&#160;that&#160;a&#160;right&#160;cascade<br/>
will&#160;continue&#160;forever,&#160;so&#160;the&#160;second&#160;condition&#160;is&#160;satisfied.&#160;Furthermore,&#160;since&#160;the&#160;lower&#160;bound&#160;and<br/>upper&#160;bound&#160;of&#160;growth&#160;rate&#160;¯<br/>
ns&#160;suggest&#160;a&#160;finite&#160;interval&#160;of&#160;mk&#160;=&#160;s,&#160;mk&#160;goes&#160;to&#160;infinity&#160;as&#160;k&#160;goes<br/>
to&#160;infinity,&#160;so&#160;the&#160;first&#160;condition&#160;also&#160;holds.&#160;Thus,&#160;asymptotic&#160;learning&#160;can&#160;be&#160;achieved&#160;under&#160;this<br/>QGB.&#160;Once&#160;we’re&#160;out&#160;of&#160;a&#160;cascade,&#160;agents&#160;use&#160;their&#160;private&#160;signals&#160;and&#160;that&#160;will&#160;initiate&#160;another<br/>cascade&#160;with&#160;a&#160;bias&#160;towards&#160;a&#160;right&#160;cascade.&#160;Nevertheless,&#160;every&#160;wrong&#160;cascade&#160;will&#160;be&#160;stopped&#160;in<br/>finite&#160;time&#160;and&#160;an&#160;unstoppable&#160;right&#160;cascade&#160;happens&#160;after&#160;finitely&#160;many&#160;stopped&#160;right&#160;cascades.<br/>Thus,&#160;the&#160;learning&#160;happens&#160;almost&#160;surely&#160;instead&#160;of&#160;just&#160;in&#160;probability,&#160;as&#160;in&#160;Definition&#160;<a href="1811.00226v3s.html#4">1,&#160;</a>so&#160;that<br/>in&#160;finite&#160;time&#160;learning&#160;occurs.<br/>
5<br/>
Conclusion<br/>
We&#160;have&#160;shown&#160;that&#160;in&#160;the&#160;sequential&#160;social&#160;learning&#160;model&#160;of&#160;BHW&#160;<a href="1811.00226v3s.html#12">[1],&#160;</a>agents&#160;avoid&#160;wrong&#160;cascades<br/>and&#160;achieve&#160;asymptotic&#160;learning&#160;by&#160;asking&#160;one&#160;well&#160;designed&#160;binary&#160;question&#160;to&#160;the&#160;preceeding<br/>agent.&#160;To&#160;do&#160;this,&#160;we&#160;develop&#160;a&#160;question&#160;guidebook&#160;that&#160;the&#160;agents&#160;can&#160;use&#160;to&#160;ask&#160;questions&#160;such<br/>that&#160;the&#160;agent&#160;can&#160;always&#160;answer&#160;the&#160;question,&#160;and&#160;agents&#160;always&#160;ask&#160;a&#160;question&#160;that&#160;best&#160;serves<br/>their&#160;self&#160;interest.&#160;Determining&#160;the&#160;distribution&#160;of&#160;the&#160;time&#160;of&#160;learning&#160;or&#160;finding&#160;the&#160;best&#160;question<br/>guidebook&#160;to&#160;minimize&#160;some&#160;statistic&#160;of&#160;the&#160;time&#160;of&#160;learning&#160;is&#160;for&#160;future&#160;work.&#160;Generalizing&#160;from<br/>binary&#160;private&#160;signals&#160;to&#160;other&#160;discrete&#160;signals&#160;and&#160;then&#160;to&#160;the&#160;framework&#160;of&#160;<a href="1811.00226v3s.html#12">[4],&#160;</a>or&#160;to&#160;consider<br/>multiple&#160;states&#160;of&#160;nature&#160;<a href="1811.00226v3s.html#12">[5]&#160;</a>is&#160;also&#160;for&#160;future&#160;work.<br/>
18See&#160;Appendix&#160;<a href="1811.00226v3s.html#17">A.4&#160;</a>for&#160;detailed&#160;calculation<br/>
10<br/>
<hr/>
<a name=12></a>References<br/>
[1]&#160;S.&#160;Bikhchandani,&#160;D.&#160;Hirshleifer,&#160;and&#160;I.&#160;Welch,&#160;“A&#160;theory&#160;of&#160;fads,&#160;fashion,&#160;custom,&#160;and&#160;cultural<br/>
change&#160;as&#160;informational&#160;cascades,”&#160;Journal&#160;of&#160;political&#160;Economy,&#160;vol.&#160;100,&#160;no.&#160;5,&#160;pp.&#160;992–1026,<br/>1992.<br/>
[2]&#160;I.&#160;Welch,&#160;“Sequential&#160;sales,&#160;learning,&#160;and&#160;cascades,”&#160;The&#160;Journal&#160;of&#160;finance,&#160;vol.&#160;47,&#160;no.&#160;2,&#160;pp.<br/>
695–732,&#160;1992.<br/>
[3]&#160;A.&#160;V.&#160;Banerjee,&#160;“A&#160;simple&#160;model&#160;of&#160;herd&#160;behavior,”&#160;The&#160;quarterly&#160;journal&#160;of&#160;economics,&#160;vol.<br/>
107,&#160;no.&#160;3,&#160;pp.&#160;797–817,&#160;1992.<br/>
[4]&#160;L.&#160;Smith&#160;and&#160;P.&#160;Sørensen,&#160;“Pathological&#160;outcomes&#160;of&#160;observational&#160;learning,”&#160;Econometrica,<br/>
vol.&#160;68,&#160;no.&#160;2,&#160;pp.&#160;371–398,&#160;2000.<br/>
[5]&#160;P.&#160;N.&#160;Sørensen,&#160;“Rational&#160;social&#160;learning,”&#160;Ph.D.&#160;dissertation,&#160;Massachusetts&#160;Institute&#160;of&#160;Tech-<br/>
nology,&#160;1996.<br/>
[6]&#160;W.&#160;Hann-Caruthers,&#160;V.&#160;V.&#160;Martynov,&#160;and&#160;O.&#160;Tamuz,&#160;“The&#160;speed&#160;of&#160;sequential&#160;asymptotic<br/>
learning,”&#160;Journal&#160;of&#160;Economic&#160;Theory,&#160;vol.&#160;173,&#160;pp.&#160;383–409,&#160;2018.<br/>
[7]&#160;D.&#160;Acemoglu,&#160;A.&#160;Makhdoumi,&#160;A.&#160;Malekian,&#160;and&#160;A.&#160;Ozdaglar,&#160;“Fast&#160;and&#160;slow&#160;learning&#160;from<br/>
reviews,”&#160;National&#160;Bureau&#160;of&#160;Economic&#160;Research,&#160;Tech.&#160;Rep.,&#160;2017.<br/>
[8]&#160;D.&#160;Acemoglu,&#160;M.&#160;A.&#160;Dahleh,&#160;I.&#160;Lobel,&#160;and&#160;A.&#160;Ozdaglar,&#160;“Bayesian&#160;learning&#160;in&#160;social&#160;networks,”<br/>
The&#160;Review&#160;of&#160;Economic&#160;Studies,&#160;vol.&#160;78,&#160;no.&#160;4,&#160;pp.&#160;1201–1236,&#160;2011.<br/>
[9]&#160;I.&#160;H.&#160;Lee,&#160;“On&#160;the&#160;convergence&#160;of&#160;informational&#160;cascades,”&#160;Journal&#160;of&#160;Economic&#160;theory,&#160;vol.&#160;61,<br/>
no.&#160;2,&#160;pp.&#160;395–411,&#160;1993.<br/>
[10]&#160;F.&#160;Gul&#160;and&#160;R.&#160;Lundholm,&#160;“Endogenous&#160;timing&#160;and&#160;the&#160;clustering&#160;of&#160;agents’&#160;decisions,”&#160;Journal<br/>
of&#160;political&#160;Economy,&#160;vol.&#160;103,&#160;no.&#160;5,&#160;pp.&#160;1039–1066,&#160;1995.<br/>
[11]&#160;X.&#160;Vives,&#160;“Learning&#160;from&#160;others:&#160;a&#160;welfare&#160;analysis,”&#160;Games&#160;and&#160;Economic&#160;Behavior,&#160;vol.&#160;20,<br/>
no.&#160;2,&#160;pp.&#160;177–200,&#160;1997.<br/>
[12]&#160;S.&#160;Huck&#160;and&#160;J.&#160;Oechssler,&#160;“Informational&#160;cascades&#160;with&#160;continuous&#160;action&#160;spaces,”&#160;Economics<br/>
Letters,&#160;vol.&#160;60,&#160;no.&#160;2,&#160;pp.&#160;163–166,&#160;1998.<br/>
[13]&#160;E.&#160;Mossel,&#160;A.&#160;Sly,&#160;and&#160;O.&#160;Tamuz,&#160;“Strategic&#160;learning&#160;and&#160;the&#160;topology&#160;of&#160;social&#160;networks,”<br/>
Econometrica,&#160;vol.&#160;83,&#160;no.&#160;5,&#160;pp.&#160;1755–1794,&#160;2015.<br/>
[14]&#160;T.&#160;M.&#160;Cover,&#160;“Hypothesis&#160;testing&#160;with&#160;finite&#160;statistics,”&#160;The&#160;Annals&#160;of&#160;Mathematical&#160;Statistics,<br/>
vol.&#160;40,&#160;no.&#160;3,&#160;pp.&#160;828–835,&#160;1969.<br/>
[15]&#160;M.&#160;E.&#160;Hellman&#160;and&#160;T.&#160;M.&#160;Cover,&#160;“Learning&#160;with&#160;finite&#160;memory,”&#160;The&#160;Annals&#160;of&#160;Mathematical<br/>
Statistics,&#160;pp.&#160;765–782,&#160;1970.<br/>
[16]&#160;K.&#160;Drakopoulos,&#160;A.&#160;Ozdaglar,&#160;and&#160;J.&#160;Tsitsiklis,&#160;“On&#160;learning&#160;with&#160;finite&#160;memory,”&#160;arXiv<br/>
preprint&#160;arXiv:1209.1122,&#160;2012.<br/>
[17]&#160;E.&#160;Kamenica&#160;and&#160;M.&#160;Gentzkow,&#160;“Bayesian&#160;persuasion,”&#160;American&#160;Economic&#160;Review,&#160;vol.&#160;101,<br/>
no.&#160;6,&#160;pp.&#160;2590–2615,&#160;2011.<br/>
11<br/>
<hr/>
<a name=13></a>[18]&#160;L.&#160;Rayo&#160;and&#160;I.&#160;Segal,&#160;“Optimal&#160;information&#160;disclosure,”&#160;Journal&#160;of&#160;political&#160;Economy,&#160;vol.&#160;118,<br/>
no.&#160;5,&#160;pp.&#160;949–987,&#160;2010.<br/>
[19]&#160;D.&#160;Easley&#160;and&#160;J.&#160;Kleinberg,&#160;“Networks,&#160;crowds,&#160;and&#160;markets,”&#160;Cambridge&#160;Books,&#160;2012.<br/>
[20]&#160;T.&#160;N.&#160;Le,&#160;V.&#160;G.&#160;Subramanian,&#160;and&#160;R.&#160;A.&#160;Berry,&#160;“Quantifying&#160;the&#160;utility&#160;of&#160;imperfect&#160;reviews&#160;in<br/>
stopping&#160;information&#160;cascades,”&#160;in&#160;Decision&#160;and&#160;Control&#160;(CDC),&#160;2016&#160;IEEE&#160;55th&#160;Conference<br/>on.<br/>
IEEE,&#160;2016,&#160;pp.&#160;6990–6995.<br/>
[21]&#160;J.&#160;Hedlund,&#160;“Bayesian&#160;persuasion&#160;by&#160;a&#160;privately&#160;informed&#160;sender,”&#160;Journal&#160;of&#160;Economic&#160;The-<br/>
ory,&#160;vol.&#160;167,&#160;pp.&#160;229–268,&#160;2017.<br/>
[22]&#160;J.&#160;C.&#160;Ely&#160;and&#160;M.&#160;Szydlowski,&#160;“Moving&#160;the&#160;goalposts,”&#160;Working&#160;paper,&#160;Tech.&#160;Rep.,&#160;2017.<br/>
[23]&#160;I.&#160;Monz´<br/>
on,&#160;“Aggregate&#160;uncertainty&#160;can&#160;lead&#160;to&#160;incorrect&#160;herds,”&#160;American&#160;Economic&#160;Journal:<br/>
Microeconomics,&#160;vol.&#160;9,&#160;no.&#160;2,&#160;pp.&#160;295–314,&#160;2017.<br/>
[24]&#160;T.&#160;N.&#160;Le,&#160;V.&#160;G.&#160;Subramanian,&#160;and&#160;R.&#160;A.&#160;Berry,&#160;“Information&#160;cascades&#160;with&#160;noise,”&#160;IEEE<br/>
Transactions&#160;on&#160;Signal&#160;and&#160;Information&#160;Processing&#160;over&#160;Networks,&#160;vol.&#160;3,&#160;no.&#160;2,&#160;pp.&#160;239–251,<br/>2017.<br/>
[25]&#160;Z.&#160;Zhang,&#160;E.&#160;K.&#160;Chong,&#160;A.&#160;Pezeshki,&#160;and&#160;W.&#160;Moran,&#160;“Hypothesis&#160;testing&#160;in&#160;feedforward<br/>
networks&#160;with&#160;broadcast&#160;failures,”&#160;IEEE&#160;Journal&#160;of&#160;Selected&#160;Topics&#160;in&#160;Signal&#160;Processing,&#160;vol.&#160;7,<br/>no.&#160;5,&#160;pp.&#160;797–810,&#160;2013.<br/>
[26]&#160;Y.&#160;Wang&#160;and&#160;P.&#160;M.&#160;Djuri´<br/>
c,&#160;“Social&#160;learning&#160;with&#160;bayesian&#160;agents&#160;and&#160;random&#160;decision&#160;making,”<br/>
IEEE&#160;Transactions&#160;on&#160;Signal&#160;Processing,&#160;vol.&#160;63,&#160;no.&#160;12,&#160;pp.&#160;3241–3250,&#160;2015.<br/>
[27]&#160;T.&#160;N.&#160;Le,&#160;V.&#160;G.&#160;Subramanian,&#160;and&#160;R.&#160;A.&#160;Berry,&#160;“Learning&#160;from&#160;randomly&#160;arriving&#160;agents,”&#160;in<br/>
Communication,&#160;Control,&#160;and&#160;Computing&#160;(Allerton),&#160;2017&#160;55th&#160;Annual&#160;Allerton&#160;Conference<br/>on.<br/>
IEEE,&#160;2017,&#160;pp.&#160;196–197.<br/>
[28]&#160;W.&#160;P.&#160;Tay,&#160;J.&#160;N.&#160;Tsitsiklis,&#160;and&#160;M.&#160;Z.&#160;Win,&#160;“Bayesian&#160;detection&#160;in&#160;bounded&#160;height&#160;tree&#160;net-<br/>
works,”&#160;IEEE&#160;Trans.&#160;Signal&#160;Process.,&#160;vol.&#160;57,&#160;no.&#160;10,&#160;pp.&#160;4042&#160;–&#160;4051,&#160;Oct.&#160;2009.<br/>
[29]&#160;K.&#160;Drakopoulos,&#160;A.&#160;Ozdaglar,&#160;and&#160;J.&#160;N.&#160;Tsitsiklis,&#160;“When&#160;is&#160;a&#160;network&#160;epidemic&#160;hard&#160;to<br/>
eliminate?”&#160;Mathematics&#160;of&#160;Operations&#160;Research,&#160;vol.&#160;42,&#160;no.&#160;1,&#160;pp.&#160;1–14,&#160;2016.<br/>
[30]&#160;W.&#160;P.&#160;Tay,&#160;J.&#160;N.&#160;Tsitsiklis,&#160;and&#160;M.&#160;Z.&#160;Win,&#160;“On&#160;the&#160;subexponential&#160;decay&#160;of&#160;detection&#160;error<br/>
probabilities&#160;in&#160;long&#160;tandems,”&#160;IEEE&#160;Transactions&#160;on&#160;Information&#160;Theory,&#160;vol.&#160;54,&#160;no.&#160;10,&#160;pp.<br/>4767–4771,&#160;2008.<br/>
[31]&#160;J.&#160;Wu,&#160;“Helpful&#160;laymen&#160;in&#160;informational&#160;cascades,”&#160;Journal&#160;of&#160;Economic&#160;Behavior&#160;&amp;&#160;Organi-<br/>
zation,&#160;vol.&#160;116,&#160;pp.&#160;407–415,&#160;2015.<br/>
[32]&#160;S.&#160;Vaccari,&#160;M.&#160;Scarsini,&#160;and&#160;C.&#160;Maglaras,&#160;“Social&#160;learning&#160;in&#160;a&#160;competitive&#160;market&#160;with&#160;con-<br/>
sumer&#160;reviews,”&#160;2016.<br/>
[33]&#160;D.&#160;Acemoglu,&#160;A.&#160;Makhdoumi,&#160;A.&#160;Malekian,&#160;and&#160;A.&#160;Ozdaglar,&#160;“Informational&#160;braess’&#160;paradox:<br/>
The&#160;effect&#160;of&#160;information&#160;on&#160;traffic&#160;congestion,”&#160;arXiv&#160;preprint&#160;arXiv:1601.02039,&#160;2016.<br/>
[34]&#160;Y.&#160;Peres,&#160;M.&#160;Z.&#160;Racz,&#160;A.&#160;Sly,&#160;and&#160;I.&#160;Stuhl,&#160;“How&#160;fragile&#160;are&#160;information&#160;cascades?”&#160;arXiv<br/>
preprint&#160;arXiv:1711.04024,&#160;2017.<br/>
12<br/>
<hr/>
<a name=14></a>[35]&#160;A.&#160;Banerjee&#160;and&#160;D.&#160;Fudenberg,&#160;“Word-of-mouth&#160;learning,”&#160;Games&#160;and&#160;economic&#160;behavior,<br/>
vol.&#160;46,&#160;no.&#160;1,&#160;pp.&#160;1–22,&#160;2004.<br/>
[36]&#160;L.&#160;Smith&#160;and&#160;P.&#160;Sørensen,&#160;“Rational&#160;social&#160;learning&#160;with&#160;random&#160;sampling,”&#160;Available&#160;at&#160;SSRN<br/>
1138095,&#160;2008.<br/>
[37]&#160;D.&#160;Sgroi,&#160;“Optimizing&#160;information&#160;in&#160;the&#160;herd:&#160;Guinea&#160;pigs,&#160;profits,&#160;and&#160;welfare,”&#160;Games&#160;and<br/>
Economic&#160;Behavior,&#160;vol.&#160;39,&#160;no.&#160;1,&#160;pp.&#160;137–166,&#160;2002.<br/>
[38]&#160;B.&#160;Celen&#160;and&#160;S.&#160;Kariv,&#160;“Observational&#160;learning&#160;under&#160;imperfect&#160;information,”&#160;Games&#160;and<br/>
Economic&#160;Behavior,&#160;vol.&#160;47,&#160;no.&#160;1,&#160;pp.&#160;72–86,&#160;2004.<br/>
[39]&#160;S.&#160;Callander&#160;and&#160;J.&#160;H¨<br/>
orner,&#160;“The&#160;wisdom&#160;of&#160;the&#160;minority,”&#160;Journal&#160;of&#160;Economic&#160;theory,&#160;vol.<br/>
144,&#160;no.&#160;4,&#160;pp.&#160;1421–1439,&#160;2009.<br/>
[40]&#160;J.&#160;Ho,&#160;W.&#160;P.&#160;Tay,&#160;and&#160;T.&#160;Q.&#160;Quek,&#160;“Robust&#160;detection&#160;and&#160;social&#160;learning&#160;in&#160;tandem&#160;networks,”<br/>
in&#160;Acoustics,&#160;Speech&#160;and&#160;Signal&#160;Processing&#160;(ICASSP),&#160;2014&#160;IEEE&#160;International&#160;Conference<br/>on.<br/>
IEEE,&#160;2014,&#160;pp.&#160;5457–5461.<br/>
[41]&#160;Y.<br/>
Song,<br/>
“Social<br/>
learning<br/>
with<br/>
endogenous<br/>
network<br/>
formation,”<br/>
arXiv<br/>
preprint<br/>
arXiv:1504.05222,&#160;2015.<br/>
[42]&#160;J.&#160;A.&#160;Bohren&#160;and&#160;D.&#160;Hauser,&#160;“Bounded&#160;rationality&#160;and&#160;learning:&#160;A&#160;framework&#160;and&#160;a&#160;robustness<br/>
result,”&#160;2017.<br/>
[43]&#160;C.&#160;Chamley&#160;and&#160;D.&#160;Gale,&#160;“Information&#160;revelation&#160;and&#160;strategic&#160;delay&#160;in&#160;a&#160;model&#160;of&#160;investment,”<br/>
Econometrica:&#160;Journal&#160;of&#160;the&#160;Econometric&#160;Society,&#160;pp.&#160;1065–1085,&#160;1994.<br/>
[44]&#160;Y.&#160;Zhang,&#160;“Robust&#160;information&#160;cascade&#160;with&#160;endogenous&#160;ordering.”<br/>
working&#160;paper,&#160;2009.<br/>
Available&#160;at:&#160;http://www.&#160;gtcenter.&#160;org/Archive/2010/Conf/Zhang1085.&#160;pdf,&#160;2009.<br/>
[45]&#160;D.&#160;Sgroi,&#160;“Irreversible&#160;investment&#160;and&#160;the&#160;value&#160;of&#160;information&#160;gathering,”&#160;Economics&#160;Bulletin,<br/>
vol.&#160;21,&#160;no.&#160;4,&#160;2003.<br/>
[46]&#160;T.&#160;N.&#160;Le,&#160;V.&#160;G.&#160;Subramanian,&#160;and&#160;R.&#160;A.&#160;Berry,&#160;“The&#160;value&#160;of&#160;noise&#160;for&#160;informational&#160;cascades,”<br/>
in&#160;Information&#160;Theory&#160;(ISIT),&#160;2014&#160;IEEE&#160;International&#160;Symposium&#160;on.<br/>
IEEE,&#160;2014,&#160;pp.<br/>
1101–1105.<br/>
[47]&#160;——,&#160;“The&#160;impact&#160;of&#160;observation&#160;and&#160;action&#160;errors&#160;on&#160;informational&#160;cascades,”&#160;in&#160;Decision<br/>
and&#160;Control&#160;(CDC),&#160;2014&#160;IEEE&#160;53rd&#160;Annual&#160;Conference&#160;on.<br/>
IEEE,&#160;2014,&#160;pp.&#160;1917–1922.<br/>
[48]&#160;T.&#160;Le,&#160;V.&#160;Subramanian,&#160;and&#160;R.&#160;Berry,&#160;“Bayesian&#160;learning&#160;with&#160;random&#160;arrivals,”&#160;in&#160;Informa-<br/>
tion&#160;Theory&#160;(ISIT),&#160;2018&#160;IEEE&#160;International&#160;Symposium&#160;on.<br/>
IEEE,&#160;2018,&#160;pp.&#160;6990–6995.<br/>
[49]&#160;J.&#160;N.&#160;Tsitsiklis,&#160;Decentralized&#160;detection,&#160;ser.&#160;Advances&#160;in&#160;Statistical&#160;Signal&#160;Processing,&#160;Vol.&#160;2:<br/>
Signal&#160;Detection.<br/>
JAI&#160;Press,&#160;1989.<br/>
[50]&#160;J.&#160;Koplowitz,&#160;“Necessary&#160;and&#160;sufficient&#160;memory&#160;size&#160;for&#160;m-hypothesis&#160;testing,”&#160;IEEE&#160;Trans-<br/>
actions&#160;on&#160;Information&#160;Theory,&#160;vol.&#160;21,&#160;no.&#160;1,&#160;pp.&#160;44–46,&#160;1975.<br/>
[51]&#160;M.&#160;Dia,&#160;“On&#160;decision&#160;making&#160;in&#160;tandem&#160;networks,”&#160;Master’s&#160;thesis,&#160;Massachusetts&#160;Institute<br/>
of&#160;Technology,&#160;2009.<br/>
13<br/>
<hr/>
<a name=15></a>A<br/>
Appendix:&#160;Proofs&#160;and&#160;Calculations<br/>
A.1<br/>
Proof&#160;of&#160;Lemma&#160;1<br/>
Proof.&#160;Prior&#160;to&#160;showing&#160;Lemma&#160;1,&#160;we&#160;want&#160;to&#160;first&#160;claim&#160;a&#160;useful&#160;property&#160;in&#160;threshold-based<br/>question&#160;guidebooks.<br/>
Claim&#160;1.&#160;Given&#160;a&#160;threshold-based&#160;question&#160;guidebook&#160;which&#160;is&#160;feasible&#160;and&#160;incentive-compatible,<br/>active&#160;agents&#160;cannot&#160;arrive&#160;consecutively.<br/>
Proof.&#160;First&#160;we&#160;note&#160;that&#160;active&#160;agents&#160;arriving&#160;means&#160;that&#160;the&#160;cascade&#160;is&#160;still&#160;ongoing&#160;and&#160;the<br/>question&#160;guidebook&#160;operational.&#160;Then&#160;assume&#160;that&#160;active&#160;agent&#160;ak&#160;is&#160;in&#160;state&#160;Gj&#160;∈&#160;G∗,&#160;where&#160;G∗&#160;is<br/>defined&#160;as&#160;the&#160;set&#160;of&#160;states&#160;at&#160;which&#160;she&#160;can&#160;stop&#160;the&#160;cascade.<br/>
We&#160;know&#160;for&#160;sure&#160;that&#160;the&#160;likelihood&#160;ratio&#160;of&#160;agent&#160;ak&#160;+&#160;1&#160;at&#160;state&#160;G1,&#160;denoted&#160;by&#160;`ak+1&#160;is<br/>
G1<br/>
less&#160;than&#160;1−p&#160;.&#160;The&#160;reason&#160;is&#160;that&#160;G<br/>
p<br/>
1&#160;at&#160;ak&#160;+&#160;1&#160;contains&#160;two&#160;types&#160;of&#160;events.<br/>
The&#160;first&#160;types<br/>
is&#160;where&#160;ak&#160;is&#160;in&#160;Gk&#160;∈&#160;G∗&#160;but&#160;receiving&#160;an&#160;observed&#160;majority.&#160;Given&#160;`ak&#160;&lt;&#160;1&#160;for&#160;all&#160;G<br/>
G<br/>
i&#160;∈&#160;G∗,<br/>
i<br/>
(`ak+1|ak&#160;at&#160;G<br/>
;&#160;note&#160;that&#160;agent&#160;ak&#160;does&#160;not&#160;stop&#160;the&#160;cascade.&#160;The&#160;other&#160;type&#160;is&#160;ak<br/>
G<br/>
i&#160;∈&#160;G∗)&#160;&lt;&#160;1−p<br/>
1<br/>
p<br/>
was&#160;at&#160;Gi&#160;6∈&#160;G∗.&#160;Here&#160;also&#160;we&#160;get&#160;(`ak+1|ak&#160;at&#160;G<br/>
because&#160;ak&#160;cannot&#160;stop&#160;the&#160;cascade<br/>
G<br/>
i&#160;6∈&#160;G∗)&#160;&lt;&#160;1−p<br/>
1<br/>
p<br/>
even&#160;after&#160;receiving&#160;observed&#160;minority&#160;in&#160;any&#160;of&#160;those&#160;states.<br/>
Therefore,&#160;we&#160;can&#160;conclude&#160;that&#160;`ak+1&#160;&lt;&#160;1−p&#160;,&#160;which&#160;guarantees&#160;that&#160;agent&#160;ak&#160;+&#160;1&#160;is&#160;a&#160;silent<br/>
G1<br/>
p<br/>
agent,&#160;and&#160;not&#160;an&#160;active&#160;agent.<br/>
Given&#160;that&#160;every&#160;active&#160;agent&#160;goes&#160;to&#160;G1&#160;once&#160;knowing&#160;she&#160;cannot&#160;stop&#160;the&#160;cascade,&#160;Claim<br/>
<a href="1811.00226v3s.html#15">1&#160;</a>tells&#160;that&#160;the&#160;next&#160;agent&#160;must&#160;be&#160;a&#160;silent&#160;agent.&#160;With&#160;the&#160;claim,&#160;we&#160;can&#160;prove&#160;this&#160;lemma<br/>by&#160;contradiction.&#160;Starting&#160;from&#160;G1,&#160;we&#160;assume&#160;the&#160;next&#160;active&#160;agent&#160;is&#160;ak+1&#160;who&#160;can&#160;stop&#160;the<br/>cascade&#160;at&#160;Gi&#160;for&#160;some&#160;i&#160;&gt;&#160;1.&#160;Now,&#160;consider&#160;that&#160;likelihood&#160;ratio&#160;of&#160;state&#160;G1&#160;at&#160;agent&#160;ak+1&#160;−&#160;i&#160;+&#160;1,<br/>`ak+1−i+1,&#160;`ak+1−i+1&#160;≥&#160;`ak+1&#160;;&#160;this&#160;is&#160;because&#160;of&#160;the&#160;allowed&#160;transitions&#160;in&#160;the&#160;Markov&#160;chain&#160;of&#160;silent<br/>
G1<br/>
G1<br/>
Gi<br/>
agents.&#160;Agent&#160;ak+1&#160;can&#160;stop&#160;the&#160;cascade&#160;at&#160;Gi&#160;and&#160;this&#160;requires&#160;`ak+1&#160;≥&#160;1−p&#160;.&#160;It&#160;implies&#160;that<br/>
Gi<br/>
p<br/>
`ak+1−i+1&#160;≥&#160;1−p&#160;.&#160;Now,&#160;agent&#160;ak+1&#160;−&#160;i&#160;+&#160;1&#160;must&#160;be&#160;an&#160;active&#160;agent,&#160;which&#160;contradicts&#160;that&#160;next<br/>
G1<br/>
p<br/>
active&#160;agent&#160;is&#160;ak+1.<br/>
A.2<br/>
Proof&#160;of&#160;Lemma&#160;2<br/>
First,&#160;we&#160;show&#160;that&#160;if&#160;one&#160;of&#160;these&#160;three&#160;condition&#160;fails,&#160;then&#160;asymptotic&#160;learning&#160;is&#160;not&#160;achievable.<br/>
The&#160;check&#160;for&#160;the&#160;first&#160;condition&#160;is&#160;straightforward,&#160;if&#160;it&#160;fails,&#160;then&#160;there&#160;exists&#160;an&#160;N&#160;such&#160;that<br/>
mk&#160;&lt;&#160;N&#160;for&#160;all&#160;k.&#160;Now,&#160;h−(mk)&#160;is&#160;lower-bounded&#160;by&#160;h−(N&#160;)&#160;&gt;&#160;0.&#160;As&#160;we&#160;all&#160;know,&#160;limn→∞(1&#160;−<br/>h−(N&#160;))n&#160;=&#160;0,&#160;a&#160;correct&#160;cascade&#160;will&#160;always&#160;being&#160;stopped&#160;in&#160;finite&#160;time&#160;and&#160;asymptotic&#160;learning&#160;is<br/>not&#160;possible.<br/>
For&#160;the&#160;second&#160;condition,&#160;if&#160;Π∞&#160;(1&#160;−&#160;h+(mk))&#160;=&#160;0&#160;6=&#160;0,&#160;then&#160;there&#160;is&#160;a&#160;positive&#160;probability&#160;that<br/>
k=1<br/>
a&#160;wrong&#160;cascade&#160;lasts&#160;forever.&#160;Obviously,&#160;asymptotic&#160;learning&#160;cannot&#160;be&#160;achieved.&#160;If&#160;Π∞&#160;(1&#160;−<br/>
k=1<br/>
h−(mk))&#160;=&#160;Π∞&#160;(1&#160;−&#160;h+(mk))&#160;=&#160;0,&#160;then&#160;we&#160;will&#160;keep&#160;stopping&#160;every&#160;cascade&#160;whether&#160;it&#160;is&#160;a&#160;right<br/>
k=1<br/>
cascade&#160;or&#160;not.&#160;Therefore,&#160;limn→∞&#160;P(Xn&#160;=&#160;¯<br/>
Xn)&#160;&lt;&#160;1&#160;because&#160;we&#160;will&#160;have&#160;a&#160;positive&#160;probability&#160;of<br/>
either&#160;being&#160;in&#160;a&#160;wrong&#160;cascade&#160;or&#160;not&#160;being&#160;in&#160;a&#160;cascade.<br/>
Finally,&#160;if&#160;the&#160;product&#160;of&#160;transition&#160;matrix&#160;M&#160;∗&#160;=&#160;MsMa&#160;is&#160;not&#160;irreducible,&#160;then&#160;there&#160;are&#160;some<br/>
states&#160;that&#160;we&#160;either&#160;cannot&#160;access&#160;or&#160;from&#160;which&#160;we&#160;cannot&#160;go&#160;back&#160;to&#160;any&#160;other&#160;state.&#160;It&#160;implies<br/>that&#160;we&#160;cannot&#160;stop&#160;cascades&#160;at&#160;those&#160;states.&#160;Hence,&#160;it&#160;is&#160;necessary&#160;that&#160;M&#160;∗&#160;is&#160;irreducible&#160;to&#160;achieve<br/>asymptotic&#160;learning.<br/>
14<br/>
<hr/>
<a name=16></a>In&#160;the&#160;other&#160;direction,&#160;suppose&#160;we&#160;have&#160;the&#160;first&#160;and&#160;the&#160;second&#160;conditions&#160;satisfied,&#160;then&#160;we<br/>
know&#160;we&#160;will&#160;keep&#160;stopping&#160;some&#160;wrong&#160;cascades&#160;but&#160;not&#160;the&#160;correct&#160;cascades.&#160;With&#160;the&#160;third<br/>condition,&#160;we&#160;know&#160;that&#160;if&#160;a&#160;cascade,&#160;whether&#160;it’s&#160;correct&#160;or&#160;wrong,&#160;isn’t&#160;stopped&#160;by&#160;the&#160;upcoming<br/>active&#160;agent,&#160;then&#160;it&#160;has&#160;a&#160;positive&#160;probability&#160;of&#160;being&#160;stopped&#160;by&#160;at&#160;least&#160;one&#160;of&#160;the&#160;next&#160;|G|<br/>active&#160;agents,&#160;because&#160;the&#160;directed&#160;graph&#160;corresponds&#160;to&#160;M&#160;∗&#160;is&#160;strongly&#160;connected.&#160;Now,&#160;since<br/>all&#160;wrong&#160;cascades&#160;can&#160;be&#160;stopped&#160;in&#160;finite&#160;time&#160;but&#160;some&#160;of&#160;right&#160;cascade&#160;will&#160;last&#160;forever,&#160;then<br/>asymptotic&#160;learning&#160;is&#160;achieved.<br/>
A.3<br/>
Upper&#160;bound&#160;of&#160;growth&#160;rate&#160;of&#160;mk<br/>
Finding&#160;the&#160;upper&#160;bound&#160;of&#160;mk&#160;is&#160;analogous&#160;to&#160;finding&#160;a&#160;sequence&#160;of&#160;ns&#160;such&#160;that<br/>
<br/>
h+(s)<br/>
<br/>
<br/>
Hak−1+1<br/>
<br/>
<br/>
mk&#160;=&#160;s|`<br/>
≥&#160;1<br/>
≥&#160;n&#160;∀&#160;s&#160;∈<br/>
G<br/>
<br/>
N.<br/>
1<br/>
s<br/>
<br/>
h−(s)<br/>
<br/>
The&#160;following&#160;calculations&#160;derive&#160;the&#160;value&#160;of&#160;ns.<br/>
First,&#160;the&#160;number&#160;of&#160;mk&#160;=&#160;s&#160;is&#160;equivalent&#160;to&#160;difference&#160;of&#160;indices&#160;between&#160;the&#160;kth&#160;active&#160;agent&#160;to<br/>
H<br/>
the&#160;next&#160;active&#160;agent&#160;with&#160;index&#160;j&#160;such&#160;that&#160;`&#160;aj+1&#160;h+(s)&#160;&lt;&#160;1.&#160;Hence,&#160;we&#160;get&#160;the&#160;following&#160;equation:<br/>
G1<br/>
h−(s)<br/>
<br/>
h+(s)<br/>
<br/>
h+(s)<br/>
<br/>
H<br/>
H<br/>
at+1<br/>
<br/>
ak+n+1<br/>
<br/>
mt&#160;=&#160;s|`<br/>
≥&#160;1,&#160;t&#160;≥&#160;k<br/>
=&#160;min{n|`<br/>
&lt;&#160;1}.<br/>
G<br/>
<br/>
1<br/>
G1<br/>
<br/>
h−(s)<br/>
<br/>
h−(s)<br/>
Now,&#160;using&#160;the&#160;recursive&#160;formula&#160;of&#160;likelihood&#160;ratio&#160;stated&#160;in&#160;<a href="1811.00226v3s.html#10">(3),&#160;</a>we&#160;get&#160;the&#160;following&#160;equation:<br/>
<br/>
h+(s)<br/>
<br/>
<br/>
<br/>
&#160;1&#160;−&#160;h+(s)&#160;n&#160;h+(s)<br/>
<br/>
H<br/>
H<br/>
at+1<br/>
<br/>
ak&#160;+1<br/>
<br/>
mt&#160;=&#160;s|`<br/>
≥&#160;1,&#160;t&#160;≥&#160;k<br/>
=&#160;min<br/>
n|`<br/>
&lt;&#160;1<br/>
.<br/>
G<br/>
<br/>
1<br/>
G1<br/>
<br/>
h−(s)<br/>
<br/>
1&#160;−&#160;h−(s)<br/>
h−(s)<br/>
H<br/>
We&#160;know&#160;that&#160;`&#160;ak−1+1&#160;h+(s)&#160;&gt;&#160;1&#160;because&#160;mk&#160;=&#160;s&#160;and&#160;mk−1&#160;=&#160;s&#160;−&#160;1,&#160;so&#160;taking&#160;logarithms&#160;we<br/>
G1<br/>
h−(s)<br/>
obtain<br/>
<br/>
h+(s)<br/>
<br/>
<br/>
<br/>
&#160;1&#160;−&#160;h−(s)&#160;<br/>
&#160;h+(s)&#160;<br/>
<br/>
H<br/>
H<br/>
at+1<br/>
<br/>
ak&#160;+1<br/>
<br/>
mt&#160;=&#160;s|`<br/>
≥&#160;1,&#160;t&#160;≥&#160;k<br/>
=&#160;min<br/>
n|n&#160;ln<br/>
&gt;&#160;ln<br/>
+&#160;ln(`<br/>
)<br/>
G<br/>
<br/>
1<br/>
G1<br/>
<br/>
h−(s)<br/>
<br/>
1&#160;−&#160;h+(s)<br/>
h−(s)<br/>
<br/>
<br/>
&#160;1&#160;−&#160;h−(s)&#160;<br/>
&#160;h+(s)&#160;<br/>
H<br/>
H<br/>
&#160;h+(s&#160;−&#160;1)&#160;<br/>
≥&#160;min&#160;n|n&#160;ln<br/>
&gt;&#160;ln<br/>
+&#160;ln(`&#160;ak+1&#160;)&#160;−&#160;ln(`&#160;ak−1+1&#160;)&#160;−&#160;ln<br/>
1&#160;−&#160;h+(s)<br/>
h−(s)<br/>
G1<br/>
G1<br/>
h−(s&#160;−&#160;1)<br/>
Using&#160;the&#160;recursive&#160;form&#160;in&#160;<a href="1811.00226v3s.html#10">(3)&#160;</a>once&#160;again,&#160;we&#160;get<br/>
<br/>
h+(s)<br/>
<br/>
<br/>
Hat+1<br/>
<br/>
<br/>
mt&#160;=&#160;s|`<br/>
≥&#160;1,&#160;t&#160;≥&#160;k<br/>
G<br/>
<br/>
1<br/>
<br/>
h−(s)<br/>
<br/>
<br/>
<br/>
&#160;1&#160;−&#160;h−(s)&#160;<br/>
&#160;h+(s)h−(s&#160;−&#160;1)&#160;<br/>
&#160;1&#160;−&#160;h+(s&#160;−&#160;1)&#160;<br/>
≥&#160;min&#160;n|n&#160;ln<br/>
&gt;&#160;ln<br/>
+&#160;ln<br/>
1&#160;−&#160;h+(s)<br/>
h−(s)h+(s&#160;−&#160;1)<br/>
1&#160;−&#160;h−(s&#160;−&#160;1)<br/>
<br/>
<br/>
&#160;1&#160;−&#160;h−(s)&#160;<br/>
&#160;h+(s)h−(s&#160;−&#160;1)&#160;<br/>
≥&#160;min&#160;n|(n&#160;+&#160;1)&#160;ln<br/>
&gt;&#160;ln<br/>
1&#160;−&#160;h+(s)<br/>
h−(s)h+(s&#160;−&#160;1)<br/>
<br/>
<br/>
From&#160;this&#160;point&#160;onwards,&#160;we&#160;need&#160;to&#160;compute&#160;a&#160;lower&#160;bound&#160;of&#160;ln&#160;h+(s)h−(s−1)&#160;,&#160;and&#160;an&#160;upper<br/>
h−(s)h+(s−1)<br/>
<br/>
<br/>
bound&#160;of&#160;ln&#160;1−h−(s)&#160;.&#160;For&#160;ease&#160;of&#160;reading&#160;we&#160;put&#160;the&#160;derivations&#160;of&#160;the&#160;calculations&#160;of&#160;the&#160;lower<br/>
1−h+(s)<br/>
<br/>
<br/>
<br/>
<br/>
bound&#160;of&#160;ln&#160;h+(s)h−(s−1)<br/>
in&#160;Appendix&#160;<a href="1811.00226v3s.html#19">A.7.4,&#160;</a>and&#160;the&#160;upper&#160;bound&#160;of&#160;ln&#160;1−h−(s)<br/>
using&#160;the&#160;Claim<br/>
h−(s)h+(s−1)<br/>
1−h+(s)<br/>
<br/>
<br/>
<br/>
<br/>
<a href="1811.00226v3s.html#18">3&#160;</a>in&#160;Appendix&#160;<a href="1811.00226v3s.html#18">A.7.2&#160;</a>(by&#160;using&#160;the&#160;fact&#160;that&#160;ln&#160;1−h−(s)<br/>
&lt;&#160;ln<br/>
1<br/>
first).<br/>
1−h+(s)<br/>
1−h+(s)<br/>
15<br/>
<hr/>
<a name=17></a><br/>
<br/>
Combining&#160;the&#160;result&#160;in&#160;App<a href="1811.00226v3s.html#19">endixA.7.4,&#160;</a>which&#160;shows&#160;ln&#160;h+(s)h−(s−1)<br/>
≥&#160;c<br/>
h−(s)h+(s−1)<br/>
1(p),&#160;where&#160;c1(p)&#160;is<br/>
1&#160;−&#160;h−(s)<br/>
only&#160;a&#160;function&#160;of&#160;p,&#160;and&#160;the&#160;result&#160;in&#160;Appendix&#160;<a href="1811.00226v3s.html#18">A.7.2,&#160;</a>ln(<br/>
)&#160;≤&#160;ps&#160;+&#160;p2s,&#160;we&#160;can&#160;pick&#160;n<br/>
1&#160;−&#160;h+(s)<br/>
s&#160;as<br/>
ln(c1(p))<br/>
ns&#160;=<br/>
.<br/>
(7)<br/>
ps&#160;+&#160;p2s<br/>
A.4<br/>
Calculation&#160;of&#160;the&#160;probability&#160;that&#160;a&#160;wrong&#160;cascade&#160;will&#160;be&#160;stopped<br/>
First,&#160;we&#160;use&#160;the&#160;lower&#160;bound&#160;of&#160;h+(m)&#160;derived&#160;in&#160;Appendix&#160;<a href="1811.00226v3s.html#19">A.7.3&#160;</a>to&#160;get&#160;the&#160;first&#160;inequality<br/>
P(A&#160;wrong&#160;cascade&#160;can&#160;be&#160;stopped)&#160;=&#160;1&#160;−&#160;Π∞<br/>
k=1(1&#160;−&#160;h+(mk&#160;))&#160;≥&#160;1&#160;−&#160;Π∞<br/>
k=1(1&#160;−&#160;pmk&#160;).<br/>
Now,&#160;we&#160;use&#160;the&#160;sequence&#160;ns&#160;that&#160;upper&#160;bounds&#160;the&#160;growth&#160;rate&#160;of&#160;mk&#160;to&#160;replace&#160;the&#160;product&#160;and<br/>apply&#160;the&#160;lower-bound&#160;result&#160;in&#160;<a href="1811.00226v3s.html#19">A.7.4&#160;</a>for&#160;large&#160;enough&#160;J.<br/>
ln(c1(p))<br/>
P(A&#160;wrong&#160;cascade&#160;can&#160;be&#160;stopped)<br/>
≥&#160;1&#160;−&#160;A(p)Π∞<br/>
pn−1(1+pn−1)<br/>
n=J(1&#160;−&#160;pn)<br/>
∞<br/>
<br/>
X<br/>
ln(c<br/>
<br/>
≥<br/>
1(p))<br/>
1&#160;−&#160;A(p)&#160;exp&#160;p<br/>
(−pn)<br/>
pn(1&#160;+&#160;pn−1)<br/>
n=0<br/>
∞<br/>
<br/>
X<br/>
1<br/>
<br/>
=<br/>
1&#160;−&#160;A(p)&#160;exp<br/>
−&#160;p&#160;ln(c1(p))<br/>
=&#160;1,<br/>
1&#160;+&#160;pn<br/>
n=0<br/>
min{j|mj+1=J}<br/>
where&#160;A(p)&#160;=&#160;Π<br/>
(1&#160;−&#160;pmk&#160;).<br/>
k=1<br/>
A.5<br/>
Lower&#160;bound&#160;of&#160;growth&#160;rate&#160;of&#160;mk<br/>
Finding&#160;the&#160;lower&#160;bound&#160;of&#160;mk&#160;is&#160;analogous&#160;to&#160;finding&#160;a&#160;sequence&#160;of&#160;¯<br/>
ns&#160;such&#160;that&#160;|{mk&#160;=<br/>
H<br/>
s|`&#160;ak−1+1&#160;h+(s)&#160;≥&#160;1}|&#160;≥&#160;¯<br/>
n<br/>
G<br/>
s&#160;for&#160;all&#160;s&#160;∈&#160;N.&#160;In&#160;contrast&#160;to&#160;what&#160;we&#160;did&#160;in&#160;computing&#160;n<br/>
1<br/>
h−(s)<br/>
s,&#160;we&#160;now&#160;want<br/>
to&#160;upper&#160;bound&#160;the&#160;following&#160;equation:<br/>
<br/>
h+(s)<br/>
<br/>
<br/>
<br/>
&#160;1&#160;−&#160;h+(s)&#160;n&#160;h+(s)<br/>
<br/>
H<br/>
H<br/>
at+1<br/>
<br/>
ak&#160;+1<br/>
<br/>
mt&#160;=&#160;s|`<br/>
≥&#160;1,&#160;t&#160;≥&#160;k<br/>
=&#160;min<br/>
n|`<br/>
&lt;&#160;1<br/>
.<br/>
G<br/>
<br/>
1<br/>
G1<br/>
<br/>
h−(s)<br/>
<br/>
1&#160;−&#160;h−(s)<br/>
h−(s)<br/>
H<br/>
Given&#160;that&#160;mk&#160;=&#160;s&#160;and&#160;mk−1&#160;=&#160;s&#160;−&#160;1,&#160;`&#160;ak+1&#160;h+(s−1)&#160;&lt;&#160;1&#160;because&#160;mk&#160;=&#160;s&#160;and&#160;mk−1&#160;=&#160;s&#160;−&#160;1,<br/>
G1<br/>
h−(s−1)<br/>
we&#160;can&#160;lower&#160;bound&#160;the&#160;equation&#160;and&#160;then&#160;take&#160;logarithms&#160;on&#160;both&#160;sides&#160;of&#160;the&#160;inequality&#160;to&#160;get<br/>
<br/>
h+(s)<br/>
<br/>
<br/>
<br/>
&#160;1&#160;−&#160;h−(s)&#160;<br/>
&#160;h+(s)&#160;<br/>
<br/>
H<br/>
H<br/>
at+1<br/>
<br/>
ak&#160;+1<br/>
<br/>
mt&#160;=&#160;s|`<br/>
≥&#160;1,&#160;t&#160;≥&#160;k<br/>
=&#160;min<br/>
n|n&#160;ln<br/>
&gt;&#160;ln<br/>
+&#160;ln(`<br/>
)<br/>
G<br/>
<br/>
1<br/>
G1<br/>
<br/>
h−(s)<br/>
<br/>
1&#160;−&#160;h+(s)<br/>
h−(s)<br/>
<br/>
<br/>
&#160;1&#160;−&#160;h−(s)&#160;<br/>
&#160;h+(s)&#160;<br/>
H<br/>
H<br/>
&#160;h+(s&#160;−&#160;1)&#160;<br/>
≤&#160;min&#160;n|n&#160;ln<br/>
&gt;&#160;ln<br/>
+&#160;ln(`&#160;ak+1&#160;)&#160;−&#160;ln(`&#160;ak+1&#160;)&#160;−&#160;ln<br/>
1&#160;−&#160;h+(s)<br/>
h−(s)<br/>
G1<br/>
G1<br/>
h−(s&#160;−&#160;1)<br/>
n<br/>
&#160;1&#160;−&#160;h−(s)&#160;<br/>
&#160;h+(s)h−(s&#160;−&#160;1)&#160;o<br/>
=&#160;min&#160;n|n&#160;ln<br/>
&gt;&#160;ln<br/>
1&#160;−&#160;h+(s)<br/>
h−(s)h+(s&#160;−&#160;1)<br/>
<br/>
<br/>
Similarly,&#160;we&#160;can&#160;replace&#160;ln&#160;h+(s)h−(s−1)<br/>
by&#160;an&#160;upper&#160;bound&#160;c<br/>
h−(s)h+(s−1)<br/>
2(p)&#160;derived&#160;in&#160;Appendix&#160;<a href="1811.00226v3s.html#19">A.7.4</a><br/>
for&#160;large&#160;enough&#160;s.&#160;However,&#160;unlike&#160;what&#160;we&#160;did&#160;for&#160;upper&#160;bounding&#160;the&#160;growth&#160;rate&#160;of&#160;mk,&#160;now<br/>
16<br/>
<hr/>
<a name=18></a><br/>
<br/>
we&#160;keep&#160;the&#160;form&#160;ln&#160;1−h−(s)<br/>
and&#160;bring&#160;this&#160;into&#160;the&#160;calculation&#160;of&#160;the&#160;probability&#160;that&#160;a&#160;right<br/>
1−h+(s)<br/>
cascade&#160;will&#160;being&#160;stopped.&#160;In&#160;other&#160;words,<br/>
ln(c2(p))<br/>
¯<br/>
ns&#160;=<br/>
.<br/>
ln&#160;1−h−(n)&#160;<br/>
1−h+(n)<br/>
A.6<br/>
Calculation&#160;the&#160;probability&#160;that&#160;a&#160;right&#160;cascade&#160;will&#160;finally&#160;being&#160;stopped<br/>
Taking&#160;the&#160;lower&#160;bound&#160;derived&#160;in&#160;Appendix&#160;<a href="1811.00226v3s.html#17">A.5,&#160;</a>we&#160;get&#160;the&#160;following&#160;inequality:<br/>
P(A&#160;right&#160;cascade&#160;will&#160;be&#160;stopped)&#160;=&#160;1&#160;−&#160;Π∞<br/>
k=1(1&#160;−&#160;h−(mk&#160;))<br/>
ln(c2(p))<br/>
1−h−(n)&#160;<br/>
ln<br/>
≤&#160;1&#160;−&#160;A(p)Π∞&#160;(1&#160;−&#160;h−(n))<br/>
1−h+(n)<br/>
n=&#160;¯<br/>
J<br/>
∞<br/>
&#160;X<br/>
ln(c2(p))<br/>
<br/>
=&#160;1&#160;−&#160;A(p)&#160;exp<br/>
ln(1&#160;−&#160;h−(n))&#160;,<br/>
ln&#160;1−h−(n)&#160;<br/>
n=&#160;¯<br/>
J<br/>
1−h+(n)<br/>
min{j|mj+1=&#160;¯<br/>
J&#160;}<br/>
where&#160;A(p)&#160;=&#160;Π<br/>
(1&#160;−&#160;h−(k)),&#160;and&#160;¯<br/>
J&#160;is&#160;the&#160;same&#160;as&#160;in&#160;Appendix&#160;<a href="1811.00226v3s.html#17">A.4.</a><br/>
k=1<br/>
Now,&#160;the&#160;rest&#160;of&#160;calculations&#160;are&#160;just&#160;using&#160;well-known&#160;upper&#160;and&#160;lower&#160;bounds&#160;on&#160;the&#160;logarithm.<br/>
With&#160;calculations&#160;detailed&#160;in&#160;<a href="1811.00226v3s.html#20">A.7.5,&#160;</a>we&#160;get&#160;that<br/>
∞<br/>
&#160;X<br/>
1<br/>
<br/>
P(A&#160;right&#160;cascade&#160;will&#160;be&#160;stopped)&#160;≤&#160;1&#160;−&#160;B(p)&#160;exp<br/>
,<br/>
c4(p)c1(p)n&#160;−&#160;1<br/>
n=&#160;¯<br/>
J<br/>
min{j|mj+1=&#160;¯<br/>
J&#160;}<br/>
where&#160;B(p)&#160;=&#160;c2(p)ec3(p)Π<br/>
(1&#160;−&#160;h−(k)).<br/>
k=1<br/>
Now,&#160;using&#160;the&#160;fact&#160;that&#160;c1(p)&#160;&gt;&#160;1&#160;in&#160;Appendix&#160;<a href="1811.00226v3s.html#19">A.7.4,&#160;</a>for&#160;a&#160;large&#160;enough&#160;n,&#160;|&#160;c4(p)c1(p)n−1&#160;−<br/>
c4(p)c1(p)n+1−1<br/>
c<br/>
1<br/>
1(p)|&#160;≤&#160;.&#160;Hence,&#160;by&#160;ratio&#160;test,&#160;we&#160;can&#160;claim&#160;that&#160;P∞<br/>
converges,&#160;and<br/>
n=&#160;¯<br/>
J&#160;c4(p)c1(p)n−1<br/>
P(A&#160;right&#160;cascade&#160;will&#160;be&#160;stopped)&#160;&lt;&#160;1.<br/>
A.7<br/>
Technical&#160;Claims&#160;and&#160;Calculations<br/>
A.7.1<br/>
Claim&#160;2&#160;and&#160;its&#160;proof<br/>
H<br/>
Claim&#160;2.&#160;The&#160;likelihood&#160;ratio&#160;`&#160;ak+1&#160;is&#160;a&#160;strictly&#160;decreasing&#160;function&#160;of&#160;k.<br/>
G1<br/>
Proof.&#160;First,&#160;h+(m)&#160;is&#160;a&#160;strictly&#160;increasing&#160;function&#160;of&#160;m&#160;(please&#160;see&#160;calculations&#160;in&#160;Appendix&#160;<a href="1811.00226v3s.html#19">A.7.4).</a><br/>
h−(m)<br/>
H<br/>
Since&#160;h+(1)&#160;&gt;&#160;h−(1)&#160;&gt;&#160;0&#160;and&#160;given&#160;the&#160;form&#160;in&#160;<a href="1811.00226v3s.html#10">(2),&#160;</a>`&#160;ak+1&#160;is&#160;an&#160;strictly&#160;decreasing&#160;function.<br/>
G1<br/>
A.7.2<br/>
Claim&#160;3&#160;and&#160;its&#160;Proof<br/>
&#160;1&#160;−&#160;h−(s)&#160;<br/>
Claim&#160;3.&#160;ln<br/>
can&#160;be&#160;upper-bounded&#160;by&#160;ps&#160;+&#160;p2s.<br/>
1&#160;−&#160;h+(s)<br/>
&#160;1&#160;−&#160;h−(s)&#160;<br/>
<br/>
1<br/>
<br/>
Proof.&#160;First,&#160;ln<br/>
≤&#160;ln<br/>
.<br/>
1&#160;−&#160;h+(s)<br/>
1&#160;−&#160;h+(s)<br/>
Then,&#160;using&#160;the&#160;upper&#160;bound&#160;in&#160;Appendix&#160;<a href="1811.00226v3s.html#19">A.7.3&#160;</a>and&#160;Taylor’s&#160;expansion,&#160;we&#160;know&#160;that<br/>
<br/>
1<br/>
<br/>
ln<br/>
≤&#160;−&#160;ln(1&#160;−&#160;ps)&#160;≤&#160;ps&#160;+&#160;p2s.<br/>
1&#160;−&#160;h+(s)<br/>
17<br/>
<hr/>
<a name=19></a>A.7.3<br/>
Calculation&#160;of&#160;Upper&#160;bound&#160;of&#160;h+(m)<br/>
First,&#160;in&#160;this&#160;question&#160;guidebook,&#160;h+(m)&#160;has&#160;a&#160;closed&#160;form&#160;given&#160;by<br/>
<br/>
q<br/>
p<br/>
<br/>
2−(m+1)[(p&#160;+&#160;pp(4&#160;−&#160;3p))m+1&#160;−&#160;(p&#160;−&#160;pp(4&#160;−&#160;3p))m+1],<br/>
m&#160;is&#160;even<br/>
<br/>
4−3p<br/>
h+(m)&#160;=<br/>
m+1<br/>
m+1<br/>
m+1<br/>
q<br/>
p<br/>
&#160;p&#160;&#160;2<br/>
h<br/>
<br/>
2<br/>
<br/>
<br/>
2<br/>
i<br/>
<br/>
(2&#160;−&#160;p)&#160;+&#160;pp(4&#160;−&#160;3p)<br/>
−&#160;(2&#160;−&#160;p)&#160;−&#160;pp(4&#160;−&#160;3p)<br/>
,<br/>
m&#160;is&#160;odd<br/>
<br/>
4−3p<br/>
2<br/>
h+(m&#160;+&#160;1)<br/>
With&#160;the&#160;closes&#160;form&#160;of&#160;h+(m),&#160;a&#160;simple&#160;bound&#160;of<br/>
&lt;&#160;p&#160;holds&#160;for&#160;all&#160;m&#160;∈&#160;N.<br/>
h+(m)<br/>
For&#160;readers&#160;curious&#160;about&#160;the&#160;exact&#160;difference&#160;of&#160;ph+(m)&#160;−&#160;h+(m&#160;+&#160;1),&#160;the&#160;form&#160;is<br/>
h<br/>
i<br/>
pm+2&#160;2F1(−&#160;m&#160;−&#160;1&#160;,&#160;−&#160;m&#160;,&#160;−m&#160;−&#160;1,&#160;4(1&#160;−&#160;1&#160;))&#160;−<br/>
+&#160;1&#160;,&#160;−&#160;m&#160;,&#160;−m&#160;−&#160;1,&#160;4(1&#160;−&#160;1&#160;))&#160;,&#160;where<br/>
2<br/>
2<br/>
2<br/>
p<br/>
2F1(−&#160;m<br/>
2<br/>
2<br/>
2<br/>
p<br/>
2F1(·)&#160;is&#160;a<br/>
h+(m&#160;+&#160;1)<br/>
hypergeometric&#160;function.&#160;We&#160;will&#160;not&#160;need&#160;this&#160;detail&#160;as&#160;getting&#160;the&#160;bound<br/>
&lt;&#160;p&#160;is&#160;good<br/>
h+(m)<br/>
enough&#160;for&#160;our&#160;results.<br/>
h+(m&#160;+&#160;1)&#160;h+(m)<br/>
A.7.4<br/>
Convergence&#160;and&#160;bounds&#160;of<br/>
/<br/>
.<br/>
h−(m&#160;+&#160;1)&#160;h−(m)<br/>
For&#160;the&#160;simplicity,&#160;suppose&#160;m&#160;is&#160;even.&#160;Recall&#160;the&#160;closed&#160;form&#160;of&#160;h+(m)&#160;and&#160;h−(m)&#160;as&#160;follows:<br/>
r<br/>
p<br/>
p<br/>
h+(m)&#160;=<br/>
2−(m+1)[(p&#160;+<br/>
p(4&#160;−&#160;3p))m+1&#160;−&#160;(p&#160;−&#160;pp(4&#160;−&#160;3p))m+1]<br/>
4&#160;−&#160;3p<br/>
r&#160;1&#160;−&#160;p<br/>
p<br/>
p<br/>
h−(m)&#160;=<br/>
2−(m+1)[(1&#160;−&#160;p&#160;+<br/>
1&#160;+&#160;2p&#160;−&#160;3p2)m+1&#160;−&#160;(1&#160;−&#160;p&#160;−<br/>
1&#160;+&#160;2p&#160;−&#160;3p2)m+1]<br/>
1&#160;+&#160;3p<br/>
h+(m&#160;+&#160;2)&#160;h+(m)<br/>
Consider<br/>
/<br/>
.<br/>
h−(m&#160;+&#160;2)&#160;h−(m)<br/>
h+(m&#160;+&#160;2)&#160;h−(m)<br/>
(p&#160;+&#160;pp(4&#160;−&#160;3p))m+3&#160;−&#160;(p&#160;−&#160;pp(4&#160;−&#160;3p))m+3<br/>
=<br/>
h−(m&#160;+&#160;2)&#160;h+(m)<br/>
p<br/>
(1&#160;−&#160;p&#160;+<br/>
1&#160;+&#160;2p&#160;−&#160;3p2)m+3&#160;−&#160;(1&#160;−&#160;p&#160;−&#160;p1&#160;+&#160;2p&#160;−&#160;3p2)m+3<br/>
p<br/>
(1&#160;−&#160;p&#160;+<br/>
1&#160;+&#160;2p&#160;−&#160;3p2)m+1&#160;−&#160;(1&#160;−&#160;p&#160;−&#160;p1&#160;+&#160;2p&#160;−&#160;3p2)m+1<br/>
×<br/>
(p&#160;+&#160;pp(4&#160;−&#160;3p))m+1&#160;−&#160;(p&#160;−&#160;pp(4&#160;−&#160;3p))m+1<br/>
√<br/>
√<br/>
(p−<br/>
p(4−3p))m+3<br/>
1+2p−3p2)m+1<br/>
1&#160;−<br/>
√<br/>
1&#160;−&#160;(1−p−√<br/>
(p&#160;+&#160;pp(4&#160;−&#160;3p))2<br/>
(p+<br/>
p(4−3p))m+3<br/>
(1−p+<br/>
1+2p−3p2)m+1<br/>
=<br/>
√<br/>
√<br/>
p<br/>
(1&#160;−&#160;p&#160;+<br/>
1&#160;+&#160;2p&#160;−&#160;3p2)2<br/>
(p−<br/>
p(4−3p))m+1<br/>
1+2p−3p2)m+3<br/>
1&#160;−<br/>
√<br/>
1&#160;−&#160;(1−p−√<br/>
(p+<br/>
p(4−3p))m+1<br/>
(1−p+<br/>
1+2p−3p2)m+3<br/>
&#34;<br/>
(p&#160;+&#160;pp(4&#160;−&#160;3p))2<br/>
&#160;p&#160;−&#160;pp(4&#160;−&#160;3p)&#160;m+1<br/>
&#160;p&#160;−&#160;pp(4&#160;−&#160;3p)&#160;m+2<br/>
≤<br/>
1&#160;+<br/>
+<br/>
p<br/>
(1&#160;−&#160;p&#160;+<br/>
1&#160;+&#160;2p&#160;−&#160;3p2)2<br/>
p&#160;+&#160;pp(4&#160;−&#160;3p)<br/>
p&#160;+&#160;pp(4&#160;−&#160;3p)<br/>
#<br/>
&#160;1&#160;−&#160;p&#160;−&#160;p1&#160;+&#160;2p&#160;−&#160;3p2&#160;m+1<br/>
&#160;1&#160;−&#160;p&#160;−&#160;p1&#160;+&#160;2p&#160;−&#160;3p2&#160;m+2<br/>
−<br/>
−<br/>
p<br/>
p<br/>
1&#160;−&#160;p&#160;+<br/>
1&#160;+&#160;2p&#160;−&#160;3p2<br/>
1&#160;−&#160;p&#160;+<br/>
1&#160;+&#160;2p&#160;−&#160;3p2<br/>
h+(m&#160;+&#160;2)&#160;h−(m)<br/>
(p&#160;+&#160;pp(4&#160;−&#160;3p))2<br/>
Since<br/>
converges&#160;to<br/>
exponentially&#160;fast,&#160;for&#160;large<br/>
h−(m&#160;+&#160;2)&#160;h+(m)<br/>
p<br/>
(1&#160;−&#160;p&#160;+<br/>
1&#160;+&#160;2p&#160;−&#160;3p2)2<br/>
<br/>
<br/>
&#160;h+(m&#160;+&#160;2)&#160;h−(m)<br/>
(p&#160;+&#160;pp(4&#160;−&#160;3p))2<br/>
<br/>
enough&#160;m,&#160;we&#160;can&#160;bound&#160;<br/>
−<br/>
&#160;&lt;&#160;.<br/>
&#160;h−(m&#160;+&#160;2)&#160;h+(m)<br/>
p<br/>
(1&#160;−&#160;p&#160;+<br/>
1&#160;+&#160;2p&#160;−&#160;3p2)2&#160;<br/>
<br/>
<br/>
18<br/>
<hr/>
<a name=20></a>(p&#160;+&#160;pp(4&#160;−&#160;3p))2<br/>
Given&#160;the&#160;fact&#160;that<br/>
&gt;&#160;1&#160;for&#160;all&#160;p&#160;&gt;&#160;0.5,&#160;there&#160;exists&#160;functions<br/>
p<br/>
(1&#160;−&#160;p&#160;+<br/>
1&#160;+&#160;2p&#160;−&#160;3p2)2<br/>
h+(m&#160;+&#160;2)&#160;h−(m)<br/>
c1(p),&#160;c2(p)&#160;&gt;&#160;1&#160;such&#160;that&#160;c1(p)&#160;&lt;<br/>
for&#160;all&#160;m&#160;greater&#160;than&#160;some&#160;natural&#160;num-<br/>
h−(m&#160;+&#160;2)&#160;h+(m)<br/>
h+(m&#160;+&#160;2)&#160;h−(m)<br/>
ber&#160;J&#160;and<br/>
&lt;&#160;c2(p)&#160;for&#160;all&#160;m&#160;greater&#160;than&#160;some&#160;natural&#160;number&#160;¯<br/>
J&#160;.<br/>
h−(m&#160;+&#160;2)&#160;h+(m)<br/>
A.7.5<br/>
Bounding&#160;the&#160;probability&#160;of&#160;stopping&#160;a&#160;right&#160;cascade<br/>
P(a&#160;right&#160;cascade&#160;will&#160;be&#160;stopped)<br/>
∞<br/>
<br/>
X<br/>
−h−(n)<br/>
<br/>
≤&#160;1&#160;−&#160;A(p)&#160;exp&#160;ln(c2(p))<br/>
ln(1&#160;+&#160;h+(n)−h−(n)&#160;)<br/>
n=&#160;¯<br/>
J<br/>
1−h+(n)<br/>
∞<br/>
<br/>
X<br/>
−h−(n)<br/>
<br/>
≤&#160;1&#160;−&#160;A(p)&#160;exp&#160;ln(c2(p))<br/>
h+(n)−h−(n)&#160;(1&#160;−&#160;h+(n)−h−(n))<br/>
n=&#160;¯<br/>
J<br/>
1−h+(n)<br/>
1−h+(n)<br/>
∞<br/>
<br/>
X<br/>
−1<br/>
<br/>
≤&#160;1&#160;−&#160;A(p)&#160;exp&#160;ln(c2(p))<br/>
(&#160;h+(n)&#160;−&#160;1)(1&#160;−&#160;h+(n)−h−(n)&#160;)<br/>
1<br/>
n=&#160;¯<br/>
J<br/>
h−(n)<br/>
1−h+(n)<br/>
1−h+(n)<br/>
∞<br/>
<br/>
X<br/>
−1<br/>
<br/>
≤&#160;1&#160;−&#160;A(p)&#160;exp&#160;ln(c2(p))<br/>
−<br/>
n=1&#160;(&#160;h+(n)<br/>
1)(1&#160;−&#160;pn−0&#160;)&#160;1<br/>
h−(n)<br/>
1−pn<br/>
1−pn<br/>
∞<br/>
<br/>
X<br/>
−1<br/>
<br/>
≤&#160;1&#160;−&#160;A(p)&#160;exp&#160;ln(c2(p))<br/>
−<br/>
n=1&#160;(&#160;h+(n)<br/>
1)&#160;1−2pn<br/>
h−(n)<br/>
(1−pn)2<br/>
∞<br/>
<br/>
X<br/>
−1<br/>
<br/>
≤&#160;1&#160;−&#160;A(p)&#160;exp&#160;ln(c2(p))<br/>
1−2pn<br/>
−<br/>
n=1&#160;(&#160;h+(n)<br/>
1<br/>
h−(n)&#160;(1−pn)2<br/>
∞<br/>
&#160;X<br/>
1<br/>
<br/>
≤&#160;1&#160;−&#160;B(p)&#160;exp<br/>
)&#160;,<br/>
c4(p)c1(p)n&#160;−&#160;1<br/>
n=&#160;¯<br/>
J<br/>
min{j|mj+1=&#160;¯<br/>
J&#160;}<br/>
where&#160;B(p)&#160;=&#160;c2(p)ec3(p)Π<br/>
(1&#160;−&#160;h−(k))<br/>
k=1<br/>
B<br/>
Appendix:&#160;Discussions<br/>
B.1<br/>
Question&#160;guidebooks&#160;are&#160;delicate<br/>
For&#160;the&#160;model&#160;described&#160;in&#160;Section&#160;<a href="1811.00226v3s.html#4">2&#160;</a>assume&#160;that&#160;every&#160;agent&#160;is&#160;only&#160;allowed&#160;to&#160;ask&#160;one&#160;binary<br/>question&#160;to&#160;the&#160;agent&#160;just&#160;in&#160;front&#160;of&#160;her.&#160;In&#160;other&#160;words,&#160;the&#160;capacity&#160;of&#160;the&#160;channel&#160;is&#160;exactly&#160;one<br/>bit.&#160;We&#160;will&#160;attempt&#160;to&#160;manually&#160;design&#160;the&#160;questions&#160;with&#160;the&#160;goal&#160;being&#160;asymptotic&#160;learning.<br/>Before&#160;we&#160;proceed,&#160;we&#160;remind&#160;the&#160;reader&#160;that&#160;in&#160;our&#160;model&#160;when&#160;indifferent&#160;(i.e.,&#160;the&#160;posterior<br/>beliefs&#160;on&#160;the&#160;states&#160;of&#160;world&#160;are&#160;equally&#160;likely,&#160;or&#160;alternatively&#160;the&#160;likelihood&#160;ratio&#160;of&#160;state&#160;is&#160;A<br/>versus&#160;the&#160;state&#160;is&#160;B&#160;is&#160;1),&#160;an&#160;agent&#160;will&#160;always&#160;take&#160;the&#160;action&#160;suggested&#160;by&#160;her&#160;private&#160;signal.<br/>
It&#160;is&#160;clear&#160;that&#160;along&#160;a&#160;sample-path,&#160;the&#160;only&#160;interesting&#160;parts&#160;are&#160;the&#160;questions&#160;asked&#160;after&#160;a<br/>
cascade&#160;happens.&#160;Therefore,&#160;without&#160;loss&#160;of&#160;generality,&#160;we&#160;assume&#160;the&#160;first&#160;two&#160;agents&#160;get&#160;private<br/>signal&#160;A&#160;and&#160;take&#160;action&#160;¯<br/>
A&#160;to&#160;start&#160;a&#160;¯<br/>
A&#160;cascade.<br/>
Give&#160;the&#160;above&#160;assumption,&#160;it&#160;is&#160;clear&#160;that&#160;agent&#160;3&#160;cannot&#160;stop&#160;the&#160;cascade&#160;as&#160;she&#160;exactly&#160;knows<br/>
the&#160;private&#160;signal&#160;of&#160;agent&#160;1&#160;and&#160;2&#160;from&#160;their&#160;actions.&#160;Hence,&#160;agent&#160;3&#160;will&#160;take&#160;action&#160;¯<br/>
A&#160;whichever<br/>
19<br/>
<hr/>
<a name=21></a>private&#160;signal&#160;she&#160;receives.&#160;Now,&#160;agent&#160;4&#160;has&#160;a&#160;chance&#160;to&#160;stop&#160;the&#160;cascade&#160;if&#160;both&#160;she&#160;and&#160;agent&#160;3<br/>get&#160;B.&#160;Therefore,&#160;once&#160;she&#160;receives&#160;signal&#160;B,&#160;she&#160;should&#160;definitely&#160;ask&#160;agent&#160;3&#160;the&#160;question&#160;“Did<br/>you&#160;get&#160;signal&#160;B?”&#160;Now&#160;we&#160;have&#160;another&#160;issue&#160;on&#160;designing&#160;the&#160;question&#160;book.&#160;What&#160;questions<br/>should&#160;agent&#160;4&#160;ask&#160;if&#160;she&#160;gets&#160;signal&#160;A.&#160;Since&#160;the&#160;above&#160;question&#160;is&#160;the&#160;most&#160;informative&#160;question<br/>that&#160;agent&#160;4&#160;can&#160;ask,&#160;we&#160;assume&#160;she&#160;will&#160;ask&#160;the&#160;same&#160;question&#160;even&#160;if&#160;she&#160;gets&#160;signal&#160;A.<br/>
When&#160;the&#160;game&#160;goes&#160;to&#160;agent&#160;5,&#160;there&#160;are&#160;two&#160;possible&#160;observations&#160;for&#160;her,&#160;either&#160;¯<br/>
A&#160;¯<br/>
A&#160;¯<br/>
A&#160;¯<br/>
B&#160;or<br/>
¯<br/>
A&#160;¯<br/>
A&#160;¯<br/>
A&#160;¯<br/>
A.&#160;If&#160;¯<br/>
A&#160;¯<br/>
A&#160;¯<br/>
A&#160;¯<br/>
B&#160;is&#160;observed,&#160;the&#160;she&#160;definitely&#160;know&#160;that&#160;the&#160;underlying&#160;private&#160;signal&#160;is&#160;AABB<br/>
and&#160;the&#160;cascade&#160;has&#160;already&#160;been&#160;stopped.&#160;Hence,&#160;she&#160;should&#160;take&#160;a&#160;decision&#160;according&#160;to&#160;her<br/>private&#160;signal.&#160;The&#160;interesting&#160;part&#160;comes&#160;when&#160;she&#160;observes&#160;¯<br/>
A&#160;¯<br/>
A&#160;¯<br/>
A&#160;¯<br/>
A.&#160;Now,&#160;prior&#160;to&#160;asking&#160;any<br/>
questions,&#160;she&#160;knows&#160;there&#160;are&#160;at&#160;least&#160;three&#160;A&#160;in&#160;the&#160;first&#160;four&#160;agent’s&#160;private&#160;signal.&#160;Therefore,&#160;she<br/>should&#160;take&#160;action&#160;¯<br/>
A&#160;whatever&#160;signal&#160;she&#160;receives.&#160;However,&#160;her&#160;question,&#160;even&#160;though&#160;it&#160;cannot<br/>
benefit&#160;herself,&#160;may&#160;be&#160;critical&#160;to&#160;the&#160;following&#160;agents&#160;and&#160;could&#160;enable&#160;them&#160;to&#160;stop&#160;the&#160;cascade.<br/>Suppose&#160;she&#160;gets&#160;¯<br/>
B,&#160;and&#160;she&#160;can&#160;ask&#160;agent&#160;4&#160;the&#160;question&#160;“Did&#160;you&#160;or&#160;agent&#160;3&#160;get&#160;signal&#160;¯<br/>
B?”.<br/>
First,&#160;we&#160;realize&#160;that&#160;agent&#160;4&#160;is&#160;able&#160;to&#160;answer&#160;this&#160;question.&#160;Once&#160;she&#160;get&#160;positive&#160;answer,&#160;she<br/>know&#160;there&#160;are&#160;exactly&#160;3&#160;¯<br/>
As&#160;and&#160;2&#160;¯<br/>
Bs&#160;received&#160;by&#160;the&#160;first&#160;5&#160;agents.&#160;Therefore,&#160;once&#160;the&#160;agent&#160;6&#160;ask<br/>
if&#160;there&#160;are&#160;two&#160;¯<br/>
Bs&#160;in&#160;the&#160;first&#160;five&#160;agents,&#160;she&#160;can&#160;answer&#160;this&#160;question,&#160;and&#160;the&#160;positive&#160;answer<br/>
can&#160;help&#160;the&#160;agent&#160;6&#160;to&#160;stop&#160;the&#160;cascade&#160;once&#160;she&#160;gets&#160;¯<br/>
B.&#160;Now,&#160;we&#160;have&#160;a&#160;clear&#160;example&#160;how&#160;a<br/>
silent&#160;agent&#160;can&#160;actually&#160;help&#160;the&#160;following&#160;active&#160;agents&#160;to&#160;stop&#160;the&#160;cascade&#160;by&#160;asking&#160;questions<br/>in&#160;preparation&#160;of&#160;the&#160;(possible)&#160;questions&#160;asked&#160;by&#160;active&#160;agents.<br/>
Everything&#160;works&#160;well&#160;until&#160;agent&#160;6.&#160;However,&#160;once&#160;agent&#160;6&#160;gets&#160;signal&#160;A,&#160;there&#160;exist&#160;multiple<br/>
questions&#160;that&#160;are&#160;informative.&#160;For&#160;example,&#160;agent&#160;6&#160;can&#160;ask&#160;question&#160;1:&#160;“Did&#160;the&#160;first&#160;five&#160;agents<br/>get&#160;2&#160;Bs?”&#160;or&#160;question&#160;2:&#160;“Did&#160;the&#160;first&#160;five&#160;agents&#160;get&#160;one&#160;or&#160;more&#160;Bs?”.&#160;Both&#160;questions&#160;can<br/>be&#160;answered&#160;by&#160;agent&#160;5,&#160;but&#160;it&#160;is&#160;hard&#160;for&#160;us&#160;to&#160;know&#160;which&#160;one&#160;is&#160;the&#160;better&#160;question&#160;to&#160;help<br/>achieving&#160;asymptotic&#160;learning.&#160;Furthermore,&#160;agent&#160;6&#160;cannot&#160;distinguish&#160;the&#160;exact&#160;number&#160;of&#160;B&#160;in<br/>the&#160;first&#160;5&#160;agents&#160;once&#160;she&#160;receives&#160;B&#160;but&#160;gets&#160;a&#160;negative&#160;answer&#160;from&#160;agent&#160;5.&#160;Therefore,&#160;when<br/>the&#160;cascade&#160;continuous&#160;to&#160;agent&#160;7,&#160;we&#160;have&#160;to&#160;keep&#160;every&#160;branch&#160;of&#160;possible&#160;questions&#160;alive,&#160;and<br/>try&#160;to&#160;proceed&#160;on&#160;every&#160;branch&#160;until&#160;we&#160;finally&#160;understand&#160;that&#160;some&#160;branches&#160;cannot&#160;achieve<br/>asymptotic&#160;learning.&#160;Therefore,&#160;we&#160;can&#160;realize&#160;that&#160;question&#160;guidebooks&#160;are&#160;very&#160;delicate&#160;to&#160;design<br/>even&#160;we&#160;have&#160;already&#160;restrict&#160;our&#160;attention&#160;to&#160;a&#160;single&#160;Yes-No&#160;question.&#160;To&#160;conclude,&#160;even&#160;though<br/>we&#160;can&#160;proceed&#160;and&#160;design&#160;question&#160;guidebooks&#160;in&#160;this&#160;way,&#160;it&#160;is&#160;hard&#160;to&#160;analyze&#160;and&#160;generalize<br/>the&#160;result&#160;to&#160;non-binary&#160;states&#160;and&#160;channels&#160;with&#160;higher&#160;capacity.&#160;The&#160;main&#160;value&#160;of&#160;this&#160;example<br/>is&#160;to&#160;indicate&#160;that&#160;it&#160;may&#160;not&#160;be&#160;the&#160;best&#160;approach&#160;to&#160;design&#160;the&#160;question&#160;guidebooks&#160;directly,&#160;and<br/>also&#160;to&#160;justify&#160;why&#160;we&#160;want&#160;to&#160;work&#160;with&#160;the&#160;corresponding&#160;Markov&#160;chains&#160;instead.<br/>
B.2<br/>
Why&#160;learning&#160;is&#160;more&#160;difficult&#160;in&#160;a&#160;deterministic&#160;network&#160;topology<br/>
Unlike&#160;a&#160;deterministic&#160;network&#160;where&#160;the&#160;topology&#160;is&#160;the&#160;common&#160;knowledge&#160;of&#160;every&#160;agent,&#160;a<br/>common&#160;assumption&#160;is&#160;to&#160;use&#160;a&#160;randomized&#160;network&#160;topology&#160;where&#160;it&#160;is&#160;assumed&#160;that&#160;distributions<br/>of&#160;edges&#160;are&#160;common&#160;knowledge&#160;but&#160;the&#160;realized&#160;set&#160;of&#160;predecessors&#160;Bn&#160;=&#160;{m|(m,&#160;n)&#160;∈&#160;E}&#160;that<br/>agent&#160;n&#160;can&#160;communicate&#160;is&#160;a&#160;private&#160;information&#160;of&#160;agent&#160;n&#160;(otherwise&#160;higher&#160;order&#160;beliefs&#160;will<br/>be&#160;hard&#160;to&#160;analyze).&#160;Under&#160;this&#160;assumption,&#160;if&#160;an&#160;information&#160;cascade&#160;occurs&#160;and&#160;the&#160;information<br/>that&#160;is&#160;allowed&#160;to&#160;get&#160;from&#160;predecessors&#160;with&#160;communication&#160;channels&#160;is&#160;restricted&#160;to&#160;their&#160;private<br/>signals,&#160;it&#160;is&#160;analogous&#160;to&#160;the&#160;model&#160;in&#160;<a href="1811.00226v3s.html#12">[8]&#160;</a>with&#160;neighbor&#160;set&#160;Nn&#160;=&#160;Bn&#160;∪&#160;{i}&#160;∪&#160;{i&#160;+&#160;1},&#160;where<br/>agent&#160;i,&#160;i&#160;+&#160;1&#160;are&#160;the&#160;agents&#160;to&#160;start&#160;the&#160;cascade.&#160;Then,&#160;Theorem&#160;4&#160;in&#160;<a href="1811.00226v3s.html#12">[8]&#160;</a>states&#160;the&#160;condition<br/>that&#160;asymptotic&#160;learning&#160;can&#160;be&#160;achieved&#160;in&#160;randomized&#160;networks.&#160;In&#160;contrast,&#160;things&#160;are&#160;not<br/>that&#160;simple&#160;with&#160;deterministic&#160;networks&#160;as&#160;there&#160;is&#160;an&#160;informational&#160;Braess’s&#160;paradox,&#160;i.e.,&#160;two<br/>information&#160;sources&#160;that&#160;both&#160;individually&#160;suggest&#160;agent&#160;n&#160;to&#160;ignore&#160;her&#160;private&#160;signal&#160;and&#160;take<br/>action&#160;¯<br/>
A&#160;may&#160;collectively&#160;lead&#160;agent&#160;n&#160;take&#160;action&#160;¯<br/>
B&#160;instead.&#160;An&#160;example&#160;will&#160;be&#160;provided&#160;below<br/>
20<br/>
<hr/>
<a name=22></a>to&#160;illustrate&#160;this&#160;phenomenon,&#160;but&#160;the&#160;main&#160;message&#160;here&#160;is&#160;that&#160;problems&#160;in&#160;deterministic&#160;and<br/>randomized&#160;network&#160;topology&#160;are&#160;substantially&#160;different.<br/>
B.2.1<br/>
Informational&#160;Braess’s&#160;paradox&#160;in&#160;deterministic&#160;networks<br/>
Here,&#160;we&#160;want&#160;to&#160;present&#160;a&#160;counter-intuitive&#160;example&#160;showing&#160;that&#160;informational&#160;monotonicity&#160;may<br/>not&#160;exist&#160;in&#160;the&#160;deterministic&#160;network.&#160;In&#160;a&#160;nutshell,&#160;two&#160;(or&#160;more)&#160;sources&#160;of&#160;information&#160;both<br/>suggest&#160;an&#160;agent&#160;ignoring&#160;her&#160;private&#160;signal&#160;and&#160;taking&#160;an&#160;action&#160;¯<br/>
A&#160;may&#160;eventually&#160;makes&#160;agent<br/>
taking&#160;action&#160;¯<br/>
B.<br/>
Consider&#160;the&#160;observable&#160;history&#160;is&#160;represented&#160;by&#160;network&#160;G&#160;contains&#160;two&#160;subnetwork&#160;G1(U,&#160;EU&#160;)<br/>
and&#160;G2(V,&#160;EV&#160;)&#160;and&#160;two&#160;nodes&#160;W1,&#160;W2.&#160;Let&#160;eU&#160;represents&#160;the&#160;edge&#160;between&#160;U<br/>
i,j<br/>
i&#160;and&#160;Uj&#160;,&#160;and&#160;similarly<br/>
for&#160;eV&#160;.<br/>
i,j<br/>
Now,&#160;define&#160;the&#160;topology&#160;of&#160;the&#160;first&#160;subnetwork&#160;G1(U,&#160;EU&#160;)&#160;such&#160;that&#160;EU&#160;=&#160;{eU&#160;,&#160;eU&#160;,&#160;eU&#160;∀j&#160;∈<br/>
1,3<br/>
2,3<br/>
3,j<br/>
{[J&#160;]&#160;\&#160;{1,&#160;2,&#160;3}}},&#160;where&#160;J&#160;is&#160;a&#160;constant&#160;integer;&#160;and&#160;define&#160;the&#160;topology&#160;of&#160;the&#160;second&#160;subnetwork<br/>G2(V,&#160;EV&#160;)&#160;such&#160;that&#160;EV&#160;=&#160;{eV&#160;,&#160;eV&#160;,&#160;eV&#160;,&#160;eV&#160;∀k&#160;∈&#160;{[K]\{1},&#160;{2},&#160;{3}}},&#160;where&#160;K&#160;is&#160;a&#160;fixed&#160;integer.<br/>
1,3<br/>
2,3<br/>
1,k<br/>
3,k<br/>
Then,&#160;the&#160;whole&#160;network&#160;G&#160;is&#160;defined&#160;as&#160;follows:&#160;G&#160;=&#160;(U&#160;∪&#160;V&#160;∪&#160;{W1,&#160;W2},&#160;EU&#160;∪&#160;EV&#160;∪&#160;EW&#160;),<br/>
2<br/>
where&#160;EW&#160;=&#160;{(i,&#160;W<br/>
2<br/>
2)|i&#160;∈&#160;U&#160;∪&#160;V&#160;∪&#160;W1&#160;\&#160;{U2,&#160;V1,&#160;V2}}.&#160;In&#160;short,&#160;W2&#160;can&#160;observe&#160;all&#160;agents&#160;action<br/>
except&#160;agent&#160;U2,&#160;V1,&#160;and&#160;V2.&#160;We&#160;assume&#160;that&#160;agents&#160;make&#160;actions&#160;sequentially,&#160;and&#160;agent&#160;Xi&#160;takes<br/>action&#160;before&#160;agent&#160;Xj&#160;for&#160;all&#160;i&#160;&lt;&#160;j,&#160;X&#160;∈&#160;{U,&#160;V,&#160;W&#160;}&#160;and&#160;agent&#160;Xi&#160;takes&#160;action&#160;before&#160;agent&#160;W2&#160;for<br/>all&#160;X&#160;∈&#160;{U,&#160;V&#160;}.&#160;The&#160;directed&#160;graph&#160;is&#160;depicted&#160;in&#160;Figure&#160;<a href="1811.00226v3s.html#22">2.</a><br/>
𝑈<br/>
…<br/>
1<br/>
𝑈2<br/>
𝑈3<br/>
𝑈4<br/>
𝑈5<br/>
𝑈6<br/>
𝑈𝐽<br/>
𝑊1<br/>
𝑊2<br/>
𝑉<br/>
…<br/>
1<br/>
𝑉2<br/>
𝑉3<br/>
𝑉4<br/>
𝑉5<br/>
𝑉6<br/>
𝑉𝐾<br/>
Figure&#160;2:&#160;Baress’s&#160;paradox&#160;in&#160;deterministic&#160;network<br/>
In&#160;this&#160;topology,&#160;consider&#160;a&#160;realized&#160;observation&#160;of&#160;W2&#160;such&#160;that&#160;actions&#160;taken&#160;by&#160;agents&#160;in&#160;Uj,<br/>
XU&#160;=&#160;¯<br/>
A&#160;for&#160;all&#160;j&#160;≥&#160;3&#160;and&#160;j&#160;=&#160;1,&#160;and&#160;actions&#160;taken&#160;by&#160;agents&#160;in&#160;V<br/>
=&#160;¯<br/>
B&#160;for&#160;all&#160;k&#160;≥&#160;3.&#160;By<br/>
j<br/>
k&#160;,&#160;XVk<br/>
calculating&#160;the&#160;likelihood&#160;ratio&#160;at&#160;W2,&#160;we&#160;know&#160;that&#160;W2&#160;should&#160;ignore&#160;her&#160;private&#160;signal&#160;and&#160;take<br/>action&#160;¯<br/>
A&#160;the&#160;observation&#160;of&#160;XW&#160;=&#160;¯<br/>
A.<br/>
1<br/>
At&#160;this&#160;point,&#160;we&#160;know&#160;that&#160;if&#160;agent&#160;W2&#160;observes&#160;the&#160;history&#160;realized&#160;in&#160;the&#160;above&#160;case,&#160;there<br/>
is&#160;a&#160;information&#160;cascade&#160;on&#160;¯<br/>
A;&#160;and&#160;we&#160;say&#160;this&#160;is&#160;the&#160;first&#160;source&#160;of&#160;information&#160;that&#160;agent&#160;W1&#160;can<br/>
get&#160;from.<br/>
Now,&#160;if&#160;on&#160;top&#160;of&#160;these&#160;observations,&#160;agent&#160;W2&#160;now&#160;can&#160;observe&#160;the&#160;action&#160;taken&#160;by&#160;agent&#160;V1<br/>
(the&#160;purple&#160;dash&#160;line&#160;in&#160;the&#160;figure)&#160;and&#160;XV&#160;=&#160;¯<br/>
A,&#160;which&#160;solely&#160;suggests&#160;agent&#160;W<br/>
1<br/>
2&#160;to&#160;take&#160;action<br/>
¯<br/>
A.&#160;Surprisingly,&#160;if&#160;we&#160;calculate&#160;the&#160;likelihood&#160;ratio&#160;of&#160;W2&#160;using&#160;the&#160;observation&#160;of&#160;both&#160;source<br/>of&#160;information,&#160;agent&#160;W2,&#160;instead&#160;of&#160;being&#160;in&#160;an&#160;information&#160;cascade&#160;and&#160;taking&#160;action&#160;¯<br/>
A,&#160;will<br/>
21<br/>
<hr/>
<a name=23></a>ignore&#160;her&#160;private&#160;signal&#160;and&#160;taking&#160;action&#160;¯<br/>
B&#160;when&#160;K&#160;≥&#160;5.&#160;In&#160;this&#160;case,&#160;although&#160;both&#160;sources<br/>
of&#160;information&#160;suggest&#160;an&#160;information&#160;cascade,&#160;by&#160;considering&#160;the&#160;feasible&#160;sequence&#160;of&#160;the&#160;private<br/>signal&#160;using&#160;the&#160;both&#160;source&#160;of&#160;information,&#160;the&#160;agent&#160;can&#160;choose&#160;to&#160;initiate&#160;an&#160;information&#160;cascade<br/>opposite&#160;to&#160;the&#160;suggested&#160;one.<br/>
Instead&#160;of&#160;presenting&#160;the&#160;detailed&#160;calculations&#160;of&#160;the&#160;likelihood&#160;ratio,&#160;we&#160;want&#160;to&#160;point&#160;out&#160;the<br/>
high-level&#160;idea&#160;why&#160;such&#160;an&#160;informational&#160;Braess’s&#160;paradox&#160;can&#160;happen&#160;in&#160;deterministic&#160;networks.<br/>
In&#160;deterministic&#160;networks,&#160;agents&#160;know&#160;the&#160;whole&#160;network&#160;topology,&#160;and&#160;can&#160;build&#160;high-order<br/>
belief&#160;conditional&#160;on&#160;the&#160;past&#160;agent’s&#160;topology&#160;to&#160;get&#160;some&#160;information&#160;about&#160;some&#160;predecessors’<br/>action&#160;they&#160;cannot&#160;observe&#160;directly.&#160;In&#160;the&#160;example&#160;shown&#160;above,&#160;before&#160;observing&#160;the&#160;action&#160;taken<br/>by&#160;V1,&#160;agent&#160;W2&#160;doesn’t&#160;know&#160;if&#160;the&#160;action&#160;XV&#160;=&#160;¯<br/>
B&#160;she&#160;observes&#160;is&#160;taken&#160;by&#160;agent&#160;V<br/>
k<br/>
k&#160;’s&#160;private<br/>
signal&#160;or&#160;Vk&#160;is&#160;in&#160;an&#160;information&#160;cascade&#160;of&#160;¯<br/>
B.&#160;Therefore,&#160;she&#160;need&#160;to&#160;take&#160;both&#160;scenarios&#160;into<br/>
consideration&#160;to&#160;update&#160;her&#160;posterior&#160;belief&#160;if&#160;XV&#160;(the&#160;purple&#160;line&#160;in&#160;the&#160;figure)&#160;is&#160;not&#160;observable.<br/>
1<br/>
However,&#160;once&#160;she&#160;know&#160;that&#160;XV&#160;=&#160;¯<br/>
A,&#160;she&#160;knows&#160;that&#160;all&#160;X<br/>
,&#160;k&#160;≥&#160;3&#160;are&#160;taken&#160;by&#160;their&#160;private<br/>
1<br/>
Vk<br/>
signal.&#160;When&#160;K&#160;is&#160;large&#160;enough,&#160;agent&#160;W2&#160;will&#160;drop&#160;her&#160;private&#160;signal&#160;and&#160;initiate&#160;an&#160;information<br/>cascade&#160;¯<br/>
B.<br/>
B.3<br/>
Extended&#160;Question&#160;Guidebooks<br/>
Here,&#160;we&#160;want&#160;to&#160;point&#160;out&#160;an&#160;extension&#160;of&#160;the&#160;framework&#160;of&#160;our&#160;question&#160;guidebook.&#160;As&#160;mentioned<br/>in&#160;Section&#160;<a href="1811.00226v3s.html#4">2,&#160;</a>we&#160;are&#160;only&#160;allowed&#160;to&#160;design&#160;question&#160;guidebooks&#160;suggesting&#160;agents&#160;asking&#160;questions<br/>simultaneously.&#160;However,&#160;assume&#160;m&#160;∈&#160;Bn,&#160;questions&#160;being&#160;asked&#160;by&#160;agent&#160;n&#160;to&#160;agent&#160;m&#160;can&#160;be<br/>allowed&#160;to&#160;be&#160;dependent&#160;not&#160;only&#160;on&#160;the&#160;private&#160;signal&#160;and&#160;history&#160;observed&#160;by&#160;agent&#160;n,&#160;but&#160;also<br/>on&#160;the&#160;answers&#160;of&#160;questions&#160;asked&#160;to&#160;other&#160;agents&#160;in&#160;Bn&#160;prior&#160;to&#160;asking&#160;agent&#160;m.&#160;In&#160;short,&#160;the&#160;order<br/>of&#160;agents&#160;in&#160;Bn&#160;queried&#160;matters&#160;in&#160;the&#160;general&#160;framework.&#160;The&#160;framework&#160;of&#160;question&#160;guidebook,<br/>in&#160;general,&#160;should&#160;be&#160;able&#160;to&#160;help&#160;agents&#160;update&#160;their&#160;higher-order&#160;belief&#160;in&#160;the&#160;process&#160;of&#160;asking<br/>questions,&#160;and&#160;not&#160;just&#160;a&#160;one-shot&#160;update&#160;after&#160;all&#160;responses&#160;of&#160;questions&#160;are&#160;received.&#160;In&#160;the<br/>extended&#160;framework,&#160;a&#160;particular&#160;collection&#160;of&#160;sequence&#160;of&#160;set&#160;of&#160;questions&#160;the&#160;information&#160;designer<br/>provides&#160;to&#160;agents&#160;will&#160;be&#160;collectively&#160;called&#160;a&#160;extended&#160;question&#160;guidebook.&#160;The&#160;systematic&#160;analysis<br/>of&#160;extended&#160;question&#160;guidebooks&#160;which&#160;includes&#160;the&#160;freedom&#160;of&#160;query&#160;order&#160;on&#160;predecessors&#160;in&#160;Bn,<br/>is&#160;generally&#160;hard&#160;because&#160;of&#160;the&#160;combinatorial&#160;complexity&#160;of&#160;considering&#160;all&#160;the&#160;possible&#160;order&#160;of<br/>questions,&#160;and&#160;because&#160;the&#160;recursive&#160;analysis&#160;of&#160;the&#160;higher&#160;order&#160;beliefs&#160;on&#160;each&#160;specific&#160;order&#160;of<br/>questions&#160;has&#160;to&#160;be&#160;accounted&#160;for.&#160;To&#160;give&#160;a&#160;glimpse&#160;of&#160;how&#160;an&#160;extended&#160;question&#160;guidebooks<br/>can&#160;help&#160;achieving&#160;asymptotic&#160;learning&#160;efficiently&#160;by&#160;asking&#160;questions&#160;to&#160;agents&#160;with&#160;right&#160;order,&#160;a<br/>simple&#160;example&#160;is&#160;provided.<br/>
B.3.1<br/>
Example&#160;that&#160;the&#160;order&#160;of&#160;questions&#160;matters<br/>
Before&#160;characterizing&#160;question&#160;guidebooks,&#160;we&#160;provide&#160;a&#160;simple&#160;example&#160;demonstrating&#160;question<br/>guidebooks&#160;in&#160;the&#160;general&#160;extended&#160;framework,&#160;where&#160;a&#160;question&#160;guidebook&#160;is&#160;a&#160;collection&#160;of&#160;a<br/>sequence&#160;of&#160;an&#160;ordered&#160;set&#160;of&#160;questions.<br/>
We&#160;start&#160;with&#160;the&#160;most&#160;unrestricted&#160;network,&#160;all&#160;prior&#160;agents&#160;are&#160;contactable,&#160;so&#160;every&#160;agent&#160;is<br/>
free&#160;to&#160;ask&#160;questions&#160;to&#160;any&#160;agents&#160;with&#160;lower&#160;index&#160;than&#160;her&#160;(if&#160;any),&#160;and&#160;there&#160;are&#160;no&#160;capacity<br/>constraints&#160;on&#160;these&#160;communications.&#160;Obviously,&#160;every&#160;agent&#160;can&#160;get&#160;perfect&#160;information&#160;by&#160;asking<br/>enough&#160;questions&#160;to&#160;prior&#160;agents&#160;so&#160;that&#160;asymptotic&#160;learning&#160;can&#160;be&#160;achieved.&#160;In&#160;the&#160;most&#160;naive<br/>case,&#160;every&#160;agent&#160;just&#160;asks&#160;all&#160;past&#160;agents&#160;their&#160;private&#160;signal.&#160;This&#160;will&#160;require&#160;Θ(n)&#160;bits&#160;of<br/>information&#160;per&#160;agent.<br/>
Since&#160;agents&#160;are&#160;homogeneous,&#160;the&#160;learning&#160;can&#160;be&#160;achieved&#160;with&#160;less&#160;communication&#160;through<br/>
the&#160;“backward&#160;level&#160;tracking”&#160;scheme&#160;proposed&#160;below.&#160;First&#160;of&#160;all,&#160;it&#160;an&#160;agent&#160;is&#160;not&#160;in&#160;a&#160;cascade,<br/>
22<br/>
<hr/>
<a name=24></a>she&#160;take&#160;actions&#160;according&#160;to&#160;her&#160;private&#160;signal.&#160;For&#160;agents&#160;in&#160;an&#160;cascade,&#160;suppose&#160;they&#160;are&#160;in&#160;A<br/>cascade,&#160;there&#160;are&#160;three&#160;different&#160;cases&#160;detailed&#160;below:&#160;If&#160;she&#160;gets&#160;A,&#160;then&#160;she&#160;plays&#160;¯<br/>
A&#160;without<br/>
asking&#160;any&#160;questions.&#160;If&#160;she&#160;gets&#160;B,&#160;then&#160;she&#160;asks&#160;her&#160;immediate&#160;predecessor’s&#160;private&#160;signal.&#160;If<br/>her&#160;predecessor’s&#160;private&#160;signal&#160;is&#160;A,&#160;then&#160;she&#160;can&#160;safely&#160;play&#160;A.&#160;The&#160;reason&#160;is&#160;that&#160;she&#160;knows&#160;that<br/>there&#160;must&#160;be&#160;an&#160;agent&#160;in&#160;the&#160;history&#160;has&#160;the&#160;same&#160;number&#160;of&#160;#A&#160;−&#160;#B&#160;and&#160;that&#160;person&#160;plays&#160;A.<br/>Hereafter,&#160;we&#160;say&#160;#A&#160;−&#160;#B&#160;be&#160;the&#160;level&#160;of&#160;agents.&#160;If&#160;she&#160;gets&#160;B&#160;and&#160;her&#160;immediate&#160;predecessor<br/>also&#160;got&#160;B,&#160;she&#160;can&#160;safely&#160;play&#160;B&#160;only&#160;if&#160;she&#160;knows&#160;the&#160;current&#160;level&#160;is&#160;over&#160;2.&#160;She&#160;can&#160;ask&#160;learn<br/>the&#160;level&#160;by&#160;asking&#160;agents&#160;n&#160;−&#160;1,&#160;n&#160;−&#160;2,&#160;.&#160;.&#160;.&#160;about&#160;their&#160;private&#160;signal.&#160;Assuming&#160;that&#160;agent&#160;plays<br/>correctly,&#160;he&#160;would&#160;then&#160;know&#160;the&#160;level&#160;of&#160;that&#160;agent,&#160;and&#160;from&#160;this&#160;could&#160;compute&#160;his&#160;own&#160;level.<br/>
The&#160;remaining&#160;question&#160;is&#160;how&#160;long&#160;an&#160;agent&#160;will&#160;need&#160;to&#160;look&#160;back&#160;in&#160;order&#160;to&#160;find&#160;either&#160;the<br/>
beginning,&#160;an&#160;agent&#160;that&#160;plays&#160;a&#160;different&#160;action,&#160;or&#160;an&#160;index&#160;agent.&#160;In&#160;the&#160;long&#160;run,&#160;if&#160;the&#160;correct<br/>state&#160;of&#160;the&#160;world&#160;is&#160;B&#160;all&#160;agents&#160;will&#160;eventually&#160;play&#160;B.&#160;Thus&#160;B&#160;agents&#160;will&#160;simply&#160;play&#160;B&#160;(because<br/>the&#160;prior&#160;agent&#160;did).&#160;An&#160;A&#160;agent&#160;will&#160;need&#160;to&#160;look&#160;back&#160;until&#160;he&#160;finds&#160;an&#160;index&#160;agent.&#160;However,<br/>this&#160;is&#160;essentially&#160;a&#160;(downward)&#160;biased&#160;random&#160;walk;&#160;and&#160;so&#160;the&#160;expected&#160;number&#160;of&#160;steps&#160;until<br/>locating&#160;an&#160;index&#160;agent&#160;is&#160;constant.&#160;However,&#160;it&#160;is&#160;only&#160;constant&#160;in&#160;the&#160;average&#160;case.&#160;If&#160;the&#160;graph<br/>of&#160;the&#160;level&#160;goes&#160;down&#160;for&#160;log(n)&#160;steps&#160;(as&#160;is&#160;probable&#160;at&#160;some&#160;point),&#160;then&#160;agent&#160;n&#160;will&#160;have&#160;to&#160;ask<br/>at&#160;least&#160;log&#160;n&#160;prior&#160;agents&#160;to&#160;find&#160;an&#160;index&#160;agent.&#160;This&#160;scheme&#160;will&#160;not&#160;work&#160;for&#160;agents&#160;who&#160;only<br/>ask&#160;a&#160;fixed&#160;number&#160;of&#160;queries.&#160;Our&#160;surprising&#160;result&#160;is&#160;that,&#160;actually,&#160;agents&#160;can&#160;manage&#160;with&#160;only<br/>asking&#160;just&#160;the&#160;immediate&#160;predecessor&#160;a&#160;fixed&#160;number&#160;of&#160;queries,&#160;namely&#160;one.<br/>
B.4<br/>
A&#160;subtle&#160;weaker&#160;assumption&#160;on&#160;common&#160;knowledge&#160;of&#160;question&#160;guidebook<br/>
At&#160;the&#160;end&#160;of&#160;the&#160;Section&#160;<a href="1811.00226v3s.html#4">2,&#160;</a>we&#160;assume&#160;that&#160;the&#160;whole&#160;question&#160;guidebook&#160;is&#160;the&#160;common&#160;knowledge.<br/>However,&#160;it&#160;is&#160;no&#160;loss&#160;to&#160;use&#160;a&#160;slightly&#160;weaker&#160;assumption&#160;that&#160;only&#160;the&#160;feasibility&#160;and&#160;the<br/>compatibility&#160;of&#160;the&#160;proposed&#160;question&#160;guidebook&#160;is&#160;common&#160;knowledge.&#160;To&#160;see&#160;the&#160;difference<br/>between&#160;this&#160;two&#160;assumptions,&#160;we&#160;have&#160;to&#160;consider&#160;the&#160;set&#160;of&#160;question&#160;guidebooks&#160;containing&#160;index-<br/>dependent&#160;questions.<br/>
Now,&#160;consider&#160;we&#160;have&#160;two&#160;different&#160;question&#160;guidebooks,&#160;Q1,&#160;Q2&#160;both&#160;achieves&#160;asymptotic<br/>
learning.&#160;These&#160;two&#160;questions&#160;guidebooks,&#160;concerning&#160;the&#160;usefulness&#160;of&#160;questions,&#160;become&#160;opera-<br/>tional&#160;only&#160;when&#160;a&#160;cascade&#160;is&#160;initiated.&#160;Now,&#160;consider&#160;a&#160;joint&#160;question&#160;guidebook&#160;Q∗&#160;which&#160;uses<br/>questions&#160;in&#160;Q1&#160;when&#160;a&#160;cascade&#160;is&#160;initiated&#160;by&#160;the&#160;agent&#160;with&#160;odd&#160;index,&#160;and&#160;use&#160;questions&#160;in<br/>Q2&#160;when&#160;cascade&#160;is&#160;initiated&#160;by&#160;even-indexed&#160;agent.&#160;(This&#160;question&#160;guidebook&#160;can&#160;still&#160;achieve<br/>asymptotic&#160;learning,&#160;but&#160;it’s&#160;not&#160;the&#160;main&#160;point.)&#160;Applying&#160;the&#160;original&#160;assumption,&#160;we&#160;need&#160;to<br/>disclose&#160;the&#160;whole&#160;question&#160;guidebook&#160;to&#160;all&#160;agents,&#160;but&#160;it&#160;is&#160;straightforward&#160;that&#160;a&#160;half&#160;of&#160;the<br/>question&#160;guidebook,&#160;after&#160;an&#160;agent&#160;observes&#160;the&#160;history&#160;and&#160;knows&#160;that&#160;the&#160;cascade&#160;was&#160;initiated<br/>by&#160;an&#160;odd-indexed&#160;agent&#160;or&#160;an&#160;even-indexed&#160;one,&#160;is&#160;useless&#160;for&#160;her&#160;on&#160;updating&#160;her&#160;posterior&#160;beliefs.<br/>By&#160;restricting&#160;to&#160;the&#160;assumption&#160;which&#160;commits&#160;to&#160;the&#160;feasibility&#160;and&#160;incentive&#160;compatibility&#160;of&#160;the<br/>question&#160;guidebook,&#160;all&#160;agents’&#160;best&#160;response&#160;are&#160;to&#160;ask&#160;the&#160;questions&#160;suggested&#160;by&#160;the&#160;question<br/>guidebook,&#160;and&#160;this&#160;is&#160;enough&#160;to&#160;make&#160;our&#160;scheme&#160;stand.<br/>
B.5<br/>
Complementary&#160;discussion&#160;on&#160;mapping&#160;question&#160;guidebook&#160;to&#160;Markov<br/>chains<br/>
To&#160;formulate&#160;the&#160;mapping,&#160;we&#160;need&#160;to&#160;know&#160;how&#160;many&#160;of&#160;states&#160;are&#160;required&#160;in&#160;these&#160;Markov<br/>chains&#160;first.<br/>
Since&#160;each&#160;channel&#160;e&#160;has&#160;finite&#160;capacity,&#160;denoted&#160;by&#160;c(e)&#160;and&#160;|B(n)|&#160;&lt;&#160;∞,&#160;the&#160;answers&#160;of<br/>
questions&#160;asked&#160;by&#160;agent&#160;n&#160;conditioned&#160;on&#160;the&#160;observed&#160;history&#160;and&#160;her&#160;private&#160;signal&#160;can&#160;partition<br/>the&#160;information&#160;space&#160;to&#160;qn(Hn,&#160;sn)&#160;disjoint&#160;information&#160;sets,&#160;where&#160;qn(Hn,&#160;sn)&#160;≤&#160;Πe∈B(n)2c(e).<br/>
23<br/>
<hr/>
<a name=25></a>Besides,&#160;the&#160;minimum&#160;number&#160;of&#160;states&#160;sufficient&#160;to&#160;represent&#160;In(Q,&#160;Hn)&#160;in&#160;agent&#160;n&#160;also&#160;depends<br/>on&#160;the&#160;number&#160;of&#160;information&#160;sets&#160;in&#160;the&#160;agent&#160;n&#160;−&#160;1,&#160;|In−1(Q,&#160;Hn−1)|.&#160;Thus,&#160;the&#160;upper&#160;bound&#160;of<br/>the&#160;minimum&#160;number&#160;of&#160;states&#160;sufficient&#160;to&#160;represent&#160;In(Q,&#160;Hn)&#160;can&#160;be&#160;written&#160;as&#160;a&#160;recursive&#160;form:<br/>
|In(Q,&#160;Hn)|&#160;=&#160;min{|In−1(Q,&#160;Hn−1)|,&#160;qn(Hn−1,&#160;A)}&#160;+&#160;min{|In−1(Q,&#160;Hn−1)|,&#160;qn(Hn−1,&#160;B)}<br/>
(8)<br/>
With&#160;the&#160;knowledge&#160;of&#160;the&#160;number&#160;of&#160;required&#160;states&#160;in&#160;Markov&#160;chains,&#160;next&#160;we&#160;associate&#160;a<br/>
question&#160;guidebook&#160;with&#160;a&#160;sequence&#160;of&#160;sets&#160;of&#160;Markov&#160;chains&#160;sharing&#160;the&#160;same&#160;state&#160;space.&#160;Denote<br/>(G,&#160;(Mn))&#160;to&#160;be&#160;a&#160;sequence&#160;of&#160;sets&#160;of&#160;Markov&#160;chains,&#160;where&#160;G&#160;is&#160;the&#160;set&#160;of&#160;states&#160;and&#160;Mn&#160;is<br/>the&#160;set&#160;of&#160;Markov&#160;chains&#160;at&#160;time&#160;n.&#160;Since&#160;we&#160;are&#160;allowed&#160;to&#160;ask&#160;different&#160;questions&#160;for&#160;different<br/>observed&#160;histories,&#160;we&#160;can&#160;have&#160;different&#160;Markov&#160;chains&#160;for&#160;different&#160;feasible&#160;histories&#160;according&#160;to<br/>the&#160;current&#160;question&#160;guidebook,&#160;hence&#160;|Mt|&#160;=&#160;|{Hn|P&#160;(Hn|Q)&#160;&gt;&#160;0}|.&#160;With&#160;<a href="1811.00226v3s.html#25">(8),&#160;</a>we&#160;know&#160;that&#160;that<br/>|G|&#160;=&#160;sup<br/>
|I<br/>
n,Hn∈H,sn<br/>
n(Q,&#160;Hn)|&#160;suffices&#160;for&#160;our&#160;question&#160;guidebooks.&#160;With&#160;such&#160;a&#160;G,&#160;questions&#160;asked<br/>
by&#160;agent&#160;n&#160;conditioned&#160;on&#160;an&#160;observed&#160;history&#160;Hn&#160;and&#160;can&#160;be&#160;written&#160;as&#160;a&#160;unique&#160;Markov&#160;chain<br/>transition&#160;matrix.&#160;However,&#160;for&#160;the&#160;simplicity&#160;of&#160;identifying&#160;the&#160;case&#160;that&#160;active&#160;players&#160;actually<br/>stop&#160;the&#160;cascade,&#160;an&#160;extra&#160;state,&#160;G0&#160;is&#160;added&#160;to&#160;capture&#160;events&#160;when&#160;this&#160;cascade&#160;is&#160;stopped.&#160;For<br/>every&#160;silent&#160;agent,&#160;G0&#160;is&#160;an&#160;isolated&#160;state&#160;which&#160;has&#160;no&#160;(directed)&#160;edges&#160;to/from&#160;other&#160;states.&#160;For<br/>active&#160;agents,&#160;once&#160;a&#160;cascade&#160;is&#160;stopped,&#160;the&#160;state&#160;transitions&#160;to&#160;stage&#160;G0&#160;irrespective&#160;of&#160;the&#160;previous<br/>state.&#160;With&#160;the&#160;new&#160;G∗&#160;=&#160;G&#160;∪&#160;G0,&#160;once&#160;we&#160;specify&#160;the&#160;series&#160;of&#160;sets&#160;of&#160;Markov&#160;transition&#160;matrices<br/>that&#160;each&#160;agent&#160;uses&#160;for&#160;information&#160;set&#160;partition,&#160;the&#160;question&#160;guidebook&#160;is&#160;uniquely&#160;determined.<br/>
C<br/>
Appendix:&#160;Related&#160;work<br/>
Social&#160;learning,&#160;or&#160;so&#160;called&#160;Bayesian&#160;observation&#160;learning,&#160;studies&#160;whether&#160;and&#160;how&#160;consensus<br/>(unanimous&#160;actions)&#160;can&#160;be&#160;reached&#160;among&#160;sequential&#160;Bayes-rational&#160;decision&#160;makers&#160;under&#160;incom-<br/>plete&#160;information.&#160;Key&#160;result&#160;shown&#160;in&#160;<a href="1811.00226v3s.html#12">[1,&#160;2,&#160;3]&#160;</a>says&#160;that&#160;with&#160;homogeneous&#160;and&#160;Bayes-rational<br/>agents&#160;receiving&#160;binary&#160;private&#160;signals,&#160;an&#160;Information&#160;cascade,&#160;all&#160;but&#160;a&#160;few&#160;of&#160;the&#160;first&#160;agents<br/>will&#160;cascade&#160;to&#160;the&#160;less&#160;profitable&#160;action,&#160;happens&#160;almost&#160;surely.&#160;Once&#160;an&#160;information&#160;cascade<br/>occurs,&#160;no&#160;future&#160;private&#160;signals&#160;are&#160;revealed.&#160;Smith&#160;and&#160;Sørensen&#160;<a href="1811.00226v3s.html#12">[4]&#160;</a>significantly&#160;<a href="1811.00226v3s.html#25">generalized19<br/></a>the&#160;model&#160;to&#160;allow&#160;for&#160;richer&#160;signals&#160;characterized&#160;by&#160;the&#160;likelihood&#160;ratio&#160;of&#160;the&#160;two&#160;states&#160;of&#160;the<br/>world&#160;deduced&#160;from&#160;the&#160;private&#160;signals,&#160;and&#160;heterogeneous&#160;agent&#160;typ<a href="1811.00226v3s.html#25">es20.&#160;</a>Using&#160;both&#160;martingale<br/>techniques&#160;and&#160;Markovian&#160;analysis,&#160;they&#160;proved&#160;that&#160;with&#160;unbounded&#160;likelihood&#160;ratios&#160;in&#160;the&#160;pri-<br/>vate&#160;signals,&#160;any&#160;cascade&#160;can&#160;be&#160;stopped&#160;and&#160;learning&#160;toward&#160;the&#160;correct&#160;action&#160;can&#160;be&#160;achieved;<br/>the&#160;speed&#160;of&#160;learning&#160;in&#160;this&#160;setting&#160;is&#160;characterized&#160;in&#160;<a href="1811.00226v3s.html#12">[6,&#160;7].</a><br/>
These&#160;initial&#160;works&#160;lead&#160;to&#160;considerable&#160;follow-up&#160;work&#160;towards&#160;understanding&#160;information&#160;cas-<br/>
cades&#160;better,&#160;and&#160;towards&#160;achieving&#160;(asymptotic)&#160;learning.&#160;The&#160;vast&#160;majority&#160;of&#160;work&#160;here&#160;studies<br/>how&#160;modifying&#160;the&#160;information&#160;structure&#160;of&#160;the&#160;problem&#160;impacts&#160;cascades&#160;or&#160;allows&#160;for&#160;learning.&#160;As<br/>these&#160;are&#160;closest&#160;to&#160;our&#160;work,&#160;we&#160;will&#160;discuss&#160;these&#160;in&#160;detail&#160;to&#160;highlight&#160;our&#160;contributions&#160;and&#160;the<br/>differences.&#160;Aside&#160;from&#160;those&#160;works&#160;in&#160;the&#160;above&#160;field,&#160;there&#160;is&#160;a&#160;vast&#160;literature&#160;<a href="1811.00226v3s.html#12">[14,&#160;15,&#160;</a><a href="1811.00226v3s.html#13">25,&#160;26,&#160;27]<br/></a>that&#160;consider&#160;non-Bayesian&#160;agents&#160;including&#160;bounded&#160;rational&#160;players,&#160;irrational&#160;players,&#160;and&#160;algo-<br/>rithmic&#160;agents,&#160;and&#160;alternate&#160;history&#160;update&#160;rules&#160;as&#160;a&#160;means&#160;of&#160;achieving&#160;learning.&#160;A&#160;majority<br/>of&#160;this&#160;set&#160;of&#160;literature&#160;studies&#160;the&#160;(optimal)&#160;decision&#160;rules&#160;in&#160;decentralized&#160;(binary)&#160;hypothesis<br/>testing&#160;problem&#160;on&#160;a&#160;variety&#160;of&#160;network&#160;models&#160;<a href="1811.00226v3s.html#13">[28,&#160;29,&#160;30].&#160;</a>Since&#160;the&#160;Bayes-rationality&#160;constraint<br/>differentiates&#160;our&#160;work&#160;from&#160;the&#160;work&#160;on&#160;decentralized&#160;hypothesis&#160;testing&#160;problems,&#160;we&#160;will&#160;only<br/>
19The&#160;work&#160;in&#160;<a href="1811.00226v3s.html#12">[5,&#160;4]&#160;</a>also&#160;developed&#160;the&#160;generalization&#160;to&#160;arbitrary&#160;but&#160;finite&#160;states&#160;of&#160;the&#160;world&#160;and&#160;a&#160;finite&#160;set&#160;of<br/>
actions.<br/>
20Here&#160;a&#160;new&#160;phenomenon&#160;called&#160;“confounded&#160;learning”&#160;is&#160;demonstrated&#160;where&#160;in&#160;the&#160;long&#160;run&#160;agents&#160;of&#160;different<br/>
types&#160;will&#160;herd&#160;on&#160;the&#160;same&#160;action&#160;and&#160;from&#160;the&#160;actions&#160;it&#160;will&#160;be&#160;impossible&#160;to&#160;detect&#160;the&#160;types.<br/>
24<br/>
<hr/>
<a name=26></a>discuss&#160;several&#160;seminal&#160;works&#160;and&#160;highlight&#160;one&#160;work&#160;<a href="1811.00226v3s.html#12">[16],&#160;</a>in&#160;particular,&#160;that&#160;achievedsasymptotic<br/>learning&#160;with&#160;a&#160;specific&#160;set&#160;of&#160;four-state&#160;Markov&#160;chains.&#160;The&#160;approach&#160;in&#160;<a href="1811.00226v3s.html#12">[16],&#160;</a>from&#160;the&#160;perspective<br/>of&#160;information&#160;design,&#160;is&#160;similar&#160;in&#160;spirit&#160;to&#160;partitioning&#160;information&#160;state&#160;to&#160;information&#160;sets,&#160;but<br/>for&#160;non-Bayesian&#160;agents.&#160;Last,&#160;there&#160;is&#160;also&#160;literature&#160;that&#160;allows&#160;for&#160;heterogeneous&#160;types&#160;of&#160;agents<br/>or&#160;changes&#160;the&#160;actions&#160;and&#160;the&#160;payoff&#160;structure,&#160;and&#160;studies&#160;the&#160;impact&#160;of&#160;these&#160;on&#160;social&#160;learning.<br/>In&#160;the&#160;literature&#160;with&#160;heterogeneous&#160;agent&#160;typ<a href="1811.00226v3s.html#13">es[31,&#160;32,&#160;27],&#160;</a>disagreement&#160;between&#160;agents&#160;typically<br/>leads&#160;to&#160;an&#160;information&#160;cascade&#160;but&#160;the&#160;presence&#160;of&#160;poorly&#160;informed&#160;agents&#160;surprisingly&#160;reduces&#160;the<br/>probability&#160;of&#160;a&#160;wrong&#160;cascade.&#160;Papers&#160;<a href="1811.00226v3s.html#12">[9,&#160;10,&#160;11,&#160;12]&#160;</a>that&#160;modify&#160;the&#160;actions,&#160;typically&#160;consider<br/>continuum&#160;action&#160;spaces&#160;that&#160;result&#160;in&#160;learning.&#160;We&#160;will&#160;not&#160;discuss&#160;the&#160;last&#160;class&#160;of&#160;literature&#160;in<br/>detail&#160;but&#160;include&#160;the&#160;references&#160;for&#160;completeness.<br/>
As&#160;every&#160;agent&#160;is&#160;endowed&#160;with&#160;a&#160;(conditionally)&#160;independent&#160;and&#160;informative&#160;private&#160;signal<br/>
about&#160;the&#160;state&#160;of&#160;the&#160;world,&#160;learning&#160;would&#160;result&#160;if&#160;these&#160;signals&#160;are&#160;communicated&#160;and&#160;collected<br/>frequently&#160;enough&#160;and&#160;in&#160;an&#160;accurate&#160;fashion.&#160;The&#160;emergence&#160;of&#160;information&#160;cascades&#160;(and&#160;herd-<br/>ing)&#160;shows&#160;that&#160;the&#160;information&#160;assimilation&#160;part&#160;is&#160;faulty.&#160;Changing&#160;the&#160;underlying&#160;information<br/>structure&#160;either&#160;by&#160;revealing&#160;only&#160;part&#160;of&#160;the&#160;information&#160;in&#160;the&#160;database,&#160;by&#160;modifying&#160;the&#160;in-<br/>formation&#160;in&#160;the&#160;common&#160;database&#160;or&#160;by&#160;adding&#160;new&#160;channels&#160;of&#160;information&#160;have&#160;then&#160;been&#160;the<br/>approaches&#160;that&#160;have&#160;been&#160;taken.&#160;In&#160;<a href="1811.00226v3s.html#13">[33],&#160;</a>only&#160;a&#160;(random)&#160;subset&#160;of&#160;the&#160;past&#160;agents’&#160;actions&#160;are<br/>revealed&#160;to&#160;the&#160;current&#160;agent.&#160;This&#160;feature&#160;allows&#160;some&#160;agents&#160;to&#160;take&#160;actions&#160;solely&#160;<a href="1811.00226v3s.html#26">based21&#160;</a>on<br/>their&#160;private&#160;signal,&#160;and&#160;the&#160;paper&#160;characterizes&#160;the&#160;properties&#160;of&#160;these&#160;subsets&#160;(called&#160;networks)<br/>such&#160;that&#160;learning&#160;results.&#160;A&#160;key&#160;result&#160;is&#160;that&#160;even&#160;with&#160;private&#160;signals&#160;having&#160;a&#160;bounded&#160;likelihood<br/>ratio,&#160;there&#160;exist&#160;networks&#160;such&#160;that&#160;learning&#160;occurs.&#160;The&#160;authors&#160;in&#160;<a href="1811.00226v3s.html#12">[13]&#160;</a>show&#160;that&#160;a&#160;special&#160;class<br/>of&#160;simple&#160;networks&#160;also&#160;leads&#160;to&#160;learning,&#160;where&#160;agents&#160;only&#160;see&#160;the&#160;actions&#160;of&#160;at&#160;most&#160;d&#160;past&#160;agents,<br/>and&#160;where&#160;any&#160;agent’s&#160;action&#160;is&#160;only&#160;observed&#160;by&#160;agents&#160;at&#160;most&#160;L&#160;indices&#160;ahead.&#160;Recognizing&#160;that<br/>displaying&#160;no&#160;past&#160;action&#160;history&#160;would&#160;also&#160;result&#160;in&#160;Bayes-rational&#160;agents&#160;revealing&#160;their&#160;private<br/>signals,&#160;<a href="1811.00226v3s.html#13">[34]&#160;</a>determined&#160;the&#160;minimum&#160;sequence&#160;of&#160;revelation&#160;agents&#160;that&#160;are&#160;needed&#160;for&#160;learning:<br/>each&#160;agent&#160;n&#160;reveals&#160;independently&#160;with&#160;probability&#160;pn&#160;where&#160;we&#160;need&#160;pn&#160;∝&#160;1/n.&#160;In&#160;<a href="1811.00226v3s.html#14">[35,&#160;36]&#160;</a>,&#160;the<br/>ordering&#160;information&#160;of&#160;the&#160;subset&#160;of&#160;agents&#160;whose&#160;actions&#160;are&#160;revealed,&#160;is&#160;omitted&#160;but&#160;nevertheless<br/>learning&#160;results.&#160;Examples&#160;of&#160;imperfect&#160;observation&#160;of&#160;history&#160;that&#160;do&#160;not&#160;lead&#160;to&#160;complete&#160;learning<br/>often&#160;feature&#160;assumptions&#160;such&#160;as&#160;deterministic&#160;sub-sampling&#160;of&#160;past&#160;agents’&#160;actions&#160;(sometimes<br/>only&#160;by&#160;a&#160;finite&#160;number&#160;of&#160;agents),&#160;unknown&#160;observation&#160;order&#160;and&#160;aggregating&#160;observations,&#160;such<br/>as&#160;in&#160;<a href="1811.00226v3s.html#14">[37,&#160;38,&#160;39,&#160;40,&#160;41,&#160;42,&#160;43,&#160;44,&#160;45].</a><br/>
In&#160;<a href="1811.00226v3s.html#14">[46,&#160;47,&#160;</a><a href="1811.00226v3s.html#13">23],&#160;</a>imperfections&#160;are&#160;added&#160;when&#160;the&#160;information&#160;is&#160;stored&#160;in&#160;the&#160;database.&#160;Whereas<br/>
this&#160;does&#160;not&#160;result&#160;in&#160;learning,&#160;discontinuous&#160;and&#160;non-monotonic&#160;behavior&#160;in&#160;the&#160;amount&#160;of&#160;imper-<br/>fection&#160;added&#160;is&#160;shown;&#160;this&#160;adds&#160;to&#160;the&#160;literature&#160;on&#160;information&#160;Braess&#160;paradoxes&#160;observed&#160;with<br/>equilibrium&#160;behavior.&#160;Along&#160;the&#160;same&#160;lines,&#160;by&#160;allowing&#160;for&#160;stochastic&#160;arrivals,&#160;in&#160;<a href="1811.00226v3s.html#14">[48],&#160;</a>uncertainty<br/>in&#160;whether&#160;an&#160;agent&#160;arrived&#160;and&#160;didn’t&#160;purchase&#160;or&#160;no&#160;agent&#160;arrived,&#160;results&#160;in&#160;discontinuous&#160;and<br/>non-monotonic&#160;behavior&#160;of&#160;the&#160;wrong&#160;cascade&#160;probability&#160;in&#160;the&#160;uncertainty,&#160;even&#160;though&#160;learn-<br/>ing&#160;doesn’t&#160;result.&#160;Finally,&#160;the&#160;impact&#160;of&#160;additional&#160;information&#160;via&#160;reviews&#160;of&#160;the&#160;item&#160;obtained<br/>when&#160;purchases&#160;are&#160;made,&#160;is&#160;studied&#160;in&#160;<a href="1811.00226v3s.html#13">[20,&#160;24,&#160;</a><a href="1811.00226v3s.html#12">7],&#160;</a>with&#160;the&#160;main&#160;conclusions&#160;that&#160;learning&#160;requires<br/>unbounded&#160;likelihood&#160;ratios&#160;of&#160;the&#160;private&#160;signals&#160;(and&#160;not&#160;the&#160;reviews)&#160;and&#160;information&#160;Braess<br/>paradoxes&#160;result&#160;in&#160;extremely&#160;non-intuitive&#160;behaviors.<br/>
By&#160;relaxing&#160;the&#160;assumption&#160;that&#160;agents&#160;are&#160;Bayes-rational,&#160;learning,&#160;also&#160;called&#160;optimal&#160;deci-<br/>
sion&#160;rule,&#160;has&#160;been&#160;studied&#160;in&#160;distributed&#160;hypothesis&#160;testing&#160;problems&#160;with&#160;long&#160;history.&#160;A&#160;seminal<br/>w<a href="1811.00226v3s.html#12">ork[14]&#160;</a>studied&#160;distributed&#160;binary&#160;hypothesis&#160;testing&#160;problem&#160;and&#160;achieve&#160;learning&#160;(limit&#160;prob-<br/>ability&#160;of&#160;error&#160;zero&#160;in&#160;their&#160;language)&#160;with&#160;agents&#160;using&#160;a&#160;four-valued&#160;statistics-based&#160;algorithm.<br/>A&#160;following&#160;work&#160;by&#160;Hellman&#160;and&#160;Cover&#160;<a href="1811.00226v3s.html#12">[15]&#160;</a>showed&#160;that&#160;asymptotic&#160;learning&#160;is&#160;not&#160;achievable<br/>
21By&#160;Bayes-rationality,&#160;this&#160;is&#160;equivalent&#160;to&#160;the&#160;revelation&#160;of&#160;their&#160;private&#160;signal.<br/>
25<br/>
<hr/>
<a name=27></a>under&#160;bounded&#160;likelihood&#160;ratio&#160;on&#160;signals.&#160;General&#160;results,&#160;without&#160;a&#160;specified&#160;class&#160;of&#160;network<br/>topology,&#160;of&#160;distributed&#160;hypothesis&#160;testing&#160;were&#160;summarized/presented&#160;in&#160;<a href="1811.00226v3s.html#14">[49].&#160;</a>Learning&#160;in&#160;tree<br/>networks&#160;with&#160;bounded&#160;depth/degree&#160;with&#160;algorithmic&#160;agents&#160;were&#160;respectively&#160;studied&#160;in&#160;<a href="1811.00226v3s.html#13">[28,&#160;29].<br/></a>Restricting&#160;attentions&#160;to&#160;a&#160;line-structure&#160;network,&#160;named&#160;tandem&#160;network,&#160;although&#160;there&#160;is&#160;no<br/>learning&#160;when&#160;the&#160;signal&#160;distributions&#160;are&#160;unknown&#160;a&#160;priori&#160;<a href="1811.00226v3s.html#14">[40],&#160;</a>learning&#160;can&#160;be&#160;achieved&#160;at&#160;the<br/>sub-exponential&#160;rate&#160;for&#160;unbounded&#160;likelihood&#160;ratio&#160;in&#160;<a href="1811.00226v3s.html#13">[30].&#160;</a>In&#160;order&#160;to&#160;study&#160;what&#160;additional<br/>information&#160;is&#160;required&#160;to&#160;achieve&#160;learning&#160;under&#160;bounded&#160;likelihood&#160;ratio,&#160;authors&#160;in&#160;<a href="1811.00226v3s.html#12">[16]&#160;</a>allowed<br/>agents&#160;to&#160;see&#160;K&#160;≥&#160;2&#160;immediate&#160;predecessors&#160;actions,&#160;instead&#160;of&#160;just&#160;one.&#160;It&#160;is&#160;shown&#160;in&#160;<a href="1811.00226v3s.html#12">[16]&#160;</a>that<br/>asymptotic&#160;learning&#160;can&#160;be&#160;achieved&#160;using&#160;a&#160;specific&#160;set&#160;of&#160;four-state&#160;Markov&#160;chains,&#160;with&#160;K&#160;=&#160;2.<br/>From&#160;the&#160;perspective&#160;of&#160;information&#160;design,&#160;this&#160;approach&#160;of&#160;designing&#160;Markov&#160;chains&#160;for&#160;learning<br/>is&#160;similar&#160;in&#160;spirit&#160;to&#160;a&#160;partition&#160;of&#160;information&#160;sets,&#160;but&#160;for&#160;non-Bayesian&#160;agents.<br/>
Although&#160;designing&#160;Markov&#160;chains&#160;for&#160;learning,&#160;a&#160;prototype&#160;of&#160;information&#160;set&#160;partition,&#160;is<br/>
provided&#160;in&#160;<a href="1811.00226v3s.html#12">[16],&#160;</a>conditions&#160;to&#160;achieve&#160;learning&#160;in&#160;models&#160;with&#160;Bayesian&#160;agents&#160;are&#160;usually&#160;more<br/>harsh&#160;than&#160;with&#160;non-Bayesian&#160;agents.&#160;A&#160;well-known&#160;example&#160;is&#160;that&#160;even&#160;though&#160;neither&#160;Bayesian<br/>or&#160;Non-Bayesian&#160;model&#160;cannot&#160;achieve&#160;asymptotic&#160;learning&#160;in&#160;bounded-likelihood&#160;ratio&#160;signal&#160;with<br/>binary&#160;actions&#160;<a href="1811.00226v3s.html#12">[14],&#160;</a>learning&#160;under&#160;bounded-likelihood&#160;ratio&#160;signal&#160;can&#160;be&#160;achieved&#160;in&#160;ternary&#160;ac-<br/>tions&#160;<a href="1811.00226v3s.html#14">[50]&#160;</a>among&#160;Non-Bayesian&#160;agents,&#160;but&#160;not&#160;among&#160;Bayesian&#160;agents&#160;<a href="1811.00226v3s.html#14">[51].&#160;</a>The&#160;Bayesian-agent<br/>assumption&#160;restricts&#160;some&#160;particular&#160;(realized&#160;by&#160;nature)&#160;agents’&#160;action&#160;space&#160;and&#160;hence&#160;blocks&#160;the<br/>information&#160;aggregation.&#160;To&#160;study&#160;how&#160;to&#160;design&#160;information&#160;structure&#160;shown&#160;to&#160;Bayes-rational<br/>agents,&#160;there&#160;is&#160;an&#160;emerging&#160;field&#160;called&#160;“Information&#160;design”&#160;following&#160;a&#160;seminal&#160;paper&#160;“Bayesian<br/>Persuasion”&#160;by&#160;Kamenica&#160;and&#160;Gentzkow&#160;in&#160;<a href="1811.00226v3s.html#12">[17].&#160;</a>With&#160;the&#160;commitment&#160;power&#160;on&#160;the&#160;information<br/>structure&#160;(without&#160;changing&#160;the&#160;prior&#160;beliefs&#160;of&#160;agents),&#160;designed&#160;randomized&#160;signal&#160;can&#160;partition<br/>the&#160;information&#160;space&#160;and&#160;change&#160;agents’&#160;posterior&#160;beliefs&#160;to&#160;change&#160;agents’&#160;preferred&#160;actions&#160;with<br/>some&#160;probability.&#160;However,&#160;the&#160;nature&#160;of&#160;our&#160;problem,&#160;the&#160;finite&#160;communication&#160;capacity,&#160;restricts<br/>the&#160;strength&#160;(richness)&#160;of&#160;the&#160;additional&#160;signal&#160;available,&#160;hence&#160;that&#160;changing&#160;every&#160;agents&#160;action<br/>with&#160;additional&#160;signals&#160;is&#160;positive&#160;probability&#160;in&#160;order&#160;to&#160;stop&#160;cascades,&#160;is&#160;not&#160;possible.&#160;To&#160;over-<br/>come&#160;this&#160;and&#160;achieve&#160;learning,&#160;only&#160;a&#160;particular&#160;set&#160;of&#160;agents,&#160;called&#160;active&#160;agents&#160;in&#160;Definition<br/><a href="1811.00226v3s.html#6">5,&#160;</a>has&#160;the&#160;positive&#160;probability&#160;to&#160;stop&#160;the&#160;cascade.&#160;The&#160;purpose&#160;of&#160;the&#160;rest&#160;of&#160;agents,&#160;called&#160;silent<br/>agents&#160;in&#160;Definition&#160;<a href="1811.00226v3s.html#6">5,&#160;</a>is&#160;to&#160;relay&#160;the&#160;information&#160;to&#160;make&#160;active&#160;agents&#160;to&#160;be&#160;“persuadable”&#160;(have<br/>a&#160;positive&#160;probability&#160;to&#160;stop&#160;the&#160;cascade&#160;after&#160;updating&#160;their&#160;posterior&#160;likelihood&#160;ratio).&#160;From&#160;this<br/>perspective,&#160;the&#160;approach&#160;presented&#160;in&#160;this&#160;paper&#160;can&#160;be&#160;viewed&#160;as&#160;“relayed&#160;Bayesian&#160;persuasion”.<br/>Essentially,&#160;a&#160;long&#160;series&#160;of&#160;silent&#160;agents&#160;convince&#160;the&#160;next&#160;active&#160;agent&#160;that&#160;she&#160;is&#160;in&#160;a&#160;wrong<br/>cascade&#160;by&#160;making&#160;the&#160;likelihood&#160;ratio&#160;become&#160;very&#160;large,&#160;effectively&#160;unbounded.<br/>
26<br/>
<hr/>
<a name="outline"></a><h1>Document Outline</h1>
<ul>
<li><a href="1811.00226v3s.html#2">1 Introduction</a></li>
<li><a href="1811.00226v3s.html#4">2 Problem Formulation</a></li>
<li><a href="1811.00226v3s.html#5">3 Telephone-game Network, Strategy, and Question Guidebooks</a>
<ul>
<li><a href="1811.00226v3s.html#6">3.1 Threshold-based Strategy</a></li>
<li><a href="1811.00226v3s.html#7">3.2 Questions and Information Set Partition</a></li>
<li><a href="1811.00226v3s.html#7">3.3 Conditions for Asymptotic Learning</a></li>
</ul>
</li>
<li><a href="1811.00226v3s.html#7">4 Implementation of Threshold-based Strategy – Asymptotic Learning achieved in One-bit Questions</a>
<ul>
<li><a href="1811.00226v3s.html#10">4.1 Asymptotic Learning is achieved (Sketch of proof of Theorem 1)</a></li>
</ul>
</li>
<li><a href="1811.00226v3s.html#11">5 Conclusion</a></li>
<li><a href="1811.00226v3s.html#15">A Appendix: Proofs and Calculations</a>
<ul>
<li><a href="1811.00226v3s.html#15">A.1 Proof of Lemma 1</a></li>
<li><a href="1811.00226v3s.html#15">A.2 Proof of Lemma 2</a></li>
<li><a href="1811.00226v3s.html#16">A.3 Upper bound of growth rate of mk</a></li>
<li><a href="1811.00226v3s.html#17">A.4 Calculation of the probability that a wrong cascade will be stopped</a></li>
<li><a href="1811.00226v3s.html#17">A.5 Lower bound of growth rate of mk</a></li>
<li><a href="1811.00226v3s.html#18">A.6 Calculation the probability that a right cascade will finally being stopped</a></li>
<li><a href="1811.00226v3s.html#18">A.7 Technical Claims and Calculations</a>
<ul>
<li><a href="1811.00226v3s.html#18">A.7.1 Claim 2 and its proof</a></li>
<li><a href="1811.00226v3s.html#18">A.7.2 Claim 3 and its Proof</a></li>
<li><a href="1811.00226v3s.html#19">A.7.3 Calculation of Upper bound of h+(m)</a></li>
<li><a href="1811.00226v3s.html#19">A.7.4 Convergence and bounds of &#160;trueh+(m+1)h-(m+1)/ trueh+(m)h-(m).</a></li>
<li><a href="1811.00226v3s.html#20">A.7.5 Bounding the probability of stopping a right cascade</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="1811.00226v3s.html#20">B Appendix: Discussions</a>
<ul>
<li><a href="1811.00226v3s.html#20">B.1 Question guidebooks are delicate</a></li>
<li><a href="1811.00226v3s.html#21">B.2 Why learning is more difficult in a deterministic network topology</a>
<ul>
<li><a href="1811.00226v3s.html#22">B.2.1 Informational Braess's paradox in deterministic networks</a></li>
</ul>
</li>
<li><a href="1811.00226v3s.html#23">B.3 Extended Question Guidebooks</a>
<ul>
<li><a href="1811.00226v3s.html#23">B.3.1 Example that the order of questions matters</a></li>
</ul>
</li>
<li><a href="1811.00226v3s.html#24">B.4 A subtle weaker assumption on common knowledge of question guidebook</a></li>
<li><a href="1811.00226v3s.html#24">B.5 Complementary discussion on mapping question guidebook to Markov chains</a></li>
</ul>
</li>
<li><a href="1811.00226v3s.html#25">C Appendix: Related work</a></li>
</ul>
<hr/>
</body>
</html>
